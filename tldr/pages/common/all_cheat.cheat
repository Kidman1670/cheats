% 7za

% Archive a file or directory:

7za a <archived.7z> <path/to/file_or_directory>

% Extract an existing 7z file with original directory structure:

7za x <archived>

% Archive using a specific archive type:

7za a -t<zip|gzip|bzip2|tar> <archived> <path/to/file_or_directory>

% List available archive types:

7za i

% List the contents of an archive file:

7za l <archived>
% 7z

% Archive a file or directory:

7z a <archived.7z> <path/to/file_or_directory>

% Encrypt an existing archive (including headers):

7z a <encrypted.7z> -p<password> -mhe=on <archived.7z>

% Extract an existing 7z file with original directory structure:

7z x <archived.7z>

% Extract an archive with user-defined output path:

7z x <archived.7z> -o<path/to/output>

% Extract an archive to stdout:

7z x <archived.7z> -so

% Archive using a specific archive type:

7z a -t<zip|gzip|bzip2|tar> <archived.7z> <path/to/file_or_directory>

% List available archive types:

7z i

% List the contents of an archive file:

7z l <archived.7z>
% 7zr

% Archive a file or directory:

7zr a <archived.7z> <path/to/file_or_directory>

% Extract an existing 7z file with original directory structure:

7zr x <archived.7z>

% List the contents of an archive file:

7zr l <archived.7z>
% aapt

% List files contained in an APK archive:

aapt list <path/to/app.apk>

% Display an app's metadata (version, permissions, etc.):

aapt dump badging <path/to/app.apk>

% Create a new APK archive with files from the specified directory:

aapt package -F <path/to/app.apk> <path/to/directory>
% abduco

% List sessions:

abduco

% Attach to a session, creating it if it doesn't exist:

abduco -A <name> <bash>

% Attach to a session with `dvtm`, creating it if it doesn't exist:

abduco -A <name>

% Detach from a session:

Ctrl + \

% Attach to a session in read-only mode:

abduco -Ar <name>
% ab

% Execute 100 HTTP GET requests to a given URL:

ab -n <100> <url>

% Execute 100 HTTP GET requests, processing up to 10 requests concurrently, to given URL:

ab -n <100> -c <10> <url>

% Use keep alive:

ab -k <url>

% Set the maximum number of seconds to spend for benchmarking:

ab -t <60> <url>

% Execute 100 HTTP POST requests to a given URL, using a JSON payload from a file:

ab -n <100> -T <application/json> -p <data.json> <url>
% ack

% Find files containing "foo":

ack <foo>

% Find files of a specific type:

ack --ruby <foo>

% Count the total number of matches for the term "foo":

ack -ch <foo>

% Show the file names containing "foo" and number of matches in each file:

ack -cl <foo>

% List all valid types:

ack --help=types
% act

% List the available actions:

act -l

% Run the default event:

act

% Run a specific event:

act <event_type>

% Run a specific action:

act -a <action_id>

% Do not actually run the actions (i.e. a dry run):

act -n

% Show verbose logs:

act -v
% adb

% Check whether the adb server process is running and start it:

adb start-server

% Terminate the adb server process:

adb kill-server

% Start a remote shell in the target emulator/device instance:

adb shell

% Push an Android application to an emulator/device:

adb install -r <path/to/file.apk>

% Copy a file/directory from the target device:

adb pull <path/to/device_file_or_directory> <path/to/local_destination_directory>

% Copy a file/directory to the target device:

adb push <path/to/local_file_or_directory> <path/to/device_destination_directory>

% Get a list of connected devices:

adb devices
% ag

% Find files containing "foo", and print the line matches in context:

ag <foo>

% Find files containing "foo" in a specific directory:

ag <foo> <path/to/directory>

% Find files containing "foo", but only list the filenames:

ag -l <foo>

% Find files containing "FOO" case-insensitively, and print only the match, rather than the whole line:

ag -i -o <FOO>

% Find "foo" in files with a name matching "bar":

ag <foo> -G <bar>

% Find files whose contents match a regular expression:

ag '<^ba(r|z)$>'

% Find files with a name matching "foo":

ag -g <foo>
% airpaste

% Wait for message and display when received:

airpaste

% Send text:

echo <text> | airpaste

% Send file:

airpaste < <path/to/file>

% Receive file:

airpaste > <path/to/file>

% Create/Join channel:

airpaste <channel_name>
% alacritty

% Open a new alacritty window:

alacritty

% Run in a specific directory:

alacritty --working-directory <path/to/directory>

% Run a command in a new alacritty window:

alacritty -e <command>

% Specify alternative configuration file (defaults to $XDG_CONFIG_HOME/alacritty/alacritty.yml):

alacritty --config-file <path/to/config.yml>

% Run with live config reload enabled (can also be enabled by default in alacritty.yml):

alacritty --live-config-reload --config-file <path/to/config.yml>
% alex

% Analyze text from `stdin`:

echo <His network looks good> | alex --stdin

% Analyze all files in the current directory:

alex

% Analyze a specific file:

alex <textfile.md>

% Analyze all markdown files except `example.md`:

alex *.md !<example.md>
% alias

% List all aliases:

alias

% Create a generic alias:

alias <word>="<command>"

% View the command associated to a given alias:

alias <word>

% Remove an aliased command:

unalias <word>

% Turn `rm` into an interactive command:

alias <rm>="<rm -i>"

% Create `la` as a shortcut for `ls -a`:

alias <la>="<ls -a>"
% androguard

% Display Android app manifest:

androguard axml <path/to/app.apk>

% Display app metadata (version and app ID):

androguard apkid <path/to/app.apk>

% Decompile Java code from an app:

androguard decompile <path/to/app.apk> --output <path/to/directory>
% ansible-galaxy

% Install a role:

ansible-galaxy install <username.role_name>

% Remove a role:

ansible-galaxy remove <username.role_name>

% List installed roles:

ansible-galaxy list

% Search for a given role:

ansible-galaxy search <role_name>

% Create a new role:

ansible-galaxy init <role_name>
% ansible

% List hosts belonging to a group:

ansible <group> --list-hosts

% Ping a group of hosts by invoking the ping module:

ansible <group> -m ping

% Display facts about a group of hosts by invoking the setup module:

ansible <group> -m setup

% Execute a command on a group of hosts by invoking command module with arguments:

ansible <group> -m command -a '<my_command>'

% Execute a command with administrative privileges:

ansible <group> --become --ask-become-pass -m command -a '<my_command>'

% Execute a command using a custom inventory file:

ansible <group> -i <inventory_file> -m command -a '<my_command>'
% ansible-playbook

% Run tasks in playbook:

ansible-playbook <playbook>

% Run tasks in playbook with custom host inventory:

ansible-playbook <playbook> -i <inventory_file>

% Run tasks in playbook with extra variables defined via the command line:

ansible-playbook <playbook> -e "<variable1>=<value1> <variable2>=<value2>"

% Run tasks in playbook with extra variables defined in a json file:

ansible-playbook <playbook> -e "@<variables.json>"
% ansible-vault

% Create a new encrypted vault file with a prompt for a password:

ansible-vault create <vault_file>

% Create a new encrypted vault file using a vault key file to encrypt it:

ansible-vault create --vault-password-file=<password_file> <vault_file>

% Encrypt an existing file using an optional password file:

ansible-vault encrypt --vault-password-file=<password_file> <vault_file>

% Encrypt a string using Ansible's encrypted string format, displaying interactive prompts:

ansible-vault encrypt_string

% View an encrypted file, using a password file to decrypt:

ansible-vault view --vault-password-file=<password_file> <vault_file>

% Re-key already encrypted vault file with a new password file:

ansible-vault rekey --vault-password-file=<old_password_file> --new-vault-password-file=<new_password_file> <vault_file>
% ansiweather

% Display a forecast using metric units for the next five days for Rzeszow, Poland:

ansiweather -u <metric> -f <5> -l <Rzeszow,PL>

% Display a forecast showing symbols and daylight data for your current location:

ansiweather -s <true> -d <true>

% Display a forecast showing wind and humidity data for your current location:

ansiweather -w <true> -h <true>
% apg

% Create random passwords (default password length is 8):

apg

% Create a password with at least 1 symbol (S), 1 number (N), 1 uppercase (C), 1 lowercase (L):

apg -M SNCL

% Create a password with 16 characters:

apg -m <16>

% Create a password with maximum length of 16:

apg -x <16>

% Create a password that doesn't appear in a dictionary (the dictionary file has to be provided):

apg -r <dictionary_file>
% apm

% Install packages from http://atom.io/packages and themes from http://atom.io/themes:

apm install <package_name>

% Remove packages/themes:

apm remove <package_name>

% Upgrade packages/themes:

apm upgrade <package_name>
% apropos

% Search for keyword:

apropos <regular_expression>

% Search without restricting output to terminal width:

apropos -l <regular_expression>

% Search for pages that only contain all of the expressions given (AND search):

apropos <regular_expression_1> -a <regular_expression_2> -a <regular_expression_3}
% arch

% Display the system's architecture:

arch
% arc

% Send the changes to Differential for review:

arc diff

% Show pending revision information:

arc list

% Update Git commit messages after review:

arc amend

% Push Git changes:

arc land
% aria2c

% Download a URI to a file:

aria2c <url>

% Download from multiple sources:

aria2c <url_1> <url_2>

% Download the URIs listed in a file:

aria2c -i <filename>

% Download with multiple connections:

aria2c -s <connections_num> <url>

% FTP download with username and password:

aria2c --ftp-user=<username> --ftp-passwd=<password> <url>

% Limit download speed in bytes/s:

aria2c --max-download-limit=<speed> <url>
% aria2

% Download a web resource:

aria2c <http://example.org/myLinux.iso>

% Download a resource from multiple sources:

aria2c <http://mirror1.org/myLinux.iso> <http://mirror2.org/myLinux.iso>

% Download using 2 connections per host:

aria2c -x<2> <http://example.org/myLinux.iso>

% Download from a Metalink URI:

aria2c <http://example.org/myLinux.metalink>

% Download from a BitTorrent URI:

aria2c <http://example.org/myLinux.torrent>

% Download from a BitTorrent Magnet URI:

aria2c <'magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C'>

% Download URIs from a file:

aria2c -i <uris.txt>
% ar

% Extract all members from an archive:

ar -x <libfoo.a>

% List the members of an archive:

ar -t <libfoo.a>

% Replace or add files to an archive:

ar -r <libfoo.a> <foo.o> <bar.o> <baz.o>

% Insert an object file index (equivalent to using `ranlib`):

ar -s <libfoo.a>

% Create an archive with files and an accompanying object file index:

ar -rs <libfoo.a> <foo.o> <bar.o> <baz.o>
% arping

% Ping a host by ARP request packets:

arping <host_ip>

% Ping a host on a specific interface:

arping -I <interface> <host_ip>

% Ping a host and stop at the first reply:

arping -f <host_ip>

% Ping a host a specific number of times:

arping -c <count> <host_ip>

% Broadcast ARP request packets to update neighbours' ARP caches:

arping -U <ip_to_broadcast>

% Detect duplicated IP addresses in the network by sending ARP requests with a 3 seconds timeout:

arping -D -w <3> <ip_to_check>
% arp

% Show current arp table:

arp -a

% Clear the entire cache:

sudo arp -a -d

% Delete a specific entry:

arp -d <address>

% Create an entry:

arp -s <address> <mac_address>
% asar

% Archive a file or directory:

asar pack <path/to/file_or_directory> <archived.asar>

% Extract an archive:

asar extract <archived.asar>

% Extract a specific file from an archive:

asar extract-file <archived.asar> <file>

% List the contents of an archive file:

asar list <archived.asar>
% asciinema

% Associate the local install of `asciinema` with an asciinema.org account:

asciinema auth

% Make a new recording (once finished, user will be prompted to upload it or save it locally):

asciinema rec

% Make a new recording and save it to a local file:

asciinema rec <path/to/file>.cast

% Replay a terminal recording from a local file:

asciinema play <path/to/file>.cast

% Replay a terminal recording hosted on asciinema.org:

asciinema play https://asciinema.org/a/<cast_id>

% Make a new recording, limiting any idle time to at most 2.5 seconds:

asciinema rec -i <2.5>

% Print the full output of a locally saved recording:

asciinema cat <path/to/file>.cast

% Upload a locally saved terminal session to asciinema.org:

asciinema upload <path/to/file>.cast
% asdf

% List all available plugins:

asdf plugin-list-all

% Install a plugin:

asdf plugin-add <name>

% List all available versions for a package:

asdf list-all <name>

% Install a specific version of a package:

asdf install <name> <version>

% Set global version for a package:

asdf global <name> <version>

% Set local version for a package:

asdf local <name> <version>
% assimp

% List all supported import formats:

assimp listext

% List all supported export formats:

assimp listexport

% Convert a file to one of the supported output formats, using the default parameters:

assimp export <input_file.stl> <output_file.obj>

% Convert a file using custom parameters (the dox_cmd.h file in assimp's source code lists available parameters):

assimp export <input_file.stl> <output_file.obj> <parameters>

% Display a summary of a 3D file's contents:

assimp info <path/to/file>

% List all supported subcommands ("verbs"):

assimp help

% Get help on a specific subcommand (e.g. the parameters specific to it):

assimp <subcommand> --help
% astronomer

% Scan a repository:

astronomer <tldr-pages/tldr-node-client>

% Scan the maximum amount of stars in the repository:

astronomer <tldr-pages/tldr-node-client> --stars <50>

% Scan a repository including comparative reports:

astronomer <tldr-pages/tldr-node-client> --verbose
% astyle

% Apply the default style of 4 spaces per indent and no formatting changes:

astyle <source_file>

% Apply the java style with attached braces:

astyle --style=java <path/to/file>

% Apply the allman style with broken braces:

astyle --style=allman <path/to/file>

% Apply a custom indent using spaces. Choose between 2 and 20 spaces:

astyle --indent=spaces=<number_of_spaces> <path/to/file>

% Apply a custom indent using tabs. Choose between 2 and 20 tabs:

astyle --indent=tab=<number_of_tabs> <path/to/file>
% at

% Execute commands from standard input in 5 minutes (press `Ctrl + D` when done):

at now + 5 minutes

% Execute a command from standard input at 10:00 AM today:

echo "<./make_db_backup.sh>" | at 1000

% Execute commands from a given file next Tuesday:

at -f <path/to/file> 9:30 PM Tue
% atom

% Open a file or directory:

atom <path/to/file_or_directory>

% Open a file or directory in a new window:

atom -n <path/to/file_or_directory>

% Open a file or directory in an existing window:

atom --add <path/to/file_or_directory>

% Open Atom in safe mode (does not load any additional packages):

atom --safe

% Prevent Atom from forking into the background, keeping Atom attached to the terminal:

atom --foreground

% Wait for Atom window to close before returning (useful for git commit editor):

atom --wait
% atoum

% Initialise a configuration file:

atoum --init

% Run all tests:

atoum

% Run tests using the specified configuration file:

atoum -c <path/to/file>

% Run a specific test file:

atoum -f <path/to/file>

% Run a specific directory of tests:

atoum -d <path/to/directory>

% Run all tests under a specific namespace:

atoum -ns <namespace>

% Run all tests with a specific tag:

atoum -t <tag>

% Load a custom bootstrap file before running tests:

atoum --bootstrap-file <path/to/file>
% atq

% Show the current user's scheduled jobs:

atq

% Show jobs from queue named 'a' (queues have single-character names):

atq -q <a>

% Show jobs of all users (run as super user):

sudo atq
% atrm

% Remove job number 10:

atrm <10>

% Remove many jobs, separated by spaces:

atrm <15> <17> <22>
% autoflake

% Remove unused variables from a single file and display the diff:

autoflake --remove-unused-variables <file.py>

% Remove unused imports from multiple files and display the diffs:

autoflake --remove-all-unused-imports <file1.py> <file2.py> <file3.py>

% Remove unused variables from a file, overwriting the file:

autoflake --remove-unused-variables --in-place <file.py>

% Remove unused variables recursively from all files in a directory, overwriting each file:

autoflake --remove-unused-variables --in-place --recursive <path/to/directory>
% autojump

% Jump to a directory that contains the given pattern:

j <pattern>

% Jump to a sub-directory (child) of the current directory that contains the given pattern:

jc <pattern>

% Open a directory that contains the given pattern in the operating system file manager:

jo <pattern>

% Remove non-existing directories from the autojump database:

j --purge

% Show the entries in the autojump database:

j -s
% autossh

% Open an SSH session, restarting when a monitoring port fails return data:

autossh -M <monitor_port> <ssh_command>

% Open an SSH session which forwards a local port to a remote one, restarting if necessary:

autossh -M <monitor_port> -L <local_port>:localhost:<remote_port> <user>@<host>

% Fork before executing ssh (runs in the background) and don't open a remote shell:

autossh -f -M <monitor_port> -N <ssh_command>

% Run autossh in the background, with no monitoring port, instead relying on SSH keep-alives every 10 seconds to detect failure:

autossh -f -M 0 -N -o "ServerAliveInterval 10" -o "ServerAliveCountMax 3" <ssh_command>

% Run autossh in the background, with no monitoring port, no remote shell, exiting if the port forward fails:

autossh -f -M 0 -N -o "ServerAliveInterval 10" -o "ServerAliveCountMax 3" -o ExitOnForwardFailure=yes -L <local_port>:localhost:<remote_port> <user>@<host>

% Run autossh in the background with debug output logged to a file and ssh verbose output logged to a second file:

AUTOSSH_DEBUG=1 AUTOSSH_LOGFILE=<log_file> autossh -f -M <monitor_port> -v -E <ssh_log_file> <ssh_command>
% avrdude

% Read AVR microcontroller:

avrdude -p <AVR_device> -c <programmer> -U flash:r:<file.hex>:i

% Write AVR microcontroller:

avrdude -p <AVR_device> -c <programmer> -U flash:w:<file.hex>

% List available AVR devices:

avrdude -p \?

% List available AVR programmers:

avrdude -c \?
% awk

% Print the fifth column (a.k.a. field) in a space-separated file:

awk '{print $5}' <filename>

% Print the second column of the lines containing "something" in a space-separated file:

awk '/<something>/ {print $2}' <filename>

% Print the last column of each line in a file, using a comma (instead of space) as a field separator:

awk -F ',' '{print $NF}' <filename>

% Sum the values in the first column of a file and print the total:

awk '{s+=$1} END {print s}' <filename>

% Sum the values in the first column and pretty-print the values and then the total:

awk '{s+=$1; print $1} END {print "--------"; print s}' <filename>

% Print every third line starting from the first line:

awk 'NR%3==1' <filename>

% Print all values starting from the third column:

awk '{for (i=3; i <= NF; i++) printf $i""FS; print""}' <filename>

% Print different values based on conditions:

awk '{if ($1 == "foo") print "Exact match foo"; else if ($1 ~ "bar") print "Partial match bar"; else print "Baz"}' <filename>
% aws-google-auth

% Login with Google SSO using the IDP and SP identifiers and set the credentials duration to one hour:

aws-google-auth -u <example@example.com> -I <$GOOGLE_IDP_ID> -S <$GOOGLE_SP_ID> -d <3600>

% Login [a]sking which role to use (in case of several available SAML roles):

aws-google-auth -u <example@example.com> -I <$GOOGLE_IDP_ID> -S <$GOOGLE_SP_ID> -d <3600> -a

% Resolve aliases for AWS accounts:

aws-google-auth -u <example@example.com> -I <$GOOGLE_IDP_ID> -S <$GOOGLE_SP_ID> -d <3600> -a --resolve-aliases

% Show help information:

aws-google-auth -h
% aws

% Configure the AWS Command Line:

aws configure wizard

% Configure the AWS Command Line using SSO:

aws configure sso

% See help text for the AWS command:

aws <command> help

% Get the caller identity (used to troubleshoot permissions):

aws sts get-caller-identity

% List AWS resources in a region and output in yaml:

aws dynamodb list-tables --region <us-east-1> --output yaml

% Use auto prompt to help with a command:

aws iam create-user --cli-auto-prompt

% Get an interactive wizard for an AWS resource:

aws dynamodb wizard <new-table>

% Generate a JSON CLI Skeleton (useful for infrastructure as code):

aws dynamodb update-table --generate-cli-skeleton
% aws s3

% Show files in a bucket:

aws s3 ls <bucket_name>

% Sync files and directories from local to bucket:

aws s3 sync <path/to/files> s3://<bucket_name>

% Sync files and directories from bucket to local:

aws s3 sync s3://<bucket_name> <path/to/target>

% Sync files and directories with exclusions:

aws s3 sync <path/to/files> s3://<bucket_name> --exclude <path/to/file> --exclude <path/to/directory>/*

% Remove file from bucket:

aws s3 rm s3://<bucket>/<path/to/file>

% Preview changes only:

aws s3 <any_command> --dryrun
% axel

% Download a URL to a file:

axel <url>

% Download and specify filename:

axel <url> -o <filename>

% Download with multiple connections:

axel -n <connections_num> <url>

% Search for mirrors:

axel -S <mirrors_num> <url>

% Limit download speed (bytes per second):

axel -s <speed> <url>
% az

% Log in to Azure:

az login

% Manage azure subscription information:

az account

% List all Azure Managed Disks:

az disk list

% List all Azure virtual machines:

az vm list

% Manage Azure Kubernetes Services:

az aks

% Manage Azure Network resources:

az network
% b2sum

% Calculate the BLAKE2 checksum for a file:

b2sum <filename1>

% Calculate BLAKE2 checksums for multiple files:

b2sum <filename1> <filename2>

% Read a file of BLAKE2 sums and filenames and verify all files have matching checksums:

b2sum -c <filename.b2>

% Calculate the BLAKE2 checksum from `stdin`:

<somecommand> | b2sum
% babel

% Transpile a specified input file and output to `stdout`:

babel <path/to/file>

% Transpile a specified input file and output to a specific file:

babel <path/to/input_file> --out-file <path/to/output_file>

% Transpile the input file every time it is changed:

babel <path/to/input_file> --watch

% Transpile a whole directory of files:

babel <path/to/input_directory>

% Ignore specified comma-separated files in a directory:

babel <path/to/input_directory> --ignore <ignored_files>

% Transpile and output as minified JavaScript:

babel <path/to/input_file> --minified

% Choose a set of presets for output formatting:

babel <path/to/input_file> --presets <presets>

% Output all available options:

babel --help
% badblocks

% Search a disk for bad blocks by using a non-destructive read-only test:

sudo badblocks </dev/sda>

% Search an unmounted disk for bad blocks with a non-destructive read-write test:

sudo badblocks -n </dev/sda>

% Search an unmounted disk for bad blocks with a destructive write test:

sudo badblocks -w </dev/sda>

% Search an unmounted disk for bad blocks with a destructive write test and show verbose status:

sudo badblocks -svw </dev/sda>

% Search an unmounted disk in desctructive mode and output found blocks to a file:

sudo badblocks -o </path/to/file> -w </dev/sda>

% Search an unmounted disk in desctructive mode with improved speed using 4K block size and 64K block count:

sudo badblocks -w -b <4096> -c <65536> </dev/sda>
% balena

% Login to the balenaCloud account:

balena login

% Create a balenaCloud or openBalena application:

balena app create <app_name>

% List all balenaCloud or openBalena applications within the account:

balena apps

% List all devices associated with the balenaCloud or openBalena account:

balena devices

% Flash a balenaOS image to a local drive:

balena local flash <path/to/balenaos.img> --drive <drive_location>
% banner

% Print the text message as a large banner (quotes are optional):

banner <"Hello World">

% Print the text message as a banner with a width of 50 characters:

banner -w <50> <"Hello World">

% Read text from `stdin`:

banner
% base32

% Encode a file:

base32 <filename>

% Decode a file:

base32 -d <filename>

% Encode from `stdin`:

<somecommand> | base32

% Decode from `stdin`:

<somecommand> | base32 -d
% base64

% Encode a file:

base64 <filename>

% Decode a file:

base64 -d <filename>

% Encode from `stdin`:

<somecommand> | base64

% Decode from `stdin`:

<somecommand> | base64 -d
% basename

% Show only the file name from a path:

basename <path/to/file>

% Show only the file name from a path, with a suffix removed:

basename <path/to/file> <suffix>
% bashmarks

% List available bookmarks:

l

% Save the current directory as "bookmark_name":

s <bookmark_name>

% Go to a bookmarked directory:

g <bookmark_name>

% Print a bookmarked directory's contents:

p <bookmark_name>

% Delete a bookmark:

d <bookmark_name>
% bash

% Start interactive shell:

bash

% Execute a command:

bash -c "<command>"

% Run commands from a file:

bash <file.sh>

% Run commands from a file, logging all commands executed to the terminal:

bash -x <file.sh>

% Run commands from a file, stopping at the first error:

bash -e <file.sh>

% Run commands from `stdin`:

bash -s

% Print the version information of bash (use `echo $BASH_VERSION` to show just the version string):

bash --version
% batch

% Execute commands from standard input (press `Ctrl + D` when done):

batch

% Execute a command from standard input:

echo "<./make_db_backup.sh>" | batch

% Execute commands from a given file:

batch -f <path/to/file>
% bat

% Print the contents of a file to the standard output:

bat <file>

% Concatenate several files into the target file:

bat <file1> <file2> > <target_file>

% Append several files into the target file:

bat <file1> <file2> >> <target_file>

% Number all output lines:

bat -n <file>

% Syntax highlight a json file:

bat --language json <file.json>

% Display all supported languages:

bat --list-languages
% bc

% Run calculator in interactive mode using the standard math library:

bc -l

% Calculate the result of an expression:

bc <<< "(1 + 2) * 2 ^ 2"

% Calculate expression and force number of decimal places to 10:

bc <<< "scale=10; 5 / 3"

% Calculate expression with sine and cosine using mathlib:

bc -l <<< "s(1) + c(1)"
% beanstalkd

% Start beanstalkd, listening on port 11300:

beanstalkd

% Start beanstalkd listening on a custom port and address:

beanstalkd -l <ip_address> -p <port_number>

% Persist work queues by saving them to disk:

beanstalkd -b <path/to/persistence_directory>

% Sync to the persistence directory every 500 milliseconds:

beanstalkd -b <path/to/persistence_directory> -f <500>
% bedtools

% Intersect two files with respect to the sequences' strand and save the result to <path/to/output_file>:

bedtools intersect -a <path/to/file_1> -b <path/to/file_2> -s > <path/to/output_file>

% Intersect two files with a left outer join, i.e. report each feature from <file_1> and NULL if no overlap with <file_2>:

bedtools intersect -a <path/to/file_1> -b <path/to/file_2> -lof > <path/to/output_file>

% Using more efficient algorithm to intersect two pre-sorted files:

bedtools intersect -a <path/to/file_1> -b <path/to/file_2> -sorted > <path/to/output_file>

% Group file <path/to/file> based on the first three and the fifth column and summarize the sixth column by summing it up:

bedtools groupby -i <path/to/file> -c 1-3,5 -g 6 -o sum

% Convert bam-formated file to a bed-formated one:

bedtools bamtobed -i <path/to/file>.bam > <path/to/file>.bed

% Find for all features in <file_1>.bed the closest one in <file_2>.bed and write their distance in an extra column (input files must be sorted):

bedtools closest -a <path/to/file_1>.bed -b <path/to/file_2>.bed -d
% behat

% Initialise a new Behat project:

behat --init

% Run all tests:

behat

% Run all tests from the specified suite:

behat --suite=<suite_name>

% Run tests with a specific output formatter:

behat --format <pretty|progress>

% Run tests and output results to a file:

behat --out <path/to/file>

% Display a list of definitions in your test suites:

behat --definitions
% berks

% Install cookbook dependencies into a local repo:

berks install

% Update a specific cookbook and its dependencies:

berks update <cookbook>

% Upload a cookbook to the Chef server:

berks upload <cookbook>

% View the dependencies of a cookbook:

berks contingent <cookbook>
% bg

% Resume most recently suspended job and run it in the background:

bg

% Resume a specific job (use `jobs -l` to get its ID) and run it in the background:

bg <job_id>
% bison

% Compile a bison definition file:

bison <path/to/file.y>

% Compile in debug mode, which causes the resulting parser to write additional information to the standard output:

bison --debug <path/to/file.y>

% Specify the output filename:

bison --output <path/to/output.c> <path/to/file.y>

% Be verbose when compiling:

bison --verbose
% bitcoin-cli

% Send a transaction to a given address:

bitcoin-cli sendtoaddress "<address>" <amount>

% Generate one or more blocks:

bitcoin-cli generate <num_blocks>

% Print high-level information about the wallet:

bitcoin-cli getwalletinfo

% List all outputs from previous transactions available to fund outgoing transactions:

bitcoin-cli listunspent

% Export the wallet information to a text file:

bitcoin-cli dumpwallet "<path/to/file>"
% blackfire

% Initialise and configure the Blackfire client:

blackfire config

% Launch the Blackfire agent:

blackfire agent

% Launch the Blackfire agent on a specific socket:

blackfire agent --socket="<tcp://127.0.0.1:8307>"

% Run the profiler on a specific program:

blackfire run <php path/to/file.php>

% Run the profiler and collect 10 samples:

blackfire --samples=<10> run <php path/to/file.php>

% Run the profiler and output results as JSON:

blackfire --json run <php path/to/file.php>

% Upload a profiler file to the Blackfire web service:

blackfire upload <path/to/file>

% View the status of profiles on the Blackfire web service:

blackfire status
% black

% Auto-format a file or entire directory:

black <path/to/file_or_directory>

% Format the code passed in as a string:

black -c <path/to/file_or_directory>

% Output a diff for each file on stdout:

black --diff <path/to/file_or_directory>

% Return the status without writing the files back:

black --check <path/to/file_or_directory>

% Auto-format a file or directory emitting exclusively error messages to stderr:

black --quiet <path/to/file_or_directory>
% blender

% Render all frames of an animation in the background, without loading the UI (output is saved to `/tmp`):

blender -b <filename>.blend -a

% Render an animation using a specific image naming pattern, in a path relative (`//`) to the .blend file:

blender -b <filename>.blend -o //<render/frame_###.png> -a

% Render the 10th frame of an animation as a single image, saved to an existing directory (absolute path):

blender -b <filename>.blend -o </path/to/output_directory> -f <10>

% Render the second last frame in an animation as a JPEG image, saved to an existing directory (relative path):

blender -b <filename>.blend -o //<output_directory> -F <JPEG> -f <-2>

% Render the animation of a specific scene, starting at frame 10 and ending at frame 500:

blender -b <filename>.blend -S <scene_name> -s <10> -e <500> -a

% Render an animation at a specific resolution, by passing a Python expression:

blender -b <filename>.blend --python-expr '<import bpy; bpy.data.scenes[0].render.resolution_percentage = 25>' -a

% Start an interactive Blender session in the terminal with a python console (do `import bpy` after starting):

blender -b --python-console
% bmaptool

% Create a blockmap from image file:

bmaptool create -o <blockmap.bmap> <source.img>

% Copy an image file into sdb:

bmaptool copy --bmap <blockmap.bmap> <source.img> </dev/sdb>

% Copy a compressed image file into sdb:

bmaptool copy --bmap <blockmap.bmap> <source.img.gz> </dev/sdb>

% Copy an image file into sdb without using a blockmap:

bmaptool copy --nobmap <source.img> </dev/sdb>
% boot

% Start a REPL session either with the project or standalone:

boot repl

% Build a single "uberjar":

boot jar

% Learn about a command:

boot cljs --help

% Generate scaffolding for a new project based on a template:

boot --dependencies boot/new new --template <template_name> --name <project_name>

% Build for development (if using the boot/new template):

boot dev

% Build for production (if using the boot/new template):

boot prod
% borg

% Initialise a (local) repository:

borg init </path/to/repo_directory>

% Backup a directory into the repository, creating an archive called "Monday":

borg create --progress </path/to/repo_directory>::<Monday> </path/to/source_directory>

% List all archives in a repository:

borg list </path/to/repo_directory>

% Extract a specific directory from the "Monday" archive in a remote repository, excluding all *.ext files:

borg extract <user>@<host>:</path/to/repo_directory>::<Monday> <path/to/target_directory> --exclude '<*.ext>'

% Prune a repository by deleting all archives older than 7 days, listing changes:

borg prune --keep-within <7d> --list </path/to/repo_directory>

% Mount a repository as a FUSE filesystem:

borg mount </path/to/repo_directory>::<Monday> </path/to/mountpoint>

% Display help on creating archives:

borg create --help
% bosh

% Create local alias for director:

bosh alias-env <environment_name> -e <ip_address|url> --ca-cert <ca_certificate>

% List environments:

bosh environments

% Login to the director:

bosh login -e <environment> 

% List deployments:

bosh -e <environment> deployments

% List environment virtual machines:

bosh -e <environment> vms -d <deployment>

% Ssh into virtual machine:

bosh -e <environment> ssh <virtual_machine> -d <deployment>

% Upload stemcell:

bosh -e <environment> upload-stemcell <stemcell_file|url>

% Show current cloud config:

bosh -e <environment> cloud-config
% bower

% Install a project's dependencies, listed in its bower.json:

bower install

% Install one or more packages to the bower_components directory:

bower install <package> <package>

% Uninstall packages locally from the bower_components directory:

bower uninstall <package> <package>

% List local packages and possible updates:

bower list

% Display help information about a bower command:

bower help <command>

% Create a bower.json file for your package:

bower init

% Install a specific dependency version, and add it to bower.json:

bower install <local_name>=<package>#<version> --save
% box

% Build a new Phar file:

box build

% Build a new Phar file using a specific config file:

box build -c <path/to/config>

% Display information about the PHAR PHP extension:

box info

% Display information about a specific Phar file:

box info <path/to/phar_file>

% Validate the first found config file in the working directory:

box validate

% Verify the signature of a specific Phar file:

box verify <path/to/phar_file>

% Display all available commands and options:

box help
% browser-sync

% Start a server from a specific directory:

browser-sync start --server <path/to/directory> --files <path/to/directory>

% Start a server from local directory, watching all css files in some directory:

browser-sync start --server --files '<path/to/directory/*.css>'

% Create configuration file:

browser-sync init

% Start browser-sync from config file:

browser-sync start --config <config_file>
% bundle

% Install all gems defined in the `Gemfile` expected in the working directory:

bundle install

% Update all gems by the rules defined in the `Gemfile` and regenerate `Gemfile.lock`:

bundle update

% Update one specific gem defined in the `Gemfile`:

bundle update --source <gemname>

% Create a new gem skeleton:

bundle gem <gemname>
% bup

% Initialize a backup repository in the specified local directory:

bup -d <path/to/repository> init

% Prepare a given directory before taking a backup:

bup -d <path/to/repository> index <path/to/directory>

% Backup a directory to the repository:

bup -d <path/to/repository> save -n <backup_name> <path/to/directory>

% Show the backup snapshots currently stored in the repository:

bup -d <path/to/repository> ls

% Restore a specific backup snapshot to a target directory:

bup -d <path/to/repository> restore -C <path/to/target_directory> <backup_name>
% buzzphrase

% Generate a string of three random phrases containing an adjective, a past tense verb and a plural noun:

buzzphrase

% Output a phrase formatted as [i]mperative verb + past tense [v]erb + [a]djective + plural [N]oun:

buzzphrase <'{i} {v} {a} {N}'>

% Output 4 phrases formatted as present participle [V]erb + [a]djective + singular [n]oun + [f]inal:

buzzphrase <4 '{V} {a} {n} {f}'>
% bw

% Log in to a Bitwarden user account:

bw login

% Log out of a Bitwarden user account:

bw logout

% Search and display items from Bitwarden vault:

bw list items --search <github>

% Display a particular item from Bitwarden vault:

bw get item <github>

% Create a folder in Bitwarden vault:

<echo -n '{"name":"My Folder1"}' | base64> | bw create folder
% bzip2

% Compress a file:

bzip2 <path/to/file_to_compress>

% Decompress a file:

bzip2 -d <path/to/compressed_file.bz2>

% Decompress a file to standard output:

bzip2 -dc <path/to/compressed_file.bz2>
% c99

% Compile source file(s) and create an executable:

c99 <file.c>

% Compile source file(s) and create an executable with a custom name:

c99 -o <executable_name> <file.c>

% Compile source file(s) and create object file(s):

c99 -c <file.c>

% Compile source file(s), link with object file(s), and create an executable:

c99 <file.c> <file.o>
% cabal

% Search and list packages from Hackage:

cabal list <search_string>

% Show information about a package:

cabal info <package_name>

% Download and install a package:

cabal install <package_name>

% Create a new Haskell project in the current directory:

cabal init

% Build the project in the current directory:

cabal build

% Run tests of the project in the current directory:

cabal test
% cake

% Display basic information about the current app and available commands:

cake

% Display a list of available routes:

cake routes

% Clear configuration caches:

cake cache clear_all

% Build the metadata cache:

cake schema_cache build --connection <connection>

% Clear the metadata cache:

cake schema_cache clear

% Clear a single cache table:

cake schema_cache clear <table_name>

% Start a development web server (defaults to port 8765):

cake server

% Start a REPL interactive shell instance:

cake console
% calibredb

% List ebooks in the library with additional information:

calibredb list

% Search for ebooks displaying additional information:

calibredb list --search <search_term>

% Search for just ids of ebooks:

calibredb search <search_term>

% Add one or more ebooks to the library:

calibredb add <file1 file2 …>

% Recursively add all ebooks under a directory to the library:

calibredb add -r <path/to/directory>

% Remove one or more ebooks from the library. You need ebook-ids (see above):

calibredb remove <id1 id2 …>
% calibre-server

% Start a server to distribute ebooks. Access at http://localhost:8080:

calibre-server

% Start server on different port. Access at http://localhost:port:

calibre-server --port <port>

% Password protect the server:

calibre-server --username <username> --password <password>
% cargo doc

% Build and view the default package documentation in the browser:

cargo doc --open

% Build documentation without accessing the network:

cargo doc --offline

% View a particular package's documentation:

cargo doc --open --package <package>

% View a particular package's documentation offline:

cargo doc --open --offline --package <package>
% cargo

% Search for crates:

cargo search <search_string>

% Install a crate:

cargo install <crate_name>

% List installed crates:

cargo install --list

% Create a new binary or library Rust project in the current directory:

cargo init --<bin|lib>

% Create a new binary or library Rust project in the specified directory:

cargo new <path/to/directory> --<bin|lib>

% Build the Rust project in the current directory:

cargo build

% Build using a specific number of threads (default is the number of CPU cores):

cargo build -j <jobs>
% case

% Match a variable against string literals to decide which command to run:

case <$tocount> in <words>) <wc -w README>; ;; <lines>) <wc -l README>; ;; esac

% Combine patterns with |, use * as a fallback pattern:

case <$tocount> in <[wW]|words>) <wc -w README>; ;; <[lL]|lines>) <wc -l README>; ;; *) <echo "what?">; ;; esac
% cat

% Print the contents of a file to the standard output:

cat <file>

% Concatenate several files into the target file:

cat <file1> <file2> > <target_file>

% Append several files into the target file:

cat <file1> <file2> >> <target_file>

% Number all output lines:

cat -n <file>

% Display non-printable and whitespace characters (with `M-` prefix if non-ASCII):

cat -v -t -e <file>
% cd

% Go to the given directory:

cd <path/to/directory>

% Go to home directory of current user:

cd

% Go up to the parent of the current directory:

cd ..

% Go to the previously chosen directory:

cd -
% chars

% Look up a character by its value:

chars '<ß>'

% Look up a character by its Unicode code point:

chars <U+1F63C>

% Look up possible characters given an ambiguous code point:

chars <10>

% Look up a control character:

chars "<^C>"
% chcon

% View security context of a file:

ls -lZ <path/to/file>

% Change the security context of a target file, using a reference file:

chcon --reference=<reference_file> <target_file>

% Change the full SELinux security context of a file:

chcon <user>:<role>:<type>:<range/level> <filename>

% Change only the user part of SELinux security context:

chcon -u <user> <filename>

% Change only the role part of SELinux security context:

chcon -r <role> <filename>

% Change only the type part of SELinux security context:

chcon -t <type> <filename>

% Change only the range/level part of SELinux security context:

chcon -l <range/level> <filename>
% cheat

% Show example usage of a command:

cheat <command>

% Edit the cheat sheet for a command:

cheat -e <command>

% List the available cheat sheets:

cheat -l

% Search available the cheat sheets for a specified command name:

cheat -s <command>

% Get the current cheat version:

cheat -v
% chgrp

% Change the owner group of a file/directory:

chgrp <group> <path/to/file_or_directory>

% Recursively change the owner group of a directory and its contents:

chgrp -R <group> <path/to/directory>

% Change the owner group of a symbolic link:

chgrp -h <group> <path/to/symlink>

% Change the owner group of a file/directory to match a reference file:

chgrp --reference=<path/to/reference_file> <path/to/file_or_directory>
% chisel

% Run a Chisel server:

chisel server

% Run a Chisel server listening to a specific port:

chisel server -p <server_port>

% Run a chisel server that accepts authenticated connections using username and password:

chisel server --auth <username>:<password>

% Connect to a Chisel server and tunnel a specific port to a remote server and port:

chisel client <server_ip>:<server_port> <local_port>:<remote_server>:<remote_port>

% Connect to a Chisel server and tunnel a specific host and port to a remote server and port:

chisel client <server_ip>:<server_port> <local_host>:<local_port>:<remote_server>:<remote_port>

% Connect to a Chisel server using username and password authentication:

chisel client --auth <username>:<password> <server_ip>:<server_port> <local_port>:<remote_server>:<remote_port>
% chmod

% Give the [u]ser who owns a file the right to e[x]ecute it:

chmod u+x <file>

% Give the [u]ser rights to [r]ead and [w]rite to a file/directory:

chmod u+rw <file_or_directory>

% Remove e[x]ecutable rights from the [g]roup:

chmod g-x <file>

% Give [a]ll users rights to [r]ead and e[x]ecute:

chmod a+rx <file>

% Give [o]thers (not in the file owner's group) the same rights as the [g]roup:

chmod o=g <file>

% Remove all rights from [o]thers:

chmod o= <file>

% Change permissions recursively giving [g]roup and [o]thers the abililty to [w]rite:

chmod -R g+w,o+w <directory>
% chown

% Change the owner user of a file/directory:

chown <user> <path/to/file_or_directory>

% Change the owner user and group of a file/directory:

chown <user>:<group> <path/to/file_or_directory>

% Recursively change the owner of a directory and its contents:

chown -R <user> <path/to/directory>

% Change the owner of a symbolic link:

chown -h <user> <path/to/symlink>

% Change the owner of a file/directory to match a reference file:

chown --reference=<path/to/reference_file> <path/to/file_or_directory>
% chromium

% Open a file:

chromium <path/to/file.html>

% Open an URL:

chromium <example.com>

% Open in incognito mode:

chromium --incognito <example.com>

% Open in a new window:

chromium --new-window <example.com>

% Open in app mode (without toolbars, URL bar, buttons, etc.):

chromium --app='<https://example.com>'

% Use a proxy server:

chromium --proxy-server="<socks5://hostname:66>" <example.com>
% chroot

% Run command as new root directory:

chroot </path/to/new/root> <command>

% Specify user and group (ID or name) to use:

chroot --userspec=<user:group>
% chsh

% Change shell:

chsh -s <path/to/shell_binary> <username>
% cksum

% Display a 32 bit checksum, size in bytes and filename:

cksum <filename>
% clamscan

% Scan a file for vulnerabilities:

clamscan <path/to/file>

% Scan all files recursively in a specific directory:

clamscan -r <path/to/directory>

% Scan data from `stdin`:

<command> | clamscan -

% Specify a virus database file or directory of files:

clamscan --database <path/to/database_file_or_directory>

% Scan the current directory and output only infected files:

clamscan --infected

% Output the scan report to a log file:

clamscan --log <path/to/log_file>

% Move infected files to a specific directory:

clamscan --move <path/to/quarantine_directory>

% Remove infected files:

clamscan --remove yes
% clang

% Compile a source code file into an executable binary:

clang <input_source.c> -o <output_executable>

% Activate output of all errors and warnings:

clang <input_source.c> -Wall -o <output_executable>

% Include libraries located at a different path than the source file:

clang <input_source.c> -o <output_executable> -I<header_path> -L<library_path> -l<library_name>

% Compile source code into LLVM Intermediate Representation (IR):

clang -S -emit-llvm <file.c> -o <file.ll>
% clear

% Clear the screen (equivalent to pressing Control-L in Bash shell):

clear

% Clear the screen but keep the terminal's scrollback buffer:

clear -x

% Indicate the type of terminal to clean (defaults to the value of the environment variable `TERM`):

clear -T <type_of_terminal>

% Show the version of `ncurses` used by `clear`:

clear -V
% clementine

% Open Clementine:

clementine

% Start playing a music file:

clementine <url/or/path/to/file.ext>

% Toggle between pausing and playing:

clementine --play-pause

% Stop playback:

clementine --stop

% Skip to the next track:

clementine --next

% Skip to the previous track:

clementine --previous

% Load a playlist file:

clementine --load <path/to/playlist.ext>

% Play the 5th track in the currently loaded playlist:

clementine --play-track <5>
% clockwork-cli

% Monitor Clockwork logs for the current project:

clockwork-cli

% Monitor Clockwork logs for a specific project:

clockwork-cli <path/to/directory>

% Monitor Clockwork logs for multiple projects:

clockwork-cli <path/to/directory1 path/to/directory2 …>
% cloc

% Count all the lines of code in a directory:

cloc <path/to/directory>

% Count all the lines of code in a directory, displaying a progress bar during the counting process:

cloc --progress=1 <path/to/directory>

% Compare 2 directory structures and count the differences between them:

cloc --diff <path/to/directory/one> <path/to/directory/two>

% Ignore files that are ignored by VCS, such as files specified in .gitignore:

cloc --vcs git <path/to/directory>
% cmake

% Generate a Makefile and use it to compile a project in the same directory as the source:

cmake && make

% Generate a Makefile and use it to compile a project in a separate "build" directory (out-of-source build):

cmake -H. -B<build> && make -C <build>

% Run cmake in interactive mode (it will ask for each variable, instead of using defaults):

cmake -i
% cmark

% Render a Commonmark Markdown file to HTML:

cmark --to html <filename.md>

% Convert data from standard input to latex:

cmark --to latex

% Convert straight quotes to smart quotes:

cmark --smart --to html <filename.md>

% Validate utf8 characters:

cmark --validate-utf8 <filename.md>
% cmp

% Find the byte number and line number of the first difference between the files:

cmp <file1> <file2>

% Find the byte number and differing bytes of every difference:

cmp -l <file1> <file2>
% code

% Open VS Code:

code

% Open the current directory in VS Code:

code .

% Open a file or directory in VS Code:

code <path/to/file_or_directory>

% Open a file or directory in the currently open VS Code window:

code --reuse-window <path/to/file_or_directory>

% Compare two files in VS Code:

code -d <file1> <file2>
% coffee

% Run a script:

coffee <path/to/file.coffee>

% Compile to JavaScript and save to a file with the same name:

coffee --compile <path/to/file.coffee>

% Compile to JavaScript and save to a given output file:

coffee --compile <path/to/file.coffee> --output <path/to/file.js>

% Run interactive REPL:

coffee --interactive

% Watch script for changes and re-run script:

coffee --watch <path/to/file.coffee>
% column

% Format output for a 30 characters wide display:

printf "header1 header2\nbar foo\n" | column -c <30>

% Split columns automatically and auto-align in a tabular format:

printf "header1 header2\nbar foo\n" | column -t

% Specify column delimiter character for the -t option (e.g. "," for csv); default is whitespace:

printf "header1,header2\nbar,foo\n" | column -t -s<,>

% Fill columns before filling rows:

printf "header1\nbar\nfoobar\n" | column -c <30> -x
% command

% Execute the ls program literally, even if an ls alias exists:

command <ls>
% comm

% Produce three tab-separated columns: lines only in first file, lines only in second file and common lines:

comm <file1> <file2>

% Print only lines common to both files:

comm -12 <file1> <file2>

% Print only lines common to both files, reading one file from `stdin`:

cat <file1> | comm -12 - <file2>

% Get lines only found in first file, saving the result to a third file:

comm -23 <file1> <file2> > <file1_only>

% Print lines only found in second file, when the files aren't sorted:

comm -13 <(sort <file1>) <(sort <file2>)
% compare

% Compare 2 images:

compare <image1.png> <image2.png> <diff.png>

% Compare 2 images using a custom metric:

compare -verbose -metric <PSNR> <image1.png> <image2.png> <diff.png>
% complete

% Apply a function that performs autocompletion to a command:

complete -F <function> <command>

% Apply a command that performs autocompletion to another command:

complete -C <autocomplete_command> <command>

% Apply autocompletion without appending a space to the completed word:

complete -o nospace -F <function> <command>
% composer

% Add a package as a dependency for this project, adding it to `composer.json`:

composer require <user/package_name>

% Install all the dependencies in this project's `composer.json`:

composer install

% Uninstall a package from this project, removing it as a dependency from `composer.json`:

composer remove <user/package_name>

% Update all the dependencies in this project's `composer.json`:

composer update

% Update composer to the latest version:

composer self-update
% conda

% Create a new environment, installing named packages into it:

conda create --name <environment_name> <python=2.7 matplotlib>

% List all environments:

conda info --envs

% Load or unload an environment:

conda <activate|deactivate> <environment_name>

% Delete an environment (remove all packages):

conda remove --name <environment_name> --all

% Search conda channels for a package by name:

conda search <package_name>

% Install packages into the current environment:

conda install <python=3.4 numpy>

% List currently installed packages in current environment:

conda list

% Delete unused packages and caches:

conda clean --all
% consul-kv

% Read a value from the key-value store:

consul kv get <key>

% Store a new key-value pair:

consul kv put <key> <value>

% Delete a key-value pair:

consul kv delete <key>
% consul

% Check the Consul version:

consul --version

% Show general help:

consul --help

% Show help for a sub-command:

consul <sub-command> --help
% convert

% Convert an image from JPG to PNG:

convert <image.jpg> <image.png>

% Scale an image 50% its original size:

convert <image.png> -resize 50% <image2.png>

% Scale an image keeping the original aspect ratio to a maximum dimension of 640x480:

convert <image.png> -resize 640x480 <image2.png>

% Horizontally append images:

convert <image1.png> <image2.png> <image3.png> +append <image123.png>

% Vertically append images:

convert <image1.png> <image2.png> <image3.png> -append <image123.png>

% Create a gif from a series of images with 100ms delay between them:

convert <image1.png> <image2.png> <image3.png> -delay <100> <animation.gif>

% Create an image with nothing but a solid background:

convert -size <800x600> "xc:<#ff0000>" <image.png>
% convmv

% Test filename encoding conversion (don't actually change the filename):

convmv -f <from_encoding> -t <to_encoding> <input_file>

% Convert filename encoding and rename the file to the new encoding:

convmv -f <from_encoding> -t <to_encoding> --notest <input_file>
% copyq

% Launch CopyQ to store clipboard history:

copyq

% Show current clipboard content:

copyq clipboard

% Insert raw text into the clipboard history:

copyq add -- <text1> <text2> <text3>

% Insert text containing escape sequences ('\n', '\t') into the clipboard history:

copyq add <firstline\nsecondline>

% Print the content of the first 3 items in the clipboard history:

copyq read 0 1 2

% Copy a file's contents into the clipboard:

copyq copy < <file.txt>

% Copy a JPEG image into the clipboard:

copyq copy image/jpeg < <image.jpg>
% cordova

% Create a cordova project:

cordova create <path> <package_name> <project_name>

% Display the current workspace status:

cordova info

% Add a cordova platform:

cordova platform add <platform>

% Remove a cordova platform:

cordova platform remove <platform>

% Add a cordova plugin:

cordova plugin add <pluginid>

% Remove a cordova plugin:

cordova plugin remove <pluginid>
% cotton

% Use a specific base url:

cotton -u <base_url> <file>.md

% Disable certificate verification (insecure mode):

cotton -u <base_url> -i <file>.md

% Stop running when a test fails:

cotton -u <base_url> -s <file>.md
% couchdb

% Start couchdb:

couchdb

% Start couchdb interactive shell:

couchdb -i

% Start couchdb as a background process:

couchdb -b

% Kill the background process (Note: It will respawn if needed):

couchdb -k

% Shutdown the background process:

couchdb -d
% cowsay

% Print an ASCII cow saying "Hello world!":

cowsay "Hello world!"

% Use text from standard input for the balloon:

echo "Hello!" | cowsay

% List all available characters:

cowsay -l

% Print an ASCII dragon saying "Hello!":

cowsay -f dragon "Hello!"

% Print a stoned thinking ASCII cow:

cowthink -s "I'm just a cow, not a great thinker ..."
% cpdf

% Select pages 1, 2, 3 and 6 from a source document and write those to a destination document:

cpdf <path/to/source_document.pdf> <1-3,6> -o <path/to/destination_document.pdf>

% Merge two documents into a new one:

cpdf -merge <path/to/source_document_one.pdf> <path/to/source_document_two.pdf> -o <path/to/destination_document.pdf>

% Show the bookmarks of a document:

cpdf -list-bookmarks <path/to/document.pdf>

% Split a document into ten-page chunks, writing them to chunk001.pdf, chunk002.pdf, etc:

cpdf -split <path/to/document.pdf> -o <path/to/chunk%%%.pdf> -chunk <10>

% Encrypt a document using 128bit encryption, providing `fred` as owner password and `joe` as user password:

cpdf -encrypt <128bit> <fred> <joe> <path/to/source_document.pdf> -o <path/to/encrypted_document.pdf>

% Decrypt a document using the owner password `fred`:

cpdf -decrypt <path/to/encrypted_document.pdf> owner=<fred> -o <path/to/decrypted_document.pdf>

% Show the annotations of a document:

cpdf -list-annotations <path/to/document.pdf>

% Create a new document from an existing one with additional metadata:

cpdf -set-metadata <path/to/metadata.xml> <path/to/source_document.pdf> -o <path/to/destination_document.pdf>
% cpio

% Take a list of file names from standard input and add them [o]nto an archive in cpio's binary format:

echo "<file1> <file2> <file3>" | cpio -o > <archive.cpio>

% Copy all files and directories in a directory and add them [o]nto an archive, in [v]erbose mode:

find <path/to/directory> | cpio -ov > <archive.cpio>

% P[i]ck all files from an archive, generating [d]irectories where needed, in [v]erbose mode:

cpio -idv < <archive.cpio>
% cp

% Copy a file to another location:

cp <path/to/file.ext> <path/to/copy.ext>

% Copy a file into another directory, keeping the filename:

cp <path/to/file.ext> <path/to/target_parent_directory>

% Recursively copy a directory's contents to another location (if the destination exists, the directory is copied inside it):

cp -r <path/to/directory> <path/to/copy>

% Copy a directory recursively, in verbose mode (shows files as they are copied):

cp -vr <path/to/directory> <path/to/copy>

% Copy text files to another location, in interactive mode (prompts user before overwriting):

cp -i <*.txt> <path/to/target_directory>
% cppcheck

% Recursively check the current directory, showing progress on the screen and logging error messages to a file:

cppcheck . 2> cppcheck.log

% Recursively check a given directory, and don't print progress messages:

cppcheck --quiet <path/to/directory>

% Check a given file, specifying which tests to perform (by default only errors are shown):

cppcheck --enable=<error|warning|style|performance|portability|information|all> <path/to/file.cpp>

% List available tests:

cppcheck --errorlist

% Check a given file, ignoring specific tests:

cppcheck --suppress=<test_id1> --suppress=<test_id2> <path/to/file.cpp>

% Check the current directory, providing paths for include files located outside it (e.g. external libraries):

cppcheck -I <include/directory_1> -I <include/directory_2> .

% Check a Microsoft Visual Studio project (`*.vcxproj`) or solution (`*.sln`):

cppcheck --project=<path/to/project.sln>
% cppclean

% Run in a project's directory:

cppclean <path/to/project>

% Run on a project where the headers are in the "inc1/" and "inc2/" directories:

cppclean <path/to/project> --include-path=<inc1> --include-path=<inc2>

% Run on a specific file "main.cpp":

cppclean <main.cpp>

% Run on the current directory, excluding the "build" directory:

cppclean <.> --exclude=<build>
% cradle deploy

% Deploy Cradle to a server:

cradle deploy production

% Deploy static assets to Amazon S3:

cradle deploy s3

% Deploy static assets including the Yarn "components" directory:

cradle deploy s3 --include-yarn

% Deploy static assets including the "upload" directory:

cradle deploy s3 --include-upload
% cradle elastic

% Truncate the ElasticSearch index:

cradle elastic flush

% Truncate the ElasticSearch index for a specific package:

cradle elastic flush <package_name>

% Submit the ElasticSearch schema:

cradle elastic map

% Submit the ElasticSearch schema for a specific package:

cradle elastic map <package_name>

% Populate the ElasticSearch indices for all packages:

cradle elastic populate

% Populate the ElasticSearch indices for a specific package:

cradle elastic populate <package_name>
% cradle install

% Install Cradle's components (User will be prompted for further details):

cradle install

% Forcefully overwrite files:

cradle install --force

% Skip running SQL migrations:

cradle install --skip-sql

% Skip running package updates:

cradle install --skip-versioning

% Use specific database details:

cradle install -h <hostname> -u <username> -p <password>
% cradle

% Connect to a server:

cradle connect <server_name>

% Display general help:

cradle help

% Display help for a specific command:

cradle <command> help

% Execute a Cradle command:

cradle <command>
% cradle package

% Display a list of available packages:

cradle package list

% Search for a package:

cradle package search <package>

% Install a package from Packagist:

cradle package install <package>

% Install a specific version of a package:

cradle package install <package> <version>

% Update a package:

cradle package update <package>

% Update a package to a specific version:

cradle package update <package> <version>

% Remove a specific package:

cradle package remove <package>
% cradle sql

% Rebuild the database schema:

cradle sql build

% Rebuild the database schema for a specific package:

cradle sql build <package_name>

% Empty the entire database:

cradle sql flush

% Empty the database tables for a specific package:

cradle sql flush <package_name>

% Populate the tables for all packages:

cradle sql populate

% Populate the tables for a specific package:

cradle sql populate <package_name>
% crontab

% Edit the crontab file for the current user:

crontab -e

% Edit the crontab file for a specific user:

sudo crontab -e -u <user>

% View a list of existing cron jobs for current user:

crontab -l

% Remove all cron jobs for the current user:

crontab -r

% Sample job which runs at 10:00 every day (* means any value):

0 10 * * * <command_to_execute>

% Sample job which runs every minute on the 3rd of April:

* * 3 Apr * <command_to_execute>

% Sample job which runs a certain script at 02:30 every Friday:

30 2 * * Fri </absolute/path/to/script.sh>
% cryfs

% Mount an encrypted file system. The initialization wizard will be started on the first execution:

cryfs <path/to/cipher_dir> <path/to/mount_point>

% Unmount an encrypted file system:

cryfs-unmount <path/to/mount_point>

% Automatically unmount after ten minutes of inactivity:

cryfs --unmount-idle <10> <path/to/cipher_dir> <path/to/mount_point>

% Show a list of supported ciphers:

cryfs --show-ciphers
% crystal

% Run a Crystal file:

crystal <path/to/file.cr>

% Compile a file and all dependencies to a single executable:

crystal build <path/to/file.cr>

% Start a local interactive server for testing the language:

crystal play

% Create a project directory for a Crystal application:

crystal init app <application_name>

% Display all help options:

crystal help
% csc

% Compile one or more C# files to a CIL executable:

csc <path/to/input_file_a.cs> <path/to/input_file_b.cs>

% Specify the output filename:

csc /out:<path/to/filename> <path/to/input_file.cs>

% Compile into a '.dll' library instead of an executable:

csc /target:library <path/to/input_file.cs>

% Reference another assembly:

csc /reference:<path/to/library.dll> <path/to/input_file.cs>

% Embed a resource:

csc /resource:<path/to/resource_file> <path/to/input_file.cs>

% Automatically generate XML documentation:

csc /doc:<path/to/output.xml> <path/to/input_file.cs>

% Specify an icon:

csc /win32icon:<path/to/icon.ico> <path/to/input_file.cs>

% Strongly-name the resulting assembly with a keyfile:

csc /keyfile:<path/to/keyfile> <path/to/input_file.cs>
% csslint

% Lint a single CSS file:

csslint <file.css>

% Lint multiple CSS files:

csslint <file1.css> <file2.css> <file3.css>

% List all possible style rules:

csslint --list-rules

% Specify certain rules as errors (which result in a non-zero exit code):

csslint --errors=<errors,universal-selector,imports> <file.css>

% Specify certain rules as warnings:

csslint --warnings=<box-sizing,selector-max,floats> <file.css>

% Specify certain rules to completely ignore:

csslint --ignore=<ids,rules-count,shorthand> <file.css>
% csvclean

% Clean a CSV file:

csvclean <bad.csv>

% List locations of syntax errors in a CSV file:

csvclean -n <bad.csv>
% csvcut

% Print indices and names of all columns:

csvcut -n <data.csv>

% Extract the first and third columns:

csvcut -c <1,3> <data.csv>

% Extract all columns **except** the fourth one:

csvcut -C <4> <data.csv>

% Extract the columns named "id" and "first name" (in that order):

csvcut -c <id,"first name"> <data.csv>
% csvformat

% Convert to a tab-delimited file (TSV):

csvformat -T <data.csv>

% Convert delimiters to a custom character:

csvformat -D "<custom_character>" <data.csv>

% Convert line endings to carriage return (^M) + line feed:

csvformat -M "<\r\n>" <data.csv>

% Minimize use of quote characters:

csvformat -U 0 <data.csv>

% Maximize use of quote characters:

csvformat -U 1 <data.csv>
% csvgrep

% Find rows that have a certain string in column 1:

csvgrep -c <1> -m <string_to_match> <data.csv>

% Find rows in which columns 3 or 4 match a certain regex pattern:

csvgrep -c <3,4> -r <regex_pattern> <data.csv>

% Find rows in which the "name" column does NOT include the string "John Doe":

csvgrep -i -c <name> -m <"John Doe"> <data.csv>
% csvkit

% Run a command on a CSV file with a custom delimiter:

<cmd> -d <delimiter> <filename.csv>

% Run a command on a CSV file with a tab as a delimiter (overrides -d):

<cmd> -t <filename.csv>

% Run a command on a CSV file with a custom quote character:

<cmd> -q <quote_char> <filename.csv>

% Run a command on a CSV file with no header row:

<cmd> -H <filename.csv>
% csvlook

% View a CSV file:

csvlook <data.csv>
% csvpy

% Load a CSV file into a `CSVKitReader` object:

csvpy <data.csv>

% Load a CSV file into a `CSVKitDictReader` object:

csvpy --dict <data.csv>
% csvsort

% Sort a CSV file by column 9:

csvsort -c <9> <data.csv>

% Sort a CSV file by the "name" column in descending order:

csvsort -r -c <name> <data.csv>

% Sort a CSV file by column 2, then by column 4:

csvsort -c <2,4> <data.csv>

% Sort a CSV file without inferring data types:

csvsort --no-inference -c <columns> <data.csv>
% csvstat

% Show all stats for all columns:

csvstat <data.csv>

% Show all stats for columns 2 and 4:

csvstat -c <2,4> <data.csv>

% Show sums for all columns:

csvstat --sum <data.csv>

% Show the max value length for column 3:

csvstat -c <3> --len <data.csv>

% Show the number of unique values in the "name" column:

csvstat -c <name> --unique <data.csv>
% ctags

% Generate tags for a single file, and output them to a file named "tags" in the current directory, overwriting the file if it exists:

ctags <path/to/file>

% Generate tags for all files in the current directory, and output them to a specific file, overwriting the file if it exists:

ctags -f <filename> *

% Generate tags for all files in the current directory and all subdirectories:

ctags --recurse
% ctest

% Run all tests defined in the CMake project, executing 4 jobs at a time in parallel:

ctest -j<4> --output-on-failure

% Show a list of available tests:

ctest -N

% Run a single test based on its name, or filter on a regular expression:

ctest --output-on-failure -R '^<test_name>$'
% curl

% Download the contents of an URL to a file:

curl <http://example.com> -o <filename>

% Download a file, saving the output under the filename indicated by the URL:

curl -O <http://example.com/filename>

% Download a file, following [L]ocation redirects, and automatically [C]ontinuing (resuming) a previous file transfer:

curl -O -L -C - <http://example.com/filename>

% Send form-encoded data (POST request of type `application/x-www-form-urlencoded`):

curl -d <'name=bob'> <http://example.com/form>

% Send a request with an extra header, using a custom HTTP method:

curl -H <'X-My-Header: 123'> -X <PUT> <http://example.com>

% Send data in JSON format, specifying the appropriate content-type header:

curl -d <'{"name":"bob"}'> -H <'Content-Type: application/json'> <http://example.com/users/1234>

% Pass a user name and password for server authentication:

curl -u myusername:mypassword <http://example.com>

% Pass client certificate and key for a resource, skipping certificate validation:

curl --cert <client.pem> --key <key.pem> --insecure <https://example.com>
% cut

% Cut out the first sixteen characters of each line of `stdin`:

cut -c <1-16>

% Cut out the first sixteen characters of each line of the given files:

cut -c <1-16> <file>

% Cut out everything from the 3rd character to the end of each line:

cut -c <3->

% Cut out the fifth field of each line, using a colon as a field delimiter (default delimiter is tab):

cut -d'<:>' -f<5>

% Cut out the 2nd and 10th fields of each line, using a semicolon as a delimiter:

cut -d'<;>' -f<2,10>

% Cut out the fields 3 through to the end of each line, using a space as a delimiter:

cut -d'< >' -f<3->
% darkhttpd

% Start server serving the specified document root:

darkhttpd <path/to/docroot>

% Start server on specified port (port 8080 by default if running as non-root user):

darkhttpd <path/to/docroot> --port <port>

% Listen only on specified IP address (by default, the server listens on all interfaces):

darkhttpd <path/to/docroot> --addr <ip_address>
% date

% Display the current date using the default locale's format:

date +"%c"

% Display the current date in UTC and ISO 8601 format:

date -u +"%Y-%m-%dT%H:%M:%SZ"

% Display the current date as a Unix timestamp (seconds since the Unix epoch):

date +%s

% Display a specific date (represented as a Unix timestamp) using the default format:

date -d @1473305798

% Convert a specific date to the Unix timestamp format:

date -d "<2018-09-01 00:00>" +%s --utc
% dcfldd

% Copy a disk to a raw image file and hash the image using SHA256:

dcfldd if=/dev/<disk_device> of=<file.img> hash=sha256 hashlog=<file.hash>

% Copy a disk to a raw image file, hashing each 1GB chunk:

dcfldd if=/dev/<disk_device> of=<file.img> hash=<sha512|sha384|sha256|sha1|md5> hashlog=<file.hash> hashwindow=<1G>
% dc

% Run calculator in interactive mode:

dc

% Execute dc script in file:

dc -f <file>

% Calculate 4 times 5 [4 5 *], subtract 17 [17 -], and [p]rint the output (using echo):

echo "4 5 * 17 - p"| dc

% Set number of decimal places to 7 [7 k], calculate 5 divided by -3 [5 _3 /] and [p]rint (using dc -e):

dc -e "7 k 5 _3 / p"

% Calculate the golden ratio, phi: Set number of decimal places to 100 [100 k], square root of 5 [5 v] plus 1 [1 +], divided by 2 [2 /], and [p]rint result:

dc -e "100 k 5 v 1 + 2 / p"
% dd

% Make a bootable usb drive from an isohybrid file (such like archlinux-xxx.iso) and show the progress:

dd if=<file.iso> of=/dev/<usb_drive> status=progress

% Clone a drive to another drive with 4MB block, ignore error and show progress:

dd if=/dev/<source_drive> of=/dev/<dest_drive> bs=4M conv=noerror status=progress

% Generate a file of 100 random bytes by using kernel random driver:

dd if=/dev/urandom of=<random_file> bs=100 count=1

% Benchmark the write performance of a disk:

dd if=/dev/zero of=<file_1GB> bs=1024 count=1000000

% Check progress of an ongoing dd operation (Run this command from another shell):

kill -USR1 $(pgrep ^dd)
% decaffeinate

% Convert a CoffeeScript file to JavaScript:

decaffeinate <path/to/file.coffee>

% Convert a CoffeeScript v2 file to JavaScript:

decaffeinate --use-cs2 <path/to/file.coffee>

% Convert require and module.exports to import and export:

decaffeinate --use-js-modules <path/to/file.coffee>

% Convert a CoffeeScript, allowing named exports:

decaffeinate --loose-js-modules <path/to/file.coffee>
% deluge-console

% Start the interactive console interface:

deluge-console

% Connect to a Deluge daemon instance:

connect <hostname>:<port>

% Add a torrent to the daemon:

add <url|magnet|path/to/file>

% Display information about all torrents:

info

% Display information about a specific torrent:

info <torrent_id>

% Pause a torrent:

pause <torrent_id>

% Resume a torrent:

resume <torrent_id>

% Remove a torrent from the daemon:

rm <torrent_id>
% deluged

% Start the Deluge daemon:

deluged

% Start the Deluge daemon on a specific port:

deluged -p <port>

% Start the Deluge daemon using a specific configuration file:

deluged -c <path/to/configuration_file>

% Start the Deluge daemon and output the log to a file:

deluged -l <path/to/log_file>
% deluge

% Download a torrent:

deluge <url|magnet|path/to/file>

% Download a torrent using a specific configuration file:

deluge -c <path/to/configuration_file> <url|magnet|path/to/file>

% Download a torrent and launch the specified user interface:

deluge -u <gtk|web|console> <url|magnet|path/to/file>

% Download a torrent and output the log to a file:

deluge -l <path/to/log_file> <url|magnet|path/to/file>
% deluser

% Remove a user:

deluser <name>

% Remove a user along with their home directory and mail spool:

deluser -r <name>

% Remove a user from a group:

deluser <name> <group>
% deno

% Run a JavaScript or TypeScript file:

deno <path/to/file.ts>

% Start a REPL (interactive shell):

deno

% Run a file with network access enabled:

deno --allow-net <path/to/file.ts>

% Run a file from a URL:

deno <https://deno.land/std/examples/welcome.ts>

% Install an executable script from a URL:

deno install --allow-net --allow-read <file_server> <https://deno.land/std/http/file_server.ts>
% dep

% Initialize the current directory as the root of a Go project:

dep init

% Install any missing dependencies (Scans Gopkg.toml and your .go files):

dep ensure

% Report the status of the project's dependencies:

dep status

% Add a dependency to the project:

dep ensure -add <package_url>

% Update the locked versions of all dependencies:

dep ensure -update
% detox

% Remove spaces and other undesirable characters from a file's name:

detox <file>

% Show how detox would rename all of the files in a directory tree:

detox --dry-run -r <directory>

% Remove spaces and other undesirable characters from all files in a directory tree:

detox -r <directory>
% dexdump

% Extract classes and methods from an APK file:

dexdump <path/to/file.apk>

% Display header information of DEX files contained in an APK file:

dexdump -f <path/to/file.apk>

% Display the dis-assembled output of executable sections:

dexdump -d <path/to/file.apk>

% Output results to a file:

dexdump -o <path/to/file> <path/to/file.apk>
% dexter

% Create and authenticate a user with Google OIDC:

dexter auth -i <client-id> -s <client-secret>

% Override the default kube config location:

dexter auth -i <client-id> -s <client-secret> --kube-config <sample/config>
% df

% Display all file systems and their disk usage:

df

% Display all file systems and their disk usage in human readable form:

df -h

% Display the file system and its disk usage containing the given file or directory:

df <path/to/file_or_directory>

% Display statistics on the number of free inodes:

df -i
% dhclient

% Get an IP address for the `eth0` interface:

sudo dhclient <eth0>

% Release an IP address for the `eth0` interface:

sudo dhclient -r <eth0>
% dhcpwn

% Flood the network with IP requests:

dhcpwn --interface <network_interface> flood --count <number_of_requests>

% Sniff local DHCP traffic:

dhcpwn --interface <network_interface> sniff
% diff

% Compare files (lists changes to turn `old_file` into `new_file`):

diff <old_file> <new_file>

% Compare files, ignoring white spaces:

diff -w <old_file> <new_file>

% Compare files, showing the differences side by side:

diff -y <old_file> <new_file>

% Compare files, showing the differences in unified format (as used by `git diff`):

diff -u <old_file> <new_file>

% Compare directories recursively (shows names for differing files/directories as well as changes made to files):

diff -r <old_directory> <new_directory>

% Compare directories, only showing the names of files that differ:

diff -rq <old_directory> <new_directory>
% diffstat

% Display changes in a histogram:

diff <file1> <file2> | diffstat

% Display inserted, deleted and modified changes as a table:

diff <file1> <file2> | diffstat -t
% dig

% Lookup the IP(s) associated with a hostname (A records):

dig +short <example.com>

% Lookup the mail server(s) associated with a given domain name (MX record):

dig +short <example.com> MX

% Get all types of records for a given domain name:

dig <example.com> ANY

% Specify an alternate DNS server to query:

dig @<8.8.8.8> <example.com>

% Perform a reverse DNS lookup on an IP address (PTR record):

dig -x <8.8.8.8>

% Find authoritative name servers for the zone and display SOA records:

dig +nssearch <example.com>

% Perform iterative queries and display the entire trace path to resolve a domain name:

dig +trace <example.com>
% dircolors

% Output commands to set LS_COLOR using default colors:

dircolors

% Output commands to set LS_COLOR using colors from a file:

dircolors <file>

% Output commands for Bourne shell:

dircolors --bourne-shell

% Output commands for C shell:

dircolors --c-shell

% View the default colors for file types and extensions:

dircolors --print-data
% dirname

% Calculate the parent directory of a given path:

dirname <path/to/file_or_directory>

% Calculate the parent directory of multiple paths:

dirname <path/to/file_a> <path/to/directory_b>

% Delimit output with a NUL character instead of a newline (useful when combining with `xargs`):

dirname --zero <path/to/directory_a> <path/to/file_b>
% dirs

% Display the directory stack with a space between each entry:

dirs

% Display the directory stack with one entry per line:

dirs -p

% Display only the nth entry in the directory stack, starting at 0:

dirs +<N>

% Clear the directory stack:

dirs -c
% dive

% Analyze a Docker image:

dive <your_image_tag>

% Build an image and start analyzing it:

dive build -t <some_tag>
% docker-compose

% List all running containers:

docker-compose ps

% Create and start all containers in the background using a `docker-compose.yml` file from the current directory:

docker-compose up -d

% Start all containers, rebuild if necessary:

docker-compose up --build

% Start all containers using an alternate compose file:

docker-compose --file <path/to/file> up

% Stop all running containers:

docker-compose stop

% Stop and remove all containers, networks, images, and volumes:

docker-compose down --rmi all --volumes

% Follow logs for all containers:

docker-compose logs --follow
% docker container

% List currently running Docker containers:

docker container ls

% Start one or more stopped containers:

docker container start <container1_name> <container2_name>

% Kill one or more running containers:

docker container kill <container_name>

% Stop one or more running containers:

docker container stop <container_name>

% Pause all processes within one or more containers:

docker container pause <container_name>

% Display detailed information on one or more containers:

docker container inspect <container_name>

% Export a container's filesystem as a tar archive:

docker container export <container_name>

% Create a new image from a container's changes:

docker container commit <container_name>
% docker images

% List all Docker images:

docker images

% List all Docker images including intermediates:

docker images -a

% List the output in quiet mode (only numeric IDs):

docker images -q

% List all Docker images not used by any container:

docker images --filter dangling=true
% docker logs

% Print logs from a container:

docker logs <container_name>

% Print logs and follow them:

docker logs -f <container_name>

% Print last 5 lines:

docker logs <container_name> --tail <5>

% Print logs and append them with timestamps:

docker logs -t <container_name>

% Print logs from a certain point in time of container execution (i.e. 23m, 10s, 2013-01-02T13:23:37):

docker logs <container_name> --until <time>
% docker-machine

% List currently running docker machines:

docker-machine ls

% Create a new docker machine with specific name:

docker-machine create <name>

% Get the status of a machine:

docker-machine status <name>

% Start a machine:

docker-machine start <name>

% Stop a machine:

docker-machine stop <name>

% Inspect information about a machine:

docker-machine inspect <name>
% docker

% List currently running docker containers:

docker ps

% List all docker containers (running and stopped):

docker ps -a

% Start a container from an image, with a custom name:

docker run --name <container_name> <image>

% Start or stop an existing container:

docker <start|stop> <container_name>

% Pull an image from a docker registry:

docker pull <image>

% Open a shell inside of an already running container:

docker exec -it <container_name> <sh>

% Remove a stopped container:

docker rm <container_name>

% Fetch and follow the logs of a container:

docker logs -f <container_name>
% dokku

% List runinng apps:

dokku apps

% Create an app:

dokku apps:create <app_name>

% Remove an app:

dokku apps:destroy <app_name>

% Install plugin:

dokku plugin:install <full_repo_url>

% Link database to an app:

dokku <db>:link <db_name> <app_name>
% dot

% Render an image file and determine output filename based on input filename and selected format:

dot -Tpng -O <path/to/file.dot>

% Create an SVG from DOT file:

dot -Tsvg -o <path/to/out_file.svg> <path/to/file.dot>
% dotnet

% Initialize a new .NET project:

dotnet new <template_short_name>

% Restore nuget packages:

dotnet restore

% Build and execute the .NET project in the current directory:

dotnet run

% Run a packaged dotnet application (only needs the runtime, the rest of the commands require the .NET Core SDK installed):

dotnet <path/to/application.dll>
% doxygen

% Generate a default template configuration file "Doxyfile":

doxygen -g

% Generate a template configuration file:

doxygen -g <path/to/config_file>

% Generate documentation using an existing configuration file:

doxygen <path/to/config_file>
% drill

% Lookup the IP(s) associated with a hostname (A records):

drill <example.com>

% Lookup the mail server(s) associated with a given domain name (MX record):

drill mx <example.com>

% Get all types of records for a given domain name:

drill any <example.com>

% Specify an alternate DNS server to query:

drill <example.com> @<8.8.8.8>

% Perform a reverse DNS lookup on an IP address (PTR record):

drill -x <8.8.8.8>

% Perform DNSSEC trace from root servers down to a domain name:

drill -TD <example.com>

% Show DNSKEY record(s) for a domain name:

drill -s dnskey <example.com>
% drupal

% Install a module:

drupal module:install <module_name>

% Uninstall a module:

drupal module:uninstall <module_name>

% Clear all caches:

drupal cache:rebuild

% View current Drupal installation status:

drupal site:status
% drush

% Enable module "foo":

drush en <foo>

% Uninstall module "foo":

drush pmu <foo>

% Clear all caches:

drush cr

% Clear CSS and JavaScript caches:

drush cc css-js
% du

% List the sizes of a directory and any subdirectories, in the given unit (B/KB/MB):

du -<b|k|m> <path/to/directory>

% List the sizes of a directory and any subdirectories, in human-readable form (i.e. auto-selecting the appropriate unit for each size):

du -h <path/to/directory>

% Show the size of a single directory, in human readable units:

du -sh <path/to/directory>

% List the human-readable sizes of a directory and of all the files and directories within it:

du -ah <path/to/directory>

% List the human-readable sizes of a directory and any subdirectories, up to N levels deep:

du -h --max-depth=N <path/to/directory>

% List the human-readable size of all .jpg files in subdirectories of the current directory, and show a cumulative total at the end:

du -ch */*.jpg
% duplicity

% Backup a directory via FTPS to a remote machine, encrypting it with a password:

FTP_PASSWORD=<ftp_login_password> PASSPHRASE=<encryption_password> duplicity <path/to/source/directory> <ftps://user@hostname/target/directory/path/>

% Backup a directory to Amazon S3, doing a full backup every month:

duplicity --full-if-older-than <1M> --use-new-style s3://<bucket_name[/prefix]>

% Delete versions older than 1 year from a backup stored on a WebDAV share:

FTP_PASSWORD=<webdav_login_password> duplicity remove-older-than <1Y> --force <webdav[s]://user@hostname[:port]/some_dir>

% List the available backups:

duplicity collection-status "file://<absolute/path/to/backup/directory>"

% List the files in a backup stored on a remote machine, via ssh:

duplicity list-current-files --time <YYYY-MM-DD> scp://<user@hostname>/path/to/backup/dir

% Restore a subdirectory from a GnuPG-encrypted local backup to a given location:

PASSPHRASE=<gpg_key_password> duplicity restore --encrypt-key <gpg_key_id> --file-to-restore <relative/path/restoredirectory> file://<absolute/path/to/backup/directory> <path/to/directory/to/restore/to>
% ebook-convert

% Convert an ebook into another format:

ebook-convert <source> <destination>

% Convert Markdown or HTML to ebook with TOC, title and author:

ebook-convert <source> <destination> --level1-toc="//h:h1" --level2-toc="//h:h2" --level3-toc="//h:h3" --title=<title> --authors=<author>
% echo

% Print a text message. Note: quotes are optional:

echo <"Hello World">

% Print a message with environment variables:

echo <"My path is $PATH">

% Print a message without the trailing newline:

echo -n <"Hello World">

% Append a message to the file:

echo <"Hello World"> >> <file.txt>

% Enable interpretation of backslash escapes (special characters):

echo -e <"Column 1\tColumn 2">
% ect

% Compress a file:

ect <filename.png>

% Compress a file with the highest compression level and multithreading:

ect -9 --mt-deflate <filename.png>

% Compress all the files in a directory recursively, keeping the original modification time:

ect -keep -recurse <directory>
% ed

% Start ed, editing an empty document (which can be saved as a new file in the current directory):

ed

% Start ed, editing an empty document, with `:` as a command prompt indicator:

ed -p :

% Start ed editing an existing file (this shows the byte count of the loaded file):

ed -p : <path/to/file>

% Toggle the printing of error explanations. (By default, explanations are not printed and only a `?` appears):

H

% Add text to the current document. Mark completion by entering a period by itself in a new line:

a<Enter><text_to_insert><Enter>.

% Print the entire document (`,` is a shortcut to the range `1,$` which covers the start to the end of the document):

,p

% Write the current document to a new file (the filename can be omitted if `ed` was called with an existing file):

w <filename>

% Quit ed:

q
% electrum

% Create a new wallet:

electrum -w <new_wallet.dat> create

% Restore an existing wallet from seed offline:

electrum -w <recovery_wallet.dat> restore -o

% Create a signed transaction offline:

electrum mktx <recipient> <amount> -f 0.0000001 -F <from> -o

% Display all wallet receiving addresses:

electrum listaddresses -a

% Sign a message:

electrum signmessage <address> <message>

% Verify a message:

electrum verifymessage <address> <signature> <message>

% Connect only to a specific electrum-server instance:

electrum -p socks5:<127.0.0.1>:9050 -s <56ckl5obj37gypcu.onion>:50001:t -1
% elinks

% Start elinks:

elinks

% Quit elinks:

Ctrl + C

% Dump output of webpage to console, colorizing the text with ANSI control codes:

elinks -dump -dump-color-mode <1> <url>
% elm

% Initialize an Elm project, generates an elm.json file:

elm init

% Start interactive Elm shell:

elm repl

% Compile an Elm file, output the result to an index.html file:

elm make <source>

% Compile an Elm file, output the result to a Javascript file:

elm make <source> --output=<destination>.js

% Start local web server that compiles Elm files on page load:

elm reactor

% Install Elm package from https://package.elm-lang.org:

elm install <author>/<package>
% emacsclient

% Open files in an existing Emacs server (using GUI if available):

emacsclient <filename>

% Open file in console mode (without X window):

emacsclient -nw <filename>

% Open a file in an existing emacs frame and return immediately:

emacsclient -n <filename>
% emacs

% Start in console mode (without X window):

emacs -nw

% Open a file:

emacs <path/to/file>

% Save a file:

Ctrl + X, Ctrl + S

% Quit:

Ctrl + X, Ctrl + C

% Open a file at a specified line number:

emacs +<line_number> <path/to/file>
% ember

% Create a new Ember application:

ember new <my_new_app>

% Create a new Ember addon:

ember addon <my_new_addon>

% Build the project:

ember build

% Build the project in production mode:

ember build -prod

% Run the development server:

ember serve

% Run the test suite:

ember test

% Run a blueprint to generate something like a route or component:

ember generate <type> <name>

% Install an ember-cli addon:

ember install <name_of_addon>
% enca

% Detect file(s) encoding according to the system's locale:

enca <file1 file2 ...>

% Detect file(s) encoding specifying a language in the POSIX/C locale format (e.g. zh_CN, en_US):

enca -L <language> <file1 file2 ...>

% Convert file(s) to a specific encoding:

enca -L <language> -x <to_encoding> <file1 file2 ...>

% Create a copy of an existing file using a different encoding:

enca -L <language> -x <to_encoding> < <original_file> > <new_file>
% enscript

% Generate a PostScript file from a text file:

enscript <path/to/input_file> --output=<path/to/output_file>

% Generate a file in a different language than PostScript:

enscript <path/to/input_file> --language=<html|rtf|...> --output=<path/to/output_file>

% Generate a PostScript file with a landscape layout, splitting the page into columns (maximum 9):

enscript <path/to/input_file> --columns=<num> --landscape --output=<path/to/output_file>

% Display available syntax highlighting languages and file formats:

enscript --help-highlight

% Generate a PostScript file with syntax highlighting and color for a specified language:

enscript <path/to/input_file> --color=1 --highlight=<language> --output=<path/to/output_file>
% entr

% Rebuild with `make` if any file in any subdirectory changes:

<ag -l> | entr <make>

% Rebuild and test with `make` if any `.c` source files in the current directory change:

<ls *.c> | entr <'make && make test'>

% Send a `SIGTERM` to any previously spawned ruby subprocesses before executing `ruby main.rb`:

<ls *.rb> | entr -r <ruby main.rb>

% Run a command with the changed file (`/_`) as an argument:

<ls *.sql> | entr <psql -f> /_
% env

% Show the environment:

env

% Run a program. Often used in scripts after the shebang (#!) for looking up the path to the program:

env <program>

% Clear the environment and run a program:

env -i <program>

% Remove variable from the environment and run a program:

env -u <variable> <program>

% Set a variable and run a program:

env <variable>=<value> <program>
% envoy

% Initialise a configuration file:

envoy init <host_name>

% Run a task:

envoy run <task_name>

% Run a task from a specific project:

envoy run --path <path/to/directory> <task_name>

% Run a task and continue on failure:

envoy run --continue <task_name>

% Dump a task as a bash script for inspection:

envoy run --pretend <task_name>

% Connect to the specified server via SSH:

envoy ssh <server_name>
% envsubst

% Replace environment variables in `stdin` and output to `stdout`:

echo '<$HOME>' | envsubst

% Replace environment variables in an input file and output to `stdout`:

envsubst < <path/to/input_file>

% Replace environment variables in an input file and output to a file:

envsubst < <path/to/input_file> > <path/to/output_file>

% Replace environment variables in an input file from a space-separated list:

envsubst '<$USER $SHELL $HOME>' < <path/to/input_file>
% erl

% Compile and run sequential Erlang program as a common script and then exit:

erlc <files> && erl -noshell '<mymodule:myfunction(arguments)>, init:stop().'

% Connect to a running Erlang node:

erl -remsh <nodename>@<hostname> -sname <custom_shortname> -hidden -setcookie <cookie_of_remote_node>

% Tell the Erlang shell to load modules from a directory:

erl -pa <directory_with_beam_files>
% eslint

% Create eslint config:

eslint --init

% Lint on a given set of files:

eslint <filename>.js <filename1>.js

% Fix lint issues:

eslint --fix

% Lint with config:

eslint -c <path/to/config_file> <app/src>
% espeak

% Speak a phrase aloud:

espeak "I like to ride my bike."

% Speak a file aloud:

espeak -f <filename>

% Save output to a WAV audio file, rather than speaking it directly:

espeak -w <filename.wav> "It's GNU plus Linux"

% Use a different voice:

espeak -v <voice>
% eva

% Run the calculator in interactive mode:

eva

% Calculate the result of an expression:

eva "<(1 + 2) * 2 ^ 2>"

% Calculate an expression forcing the number of decimal places to 5:

eva --fix <5> "<5 / 3>"

% Calculate an expression with sine and cosine:

eva "<sin(1) + cos(1)>"
% exa

% List files one per line:

exa --oneline

% List all files, including hidden files:

exa --all

% Long format list (permissions, ownership, size and modification date) of all files:

exa --long --all

% List files with the largest at the top:

exa --reverse --sort=<size>

% Display a tree of files, three levels deep:

exa --long --tree --level=<3>

% List files sorted by modification date (oldest first):

exa --long --sort=<modified>
% exec

% Replace with the specified command using the current environment variables:

exec <command -with -flags>

% Replace with the specified command, clearing environment variables:

exec -c <command -with -flags>

% Replace with the specified command and login using the default shell:

exec -l <command -with -flags>

% Replace with the specified command and change the process name:

exec -a <process_name> <command -with -flags>
% exiftool

% Remove all EXIF metadata from the given files:

exiftool -All= <file1 file2 ...>

% Move the date at which all photos in a directory were taken 1 hour forward:

exiftool "-AllDates+=0:0:0 1:0:0" <path/to/directory>

% Move the date at which all JPEG photos in the current directory were taken 1 day and 2 hours backward:

exiftool "-AllDates-=0:0:1 2:0:0" -ext jpg

% Only change the `DateTimeOriginal` field subtracting 1.5 hours, without keeping backups:

exiftool -DateTimeOriginal-=1.5 -overwrite_original

% Recursively rename all JPEG photos in a directory based on the `DateTimeOriginal` field:

exiftool '-filename<DateTimeOriginal' -d %Y-%m-%d_%H-%M-%S%%lc.%%e <path/to/directory> -r -ext jpg
% exit

% Exit the shell with the exit code of the last command executed:

exit

% Exit the shell with the specified exit code:

exit <exit_code>
% expand

% Convert tabs in each file to spaces, writing to standard output:

expand <file>

% Convert tabs to spaces, reading from standard input:

expand

% Do not convert tabs after non blanks:

expand -i <file>

% Have tabs a certain number of characters apart, not 8:

expand -t=<number> <file>

% Use a comma separated list of explicit tab positions:

expand -t=<1,4,6>
% expr

% Get string length:

expr length <string>

% Evaluate logical or math expression with an operator ('+', '-', '*', '&', '|', etc.). Special symbols should be escaped:

expr <first_argument> <operator> <second_argument>

% Get position of the first character in 'string' that matches 'substring':

echo $(expr index <string> <substring>)

% Extract part of the string:

echo $(expr substr <string> <position_to_start> <number_of_characters>

% Extract part of the string which matches a regular expression:

echo $(expr <string> : '\(<regular_expression>\)')
% f3fix

% Fill a fake flash drive with a single partition that matches its real capacity:

sudo f3fix </dev/device_name>

% Mark the partition as bootable:

sudo f3fix --boot </dev/device_name>

% Specify the filesystem:

sudo f3fix --fs-type=<filesystem_type> </dev/device_name>
% f3probe

% Probe a block device:

sudo f3probe <path/to/block_device>

% Use the minimum about of RAM possible:

sudo f3probe --min-memory <path/to/block_device>

% Time disk operations:

sudo f3probe --time-ops <path/to/block_device>
% f3read

% Validate a device by checking the files in a given directory:

f3read <path/to/mount_point>
% f3write

% Write test files to a given directory, filling the drive:

f3write <path/to/mount_point>

% Limit the write speed:

f3write --max-write-rate=<kb_per_second> <path/to/mount_point>
% factor

% Display the prime-factorization of a number:

factor <number>

% Take the input from `stdin` if no argument is specified:

echo <number> | factor
% false

% Return an exit code of 1:

false
% fastboot

% Unlock the bootloader:

fastboot oem unlock

% Relock the bootloader:

fastboot oem lock

% Reboot the device from fastboot mode into fastboot mode again:

fastboot reboot bootloader

% Flash a given image:

fastboot flash <file.zip>

% Flash a custom recovery image:

fastboot flash recovery <file.img>

% Display connected devices:

fastboot devices
% fd

% Find files matching the given pattern in the current directory:

fd <pattern>

% Find files that begin with "foo":

fd <'^foo'>

% Find files with a specific extension:

fd --extension <txt>

% Find files in a specific directory:

fd <pattern> <path/to/dir>

% Include ignored and hidden files in the search:

fd --hidden --no-ignore <pattern>
% fdroidcl

% Fetch the F-Droid index:

fdroidcl update

% Display info about an app:

fdroidcl show <app_id>

% Download an APK file:

fdroidcl download <app_id>

% Search for an app in the index:

fdroidcl search <search_pattern>

% Install an app on a connected device:

fdroidcl install <app_id>
% fdroid

% Build a specific app:

fdroid build <app_id>

% Build a specific app in a build server VM:

fdroid build <app_id> --server

% Publish the app to the local repository:

fdroid publish <app_id>

% Install the app on every connected device:

fdroid install <app_id>

% Check if the metadata is formatted correctly:

fdroid lint --format <app_id>

% Fix the formatting automatically (if possible):

fdroid rewritemeta <app_id>
% fdupes

% Search a single directory:

fdupes <directory>

% Search multiple directories:

fdupes <directory1> <directory2>

% Search all directories recursively:

fdupes -r <directory>

% Search multiple directories, one recursively:

fdupes <directory1> -R <directory2>
% ffmpeg

% Extract the sound from a video and save it as MP3:

ffmpeg -i <video.mp4> -vn <sound>.mp3

% Convert frames from a video or GIF into individual numbered images:

ffmpeg -i <video.mpg|video.gif> <frame_%d.png>

% Combine numbered images (frame_1.jpg, frame_2.jpg, etc) into a video or GIF:

ffmpeg -i <frame_%d.jpg> -f image2 <video.mpg|video.gif>

% Quickly extract a single frame from a video at time mm:ss and save it as a 128x128 resolution image:

ffmpeg -ss <mm:ss> -i <video.mp4> -frames 1 -s <128x128> -f image2 <image.png>

% Trim a video from a given start time mm:ss to an end time mm2:ss2 (omit the -to flag to trim till the end):

ffmpeg -ss <mm:ss> -to <mm2:ss2> -i <video.mp4> -codec copy <output.mp4>

% Convert AVI video to MP4. AAC Audio @ 128kbit, h264 Video @ CRF 23:

ffmpeg -i <input_video>.avi -codec:audio aac -b:audio 128k -codec:video libx264 -crf 23 <output_video>.mp4

% Remux MKV video to MP4 without re-encoding audio or video streams:

ffmpeg -i <input_video>.mkv -codec copy <output_video>.mp4

% Convert MP4 video to VP9 codec. For the best quality, use a CRF value (recommended range 15-35) and -b:video MUST be 0:

ffmpeg -i <input_video>.mp4 -codec:video libvpx-vp9 -crf <30> -b:video 0 -codec:audio libopus -vbr on -threads <number_of_threads> <output_video>.webm
% ffprobe

% Display all available stream info for a media file:

ffprobe -v error -show_entries <input.mp4>

% Display media duration:

ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 <input.mp4>

% Display the frame rate of a video:

ffprobe -v error -select_streams v:0 -show_entries stream=avg_frame_rate -of default=noprint_wrappers=1:nokey=1 <input.mp4>

% Display the width or height of a video:

ffprobe -v error -select_streams v:0 -show_entries stream=<width|height> -of default=noprint_wrappers=1:nokey=1 <input.mp4>

% Display the average bit rate of a video:

ffprobe -v error -select_streams v:0 -show_entries stream=bit_rate -of default=noprint_wrappers=1:nokey=1 <input.mp4>
% ffsend

% Upload a file:

ffsend upload <file>

% Download a file:

ffsend download <url>

% Upload a file with password:

ffsend upload <file> -p <password>

% Download a file protected by password:

ffsend download <file> -p <password>

% Upload a file and allow 4 downloads:

ffsend upload <file> -d <4>
% fg

% Bring most recently suspended background job to foreground:

fg

% Bring a specific job to foreground:

fg <job_id>
% figlet

% Generate by directly inputting text:

figlet <input_text>

% Use a custom font file:

figlet <input_text> -f <font_file_name>

% Pipe command output through figlet:

<command> | figlet

% Show available figlet fonts:

showfigfonts <optional_string_to_display>
% find

% Find files by extension:

find <root_path> -name '<*.ext>'

% Find files by matching multiple patterns:

find <root_path> -name '<*pattern_1*>' -or -name '<*pattern_2*>'

% Find directories matching a given name, in case-insensitive mode:

find <root_path> -type d -iname <*lib*>

% Find files matching a path pattern:

find <root_path> -path '<**/lib/**/*.ext>'

% Find files matching a given pattern, excluding specific paths:

find <root_path> -name '<*.py>' -not -path '<*/site-packages/*>'

% Find files matching a given size range:

find <root_path> -size <+500k> -size <-10M>

% Run a command for each file (use `{}` within the command to access the filename):

find <root_path> -name '<*.ext>' -exec <wc -l {} >\;

% Find files modified in the last 7 days, and delete them:

find <root_path> -mtime <-7> -delete
% finger

% Display information about currently logged in users:

finger

% Display information about a specific user:

finger <username>

% Display the user's login name, real name, terminal name, and other information:

finger -s

% Produce multi-line output format displaying same information as `-s` as well as user's home directory, home phone number, login shell, mail status, etc.:

finger -l

% Prevent matching against user's names and only use login names:

finger -m
% fin

% Start the project in the current directory:

fin project start

% Stop the project in the current directory:

fin project stop

% Open a shell into a specific container:

fin bash <container_name>

% Display logs of a specific container:

fin logs <container_name>

% Display logs of a specific container and follow the log:

fin logs -f <container_name>
% firefox

% Launch Firefox and open a web page:

firefox <https://www.duckduckgo.com>

% Open a new window:

firefox --new-window <https://www.duckduckgo.com>

% Open a private (incognito) window:

firefox --private-window

% Search for "wikipedia" using the default search engine:

firefox --search "<wikipedia>"

% Launch Firefox in safe mode, with all extensions disabled:

firefox --safe-mode

% Take a screenshot of a web page in headless mode:

firefox --headless --screenshot <path/to/output_file.png> <https://example.com/>

% Use a specific profile to allow multiple separate instances of Firefox to run at once:

firefox --profile <path/to/directory> <https://example.com/>

% Set Firefox as the default browser:

firefox --setDefaultBrowser
% fisher

% Install one or more plugins:

fisher <plugin1> <plugin2>

% Install a plugin from a GitHub gist:

fisher <gist_url>

% Edit 'fishfile' by hand with your favorite editor and install multiple plugins:

<editor> ~/.config/fish/fishfile; fisher

% List installed plugins:

fisher ls

% Show available plugins:

fisher ls-remote

% Update plugins:

fisher up

% Remove one or more plugins:

fisher rm <plugin1> <plugin2>
% fish

% Start interactive shell:

fish

% Execute a command:

fish -c "<command>"

% Run commands from a file:

fish <file.fish>

% Check a file for syntax errors:

fish --no-execute <file.fish>

% Display version information and exit:

fish --version

% Set and export environmental variables that persist across restarts:

set -Ux <variable_name> <variable_value>
% fkill

% Run without arguments to use the interactive interface:

fkill

% Kill the process by pid, name or port:

fkill <pid|name|:port>
% flac

% Encode a wav file to flac (this will create a flac file in the same location as the wav file):

flac <path/to/file.wav>

% Encode a wav file to flac, specifying the output file:

flac -o <path/to/output.flac> <path/to/file.wav>

% Decode a flac file to wav, specifying the output file:

flac -d -o <path/to/output.wav> <path/to/file.flac>

% Test a flac file for the correct encoding:

flac -t <path/to/file.flac>
% flask

% Run a development server:

flask run

% Show the routes for the app:

flask routes

% Run a Python interactive shell in the app's context:

flask shell
% flex

% Generate an analyser from a flex file:

flex <analyser.l>

% Specify the output file:

flex <analyser.l> --outfile <analyser.c>

% Compile a C file generated by flex:

cc <path/to/lex.yy.c> --output <executable>
% fls

% Build a recursive fls list over a device, output paths will start with C:

fls -r -m <C:> </dev/loop1p1>

% Analyse a single partition, providing the sector offset at which the file system starts in the image:

fls -r -m <C:> -o <sector> <path/to/image_file>

% Analyse a single partition, providing the timezone of the original system:

fls -r -m <C:> -z <timezone> </dev/loop1p1>
% flutter

% Check the Flutter version:

flutter --version

% Display general help:

flutter help

% Display help about a specific command:

flutter help <command>

% Execute a Flutter command:

flutter <command>

% Show information about the installed tooling:

flutter doctor
% fly

% Authenticate with and save concourse target:

fly --target <target_name> login --team-name <team_name> -c <https://ci.example.com>

% List targets:

fly targets

% List pipelines:

fly -t <target_name> pipelines

% Upload or update a pipeline:

fly -t <target_name> set-pipeline --config <pipeline.yml> --pipeline <pipeline_name>

% Unpause pipeline:

fly -t <target_name> unpause-pipeline --pipeline <pipeline_name>

% Show pipeline configuration:

fly -t <target_name> get-pipeline --pipeline <pipeline_name>

% Update local copy of fly:

fly -t <target_name> sync

% Destroy pipeline:

fly -t <target_name> destroy-pipeline --pipeline <pipeline_name>
% fmt

% Reformat a file:

fmt <path/to/file>

% Reformat a file producing output lines of (at most) `n` characters:

fmt -w <n> <path/to/file>

% Reformat a file without joining lines shorter than the given width together:

fmt -s <path/to/file>

% Reformat a file with uniform spacing (1 space between words and 2 spaces between paragraphs):

fmt -u <path/to/file>
% fnm

% Install a specific version of Node.js:

fnm install <node_version>

% List all available Node.js versions and highlight the default one:

fnm ls

% Use a specific version of Node.js in the current shell:

fnm use <node_version>

% Set the default Node.js version:

fnm default <node_version>

% Uninstall a given Node.js version:

fnm uninstall <node_version>
% fold

% Wrap each line to default width (80 characters):

fold <file>

% Wrap each line to width "30":

fold -w30 <file>

% Wrap each line to width "5" and break the line at spaces (puts each space separated word in a new line, words with length > 5 are wrapped):

fold -w5 -s <file>
% forever

% Start running a file forever (as a daemon):

forever <script>

% List running "forever" processes (along with IDs and other details of "forever" processes):

forever list

% Stop a running "forever" process:

forever stop <ID|pid|script>
% for

% Perform a command with different arguments:

for argument in 1 2 3; do <command $argument>; done

% Perform a command in every directory:

for d in *; do (cd $d; <command>); done
% fortune

% Print a quotation:

fortune

% Print an offensive quotation:

fortune -o

% Print a long quotation:

fortune -l

% Print a short quotation:

fortune -s

% List the available quotation database files:

fortune -f

% Print a quotation from one of the database files listed by `fortune -f`:

fortune <filename>
% fossa

% Initialize a `.fossa.yml` configuration file:

fossa init

% Run a default project build:

fossa build

% Analyze built dependencies:

fossa analyze

% Generate reports:

fossa report

% Test current revision against the FOSSA scan status and exit with errors if issues are found:

fossa test
% fping

% List alive hosts within a subnet generated from a netmask:

fping -a -g 192.168.1.0/24

% List alive hosts within a subnet generated from an IP range:

fping -a -g 192.168.1.1 192.168.1.254

% List unreachable hosts within a subnet generated from a netmask:

fping -u -g 192.168.1.0/24
% fselect

% Select full path and size from temporary or config files in a given directory:

fselect size, path from <path/to/directory> where name = <'*.cfg'> or name = <'*.tmp'>

% Find square images:

fselect path from <path/to/directory> where width = height

% Find old-school rap 320kbps MP3 files:

fselect path from <path/to/directory> where genre = <Rap> and bitrate = <320> and mp3_year lt <2000>

% Select only the first 5 results and output as JSON:

fselect size, path from <path/to/directory> limit <5> into json

% Use SQL aggregate functions to calculate minimum, maximum and average size of files in a directory:

fselect "<MIN(size), MAX(size), AVG(size), SUM(size), COUNT(*)> from <path/to/directory>"
% fswatch

% Run a bash command on file creation, update or deletion:

fswatch <path/to/file> | xargs -n 1 <bash_command>

% Watch one or more files and/or directories:

fswatch <path/to/file> <path/to/directory> <path/to/another_directory/**/*.js> | xargs -n 1 <bash_command>

% Print the absolute paths of the changed files:

fswatch <path/to/directory> | xargs -n 1 -I {} echo {}

% Filter by event type, eg. Updated, Deleted or Created:

fswatch --event <Updated> <path/to/directory> | xargs -n 1 <bash_command>
% fswebcam

% Take a picture:

fswebcam <filename>

% Take a picture with custom resolution:

fswebcam -r <width>x<height> <filename>

% Take a picture from selected device(Default is /dev/video0):

fswebcam -d <device> <filename>

% Take a picture with timestamp(timestamp string is formatted by strftime):

fswebcam --timestamp <timestamp> <filename>
% ftp

% Connect to an FTP server:

ftp <ftp.example.com>

% Switch to binary transfer mode (graphics, compressed files, etc):

binary

% Transfer multiple files without prompting for confirmation on every file:

prompt off

% Download multiple files (glob expression):

mget <*.png>

% Upload multiple files (glob expression):

mput <*.zip>

% Delete multiple files on the remote server:

mdelete <*.txt>

% Rename a file on the remote server:

rename <original_filename> <new_filename>
% fuck

% Set the `fuck` alias to `thefuck` tool:

eval "$(thefuck --alias)"

% Try to match a rule for the previous command:

fuck
% fzf

% Start finder on all files from arbitrary locations:

find <path/to/search> -type f | fzf

% Start finder on running processes:

ps aux | fzf

% Select multiple files with `Shift + Tab` and write to a file:

find <path/to/search_files> -type f | fzf -m > <filename>

% Start finder with a given query:

fzf -q "<query>"

% Start finder on entries that start with core and end with either go, rb, or py:

fzf -q "^core go$ | rb$ | py$"

% Start finder on entries that not match pyc and match exactly travis:

fzf -q "!pyc 'travis"
% gatsby

% Create a new site:

gatsby new <site_name>

% Create a new site with a Gatsby 'starter':

gatsby new <site_name> <url_of_starter_github_repo>

% Start a live-reloading local development server:

gatsby develop

% Perform a production build and generate static HTML:

gatsby build

% Start a local server which serves the production build:

gatsby serve
% gcalcli

% List your events for all your calendars over the next 7 days:

gcalcli agenda

% Show events starting from or between specific dates (also takes relative dates e.g. "tomorrow"):

gcalcli agenda <mm/dd> [<mm/dd>]

% List events from a specific calendar:

gcalcli --calendar <calendar_name> agenda

% Display an ASCII calendar of events by week:

gcalcli calw

% Display an ASCII calendar of events for a month:

gcalcli calm

% Quick-add an event to your calendar:

gcalcli --calendar <calendar_name> quick "<mm/dd> <HH:MM> <event_name>"

% Add an event to calendar. Triggers interactive prompt:

gcalcli --calendar "<calendar_name>" add
% gcal

% Display calendar for the current month:

gcal

% Display calendar for the month of February of the year 2010:

gcal <2> <2010>

% Provide calendar sheet with week numbers:

gcal --with-week-number

% Change starting day of week to 1st day of the week (Monday):

gcal --starting-day=<1>

% Display the previous, current and next month surrounding today:

gcal .
% gcc

% Compile multiple source files into executable:

gcc <source1.c> <source2.c> -o <executable>

% Allow warnings, debug symbols in output:

gcc <source.c> -Wall -Og -o <executable>

% Include libraries from a different path:

gcc <source.c> -o <executable> -I<header_path> -L<library_path> -l<library_name>

% Compile source code into Assembler instructions:

gcc -S <source.c>

% Compile source code without linking:

gcc -c <source.c>
% gcloud

% List all properties in one's active configuration:

gcloud config list

% Login to Google account:

gcloud auth login

% Set the active project:

gcloud config set project <project_name>

% SSH into a virtual machine instance:

gcloud compute ssh <user>@<instance> 

% Display all Google Compute Engine instances in a project. Instances from all zones are listed by default:

gcloud compute instances list

% Update a kubeconfig file with the appropriate credentials to point kubectl to a specific cluster in Google Kubernetes Engine:

gcloud container clusters get-credentials <cluster_name>

% Update all gcloud CLI components:

gcloud components update

% Show help for a given command:

gcloud help <command>
% gdb

% Debug an executable:

gdb <executable>

% Attach a process to gdb:

gdb -p <procID>

% Debug with a core file:

gdb -c <core> <executable>

% Execute given GDB commands upon start:

gdb -ex "<commands>" <executable>

% Start gdb and pass arguments:

gdb --args <executable> <argument1> <argument2>
% gdrive

% Upload a local path to the parent folder with the specified id:

gdrive upload -p <id> <path/to/file_or_folder>

% Download file or directory by id to current directory:

gdrive download <id>

% Download to a given local path by its id:

gdrive download --path <path/to/folder> <id>

% Create a new revision of an id using a given file or folder:

gdrive update <id> <path/to/file_or_folder>
% gem

% Search for remote gem(s):

gem search <regexp>

% Search for remote gem(s) and show all available versions:

gem search <regexp> --all

% Install latest version of a gem:

gem install <gemname>

% Install specific version of a gem:

gem install <gemname> --version <1.0.0>

% Update a gem:

gem update <gemname>

% List all local gems:

gem list

% Uninstall a gem:

gem uninstall <gemname>

% Uninstall specific version of a gem:

gem uninstall <gemname> --version <1.0.0>
% geth

% Connect to the main Ethereum network and automatically download the full node:

geth

% Connect to the Ropsten test network:

geth --testnet

% Create a new account:

geth account new

% Enable mining:

geth --mine
% ghc

% Find and compile all modules in the current directory:

ghc Main

% Compile a single file:

ghc <file.hs>

% Compile using extra optimization:

ghc -O <file.hs>

% Stop compilation after generating object files (.o):

ghc -c <file.hs>

% Run Haskell interactive interpreter (REPL):

ghci

% Evaluate a single expression:

ghc -e <expression>
% gh

% Create a pull request:

gh pr create

% View a pull request in the browser:

gh pr view <pr_number>

% Check out pull requests locally:

gh pr checkout <pr_number>

% Check the status of your pull requests:

gh pr status

% Create a new issue:

gh issue create

% View and filter repository’s open issues:

gh issue list

% View an issue in the browser:

gh issue view <issue_number>
% gibo

% List available boilerplates:

gibo list

% Write a boilerplate to `stdout`:

gibo dump <boilerplate>

% Write a boilerplate to .gitignore:

gibo dump <boilerplate> >><.gitignore>

% Search for boilerplates containing a given string:

gibo search <string>

% Update available local boilerplates:

gibo update
% gifsicle

% Optimise a GIF:

gifsicle --batch --optimize=3 <amin.gif>

% Make a GIF animation with gifsicle:

gifsicle --delay=<10> --loop *.gif > <anim.gif>

% Extract frames from an animation:

gifsicle <anim.gif> '#0' > <firstframe.gif>

% You can also edit animations by replacing, deleting, or inserting frames:

gifsicle -b <anim.gif> --replace '#0' <new.gif>
% gist

% Login in gist on this computer:

gist --login

% Create a gist from any number of text files:

gist <file.txt> <file2.txt>

% Create a private gist with a description:

gist -p -d <"A meaningful description"> <file.txt> 

% Read contents from `stdin` and create a gist from it:

<echo "hello world"> | gist

% List your public and private gists:

gist -l

% List all gists for the currently logged in user:

gist -l <username>

% Use the id from the gist URL to modify or include a file:

gist -u <GIST_ID> <file.txt>
% git add

% Add a file to the index:

git add <path/to/file>

% Add all files (tracked and untracked):

git add -A

% Only add already tracked files:

git add -u

% Also add ignored files:

git add -f

% Interactively stage parts of files:

git add -p

% Interactively stage parts of a given file:

git add -p <path/to/file>
% git am

% Apply a patch file:

git am <path/to/file.patch>

% Abort the process of applying a patch file:

git am --abort

% Apply as much of a patch file as possible, saving failed hunks to reject files:

git am --reject <path/to/file.patch>
% git bisect

% Start a bisect session on a commit range bounded by a known buggy commit, and a known clean (typically older) one:

git bisect start <bad_commit> <good_commit>

% For each commit that `git bisect` selects, mark it as "bad" or "good" after testing it for the issue:

git bisect <good|bad>

% After `git bisect` pinpoints the faulty commit, end the bisect session and return to the previous branch:

git bisect reset

% Skip a commit during a bisect (e.g. one that fails the tests due to a different issue):

git bisect skip
% git blame

% Print file with author name and commit hash on each line:

git blame <file>

% Print file with author email and commit hash on each line:

git blame -e <file>
% git branch

% List local branches. The current branch is highlighted by `*`:

git branch

% List all branches (local and remote):

git branch -a

% Show the name of the current branch:

git branch --show-current

% Create new branch based on the current commit:

git branch <branch_name>

% Create new branch based on a specific commit:

git branch <branch_name> <commit_hash>

% Rename a branch (must not have it checked out to do this):

git branch -m <old_branch_name> <new_branch_name>

% Delete a local branch (must not have it checked out to do this):

git branch -d <branch_name>
% git check-ignore

% Check whether a file or directory is ignored:

git check-ignore <path/to/file_or_directory>

% Check whether multiple files or directories are ignored:

git check-ignore <path/to/file> <path/to/directory>

% Use pathnames, one per line, from `stdin`:

git check-ignore --stdin < <path/to/file_list>

% Do not check the index (used to debug why paths were tracked and not ignored):

git check-ignore --no-index <path/to/files_or_directories>

% Include details about the matching pattern for each path:

git check-ignore --verbose <path/to/files_or_directories>
% git checkout

% Create and switch to a new branch:

git checkout -b <branch_name>

% Create and switch to a new branch based on a specific reference (branch, remote/branch, tag are examples of valid references):

git checkout -b <branch_name> <reference>

% Switch to an existing local branch:

git checkout <branch_name>

% Switch to the previously checked out branch:

git checkout -

% Switch to an existing remote branch:

git checkout --track <remote_name>/<branch_name>

% Discard all unstaged changes in the current directory (see `git reset` for more undo-like commands):

git checkout .

% Discard unstaged changes to a given file:

git checkout <file_name>

% Replace a file in the current directory with the version of it committed in a given branch:

git checkout <branch_name> -- <file_name>
% git cherry-pick

% Apply a commit to the current branch:

git cherry-pick <commit>

% Apply a range of commits to the current branch (see also `git rebase --onto`):

git cherry-pick <start_commit>~..<end_commit>

% Apply multiple (non-sequential) commits to the current branch:

git cherry-pick <commit_1> <commit_2>

% Add the changes of a commit to the working directory, without creating a commit:

git cherry-pick -n <commit>
% git clean

% Delete files that are not tracked by git:

git clean

% Interactively delete files that are not tracked by git:

git clean -i

% Show what files would be deleted without actually deleting them:

git clean --dry-run

% Forcefully delete files that are not tracked by git:

git clean -f

% Forcefully delete directories that are not tracked by git:

git clean -fd

% Delete untracked files, including ignored files in `.gitignore` and `.git/info/exclude`:

git clean -x
% git clone

% Clone an existing repository:

git clone <remote_repository_location>

% Clone an existing repository and its submodules:

git clone --recursive <remote_repository_location>

% Clone a local repository:

git clone -l <path/to/local/repository>

% Clone quietly:

git clone -q <remote_repository_location>

% Clone an existing repository only fetching the 10 most recent commits on the default branch (useful to save time):

git clone --depth <10> <remote_repository_location>
% git commit

% Commit staged files to the repository with a message:

git commit -m <message>

% Auto stage all modified files and commit with a message:

git commit -a -m <message>

% Replace the last commit with currently staged changes:

git commit --amend

% Commit only specific (already staged) files:

git commit <path/to/my/file1> <path/to/my/file2>
% git config

% List only local configuration entries (stored in `.git/config` in the current repository):

git config --list --local

% List only global configuration entries (stored in `~/.gitconfig`):

git config --list --global

% List all configuration entries that have been defined either locally or globally:

git config --list

% Get the value of a given configuration entry:

git config alias.unstage

% Set the global value of a given configuration entry:

git config --global alias.unstage "reset HEAD --"

% Revert a global configuration entry to its default value:

git config --global --unset alias.unstage
% git diff

% Show unstaged, uncommitted changes:

git diff

% Show all uncommitted changes (including staged ones):

git diff HEAD

% Show only staged (added, but not yet committed) changes:

git diff --staged

% Show changes from all commits since a given date/time (a date expression, e.g. "1 week 2 days" or an ISO date):

git diff 'HEAD@{3 months|weeks|days|hours|seconds ago}'

% Show only names of changed files since a given commit:

git diff --name-only <commit>

% Output a summary of file creations, renames and mode changes since a given commit:

git diff --summary <commit>

% Create a patch file:

git diff > <target_file>.patch

% Compare a single file between two branches or commits:

git diff <branch_1>..<branch_2> [--] <path/to/file>

% Compare different files from the current branch to other branch:

git diff <branch>:<path/to/file2> <path/to/file>
% git fetch

% Fetch the latest changes from the default remote upstream repository (if set):

git fetch

% Fetch new branches from a specific remote upstream repository:

git fetch <remote_name>

% Fetch the latest changes from all remote upstream repositories:

git fetch --all

% Also fetch tags from the remote upstream repository:

git fetch --tags

% Delete local references to remote branches that have been deleted upstream:

git fetch --prune
% git flow

% Initialize it inside an existing git repository:

git flow init

% Start developing on a feature branch based on `develop`:

git flow feature start <feature>

% Finish development on a feature branch, merging it into the `develop` branch and deleting it:

git flow feature finish <feature>

% Publish a feature to the remote server:

git flow feature publish <feature>

% Get a feature published by another user:

git flow feature pull origin <feature>
% git format-patch

% Create an auto-named .patch file for all the unpushed commits:

git format-patch <origin>

% Write a .patch file for all the commits between 2 revisions to `stdout`:

git format-patch <revision_1>..<revision_2>

% Write a .patch file for the 3 latest commits:

git format-patch -<3>
% git gc

% Optimise the repository:

git gc

% Aggressively optimise, takes more time:

git gc --aggressive

% Do not prune loose objects (prunes by default):

git gc --no-prune

% Suppress all output:

git gc --quiet

% View full usage:

git gc --help
% git-grep

% Search for a string in tracked files:

git grep <search_string>

% Search for a string in files matching a pattern in tracked files:

git grep <search_string> -- <file_glob_pattern>

% Search for a string in tracked files, including submodules:

git grep --recurse-submodules <search_string>

% Search for a string at a specific point in history:

git grep <search_string> <HEAD~2>

% Search for a string across all branches:

git grep <search_string> $(git rev-list --all)
% github-label-sync

% Synchronise labels using a local `labels.json` file:

github-label-sync --access-token <token> <repository_name>

% Synchronise labels using a specific labels JSON file:

github-label-sync --access-token <token> --labels <url|path/to/json_file> <repository_name>

% Perform a dry run instead of actually synchronising labels:

github-label-sync --access-token <token> --dry-run <repository_name>

% Keep labels that aren't in `labels.json`:

github-label-sync --access-token <token> --allow-added-labels <repository_name>

% Synchronise using the `GITHUB_ACCESS_TOKEN` environment variable:

github-label-sync <repository_name>
% git-imerge

% Start imerge-based rebase (checkout the branch to be rebased, first):

git imerge rebase <branch_to_rebase_onto>

% Start imerge-based merge (checkout the branch to merge into, first):

git imerge merge <branch_to_be_merged>

% Show ASCII diagram of in-progress merge or rebase:

git imerge diagram

% Continue imerge operation after resolving conflicts (`git add` the conflicted files, first):

git imerge continue --no-edit

% Wrap up imerge operation, after all conflicts are resolved:

git imerge finish

% Abort imerge operation, and return to the previous branch:

git-imerge remove && git checkout <previous_branch>
% git init

% Initialize a new local repository:

git init

% Initialize a barebones repository, suitable for use as a remote over ssh:

git init --bare
% gitk

% Show the repository browser for the current git repository:

gitk

% Show repository browser for a specific file or directory:

gitk <path/to/file_or_directory>

% Show commits made since 1 week ago:

gitk --since=<"1 week ago">

% Show commits older than 1/1/2016:

gitk --until=<"1/1/2015">

% Show at most 100 changes in all branches:

 gitk --max-count=<100> --all
% gitlab

% Create a new project:

gitlab create_project <project_name>

% Get info about a specific commit:

gitlab commit <project_name> <commit_hash>

% Get info about jobs in a CI pipeline:

gitlab pipeline_jobs <project_name> <pipeline_id>

% Start a specific CI job:

gitlab job_play <project_name> <job_id>
% git lfs

% Initialise Git LFS:

git lfs install

% Track files that match a glob:

git lfs track '<*.bin>'

% Change the Git LFS endpoint URL (useful if the LFS server is separate from the Git server):

git config -f .lfsconfig lfs.url <lfs_endpoint_url>

% List tracked patterns:

git lfs track

% List tracked files that have been commited:

git lfs ls-files

% Push all Git LFS objects to the remote server (useful if errors are encountered):

git lfs push --all <remote_name> <branch_name>

% Fetch all Git LFS objects:

git lfs fetch

% Checkout all Git LFS objects:

git lfs checkout
% git log

% Show the sequence of commits starting from the current one, in reverse chronological order:

git log

% Show the history of a particular file or directory, including differences:

git log -p <path/to/file_or_directory>

% Show only the first line of each commit message:

git log --oneline

% Show an overview of which file(s) changed in each commit:

git log --stat

% Show a graph of commits in the current branch:

git log --graph

% Show a graph of all commits, tags and branches in the entire repo:

git log --oneline --decorate --all --graph

% Show only commits whose messages include a given string (case-insensitively):

git log -i --grep <search_string>
% git ls-tree

% List the contents of the tree on a branch:

git ls-tree <branch_name>

% List the contents of the tree on a commit, recursing into subtrees:

git ls-tree -r <commit_hash>

% List only the filenames of the tree on a commit:

git ls-tree --name-only <commit_hash>
% git

% Check the Git version:

git --version

% Call general help:

git --help

% Call help on a command:

git help <command>

% Execute Git command:

git <command>
% git merge

% Merge a branch into your current branch:

git merge <branch_name>

% Edit the merge message:

git merge -e <branch_name>

% Merge a branch and create a merge commit:

git merge --no-ff <branch_name>

% Abort a merge in case of conflicts:

git merge --abort
% git mv

% Move file inside the repo and add the movement to the next commit:

git mv <path/to/file> <new/path/to/file>

% Rename file and add renaming to the next commit:

git mv <filename> <new_filename>

% Overwrite the file in the target path if it exists:

git mv --force <file> <target>
% git pr

% Check out a specific pull request:

git pr <pr_number>

% Check out a pull request for a specific remote:

git pr <pr_number> <remote>

% Check out a pull request from its URL:

git pr <url>

% Clean up old pull request branches:

git pr clean
% git pull

% Download changes from default remote repository and merge it:

git pull

% Download changes from default remote repository and use fast forward:

git pull --rebase

% Download changes from given remote repository and branch, then merge them into HEAD:

git pull <remote_name> <branch>
% git push

% Send local changes in the current branch to its remote counterpart:

git push

% Send local changes in a given branch to its remote counterpart:

git push <remote_name> <local_branch>

% Publish the current branch to a remote repository, setting the remote branch name:

git push <remote_name> -u <remote_branch>

% Send changes on all local branches to their counterparts in a given remote repository:

git push --all <remote_name>

% Delete a branch in a remote repository:

git push <remote_name> --delete <remote_branch>

% Remove remote branches that don't have a local counterpart:

git push --prune <remote_name>

% Publish tags that aren't yet in the remote repository:

git push --tags
% git rebase

% Rebase the current branch on top of the master branch:

git rebase <master>

% Start an interactive rebase, which allows the commits to be reordered, omitted, combined or modified:

git rebase -i <target_base_branch_or_commit_hash>

% Continue a rebase that was interrupted by a merge failure, after editing conflicting files:

git rebase --continue

% Continue a rebase that was paused due to merge conflicts, by skipping the conflicted commit:

git rebase --skip

% Abort a rebase in progress (e.g. if it is interrupted by a merge conflict):

git rebase --abort

% Move part of the current branch onto a new base, providing the old base to start from:

git rebase --onto <new_base> <old_base>

% Reapply the last 5 commits in-place, stopping to allow them to be reordered, omitted, combined or modified:

git rebase -i <HEAD~5>

% Auto-resolve any conflicts by favoring the working branch version (`theirs` keyword has reversed meaning in this case):

git rebase -X theirs <master>
% git reflog

% Show the reflog for HEAD:

git reflog

% Show the reflog for a given branch:

git reflog <branch_name>

% Show only the 5 latest entries in the reflog:

git reflog -n <5>
% git remote

% Show a list of existing remotes, their names and URL:

git remote -v

% Add a remote:

git remote add <remote_name> <remote_url>

% Change the URL of a remote (use `--add` to keep the existing URL):

git remote set-url <remote_name> <new_url>

% Remove a remote:

git remote remove <remote_name>

% Rename a remote:

git remote rename <old_name> <new_name>
% git reset

% Unstage everything:

git reset

% Unstage specific file(s):

git reset <path/to/file(s)>

% Unstage portions of a file:

git reset -p <path/to/file>

% Undo the last commit, keeping its changes (and any further uncommitted changes) in the filesystem:

git reset HEAD~

% Undo the last two commits, adding their changes to the index, i.e. staged for commit:

git reset --soft HEAD~2

% Discard any uncommitted changes, staged or not (for only unstaged changes, use `git checkout`):

git reset --hard

% Reset the repository to a given commit, discarding committed, staged and uncommitted changes since then:

git reset --hard <commit>
% git restore

% Restore a deleted file from the contents of the current commit (HEAD):

git restore <path/to/file>

% Restore a file to a version from a different commit:

git restore --source <commit> <path/to/file>

% Undo any uncommitted changes to tracked files, reverting to the current HEAD:

git restore .
% git revert

% Revert the most recent commit:

git revert <@>

% Revert the 5th last commit:

git revert HEAD~<4>

% Revert multiple commits:

git revert <master~5..master~2>

% Don't create new commits, just change the working tree:

git revert -n <0c01a9..9a1743>
% git rev-list

% List all commits on the current branch:

git rev-list <HEAD>

% List commits more recent than a specific date, on a specific branch:

git rev-list --since=<'2019-12-01 00:00:00'> <master>

% List all merge commits on a specific commit:

git rev-list --merges <commit>
% git rev-parse

% Get the commit hash of a branch:

git rev-parse <branch_name>

% Get the current branch name:

git rev-parse --abbrev-ref <HEAD>

% Get the absolute path to the root directory:

git rev-parse --show-toplevel
% git rm

% Remove file from repository index and filesystem:

git rm <file>

% Remove directory:

git rm -r <directory>

% Remove file from repository index but keep it untouched locally:

git rm --cached <file>
% git shortlog

% View a summary of all the commits made, grouped alphabetically by author name:

git shortlog

% View a summary of all the commits made, sorted by the number of commits made:

git shortlog -n

% View a summary of all the commits made, grouped by the commiter identities (name and email):

git shortlog -c

% View a summary of the last 5 commits (i.e. specify a revision range):

git shortlog HEAD~<5>..HEAD

% View all users, emails and the number of commits in the current branch:

git shortlog -sne

% View all users, emails and the number of commits in all branches:

git shortlog -sne --all
% git show

% Show information about the latest commit (hash, message, changes, and other metadata):

git show

% Show information about a given commit:

git show <commit>

% Show information about the commit associated with a given tag:

git show <tag>

% Show information about the 3rd commit from the tip of a branch:

git show <branch>~<3>

% Show a commit's message in a single line, suppressing the diff output:

git show --oneline -s <commit>

% Show only the list of the files changed in a commit:

git show --stat <commit>

% Show the contents of a file as it was at a given revision (e.g. branch, tag or commit):

git show <revision>:<path/to/file>
% git sizer

% Report only statistics that have a level of concern greater than 0:

git sizer

% Report all statistics:

git sizer -v

% See additional options:

git sizer -h
% gitsome

% Enter the gitsome shell (optional), to enable autocompletion and interactive help for git (and gh) commands:

gitsome

% Setup GitHub integration with the current account:

gh configure

% List notifications for the current account (as would be seen in https://github.com/notifications):

gh notifications

% List the current account's starred repos, filtered by a given search string:

gh starred "<python 3>"

% View the recent activity feed of a given GitHub repository:

gh feed <tldr-pages/tldr>

% View the recent activity feed for a given GitHub user, using the default pager (e.g. `less`):

gh feed <torvalds> -p
% git stash

% Stash current changes, except new (untracked) files:

git stash [push -m <optional_stash_message>]

% Stash current changes, including new (untracked) files:

git stash -u

% Interactively select parts of changed files for stashing:

git stash -p

% List all stashes (shows stash name, related branch and message):

git stash list

% Apply a stash (default is the latest, named stash@{0}):

git stash apply <optional_stash_name_or_commit>

% Apply a stash (default is stash@{0}), and remove it from the stash list if applying doesn't cause conflicts:

git stash pop <optional_stash_name>

% Drop a stash (default is stash@{0}):

git stash drop <optional_stash_name>

% Drop all stashes:

git stash clear
% git status

% Show changed files which are not yet added for commit:

git status

% Give output in [s]hort format:

git status -s

% Don't show untracked files in the output:

git status --untracked-files=no

% Show output in [s]hort format along with [b]ranch info:

git status -sb
% git submodule

% Install a repository's specified submodules:

git submodule update --init --recursive

% Add a git repository as a submodule:

git submodule add <repository_url>

% Add a git repository as a submodule at the specified directory:

git submodule add <repository_url> <path/to/directory>

% Update every submodule to its latest commit:

git submodule foreach git pull
% git svn

% Clone an SVN repository:

git svn clone <https://example.com/subversion_repo> <local_dir>

% Clone a SVN repository starting at a given revision number:

git svn clone -r<1234>:HEAD <https://svn.example.net/subversion/repo> <local_dir>

% Update local clone from the remote SVN repository:

git svn rebase

% Fetch updates from the remote SVN repository without changing the git HEAD:

git svn fetch

% Commit back to the SVN repository:

git svn dcommit
% git switch

% Switch to an existing branch:

git switch <branch_name>

% Create a new branch and switch to it:

git switch --create <branch_name>

% Create a new branch based on an existing commit and switch to it:

git switch --create <branch_name> <commit>

% Switch to the previous branch:

git switch -

% Switch to a branch and update all submodules to match:

git switch --recurse-submodules <branch_name>

% Switch to a branch and automatically merge the current branch and any uncommitted changes into it:

git switch --merge <branch_name>
% git tag

% List all tags:

git tag

% Create a tag with the given name pointing to the current commit:

git tag <tag_name>

% Create a tag with the given name pointing to a given commit:

git tag <tag_name> <commit>

% Create an annotated tag with the given message:

git tag <tag_name> -m <tag_message>

% Delete the tag with the given name:

git tag -d <tag_name>

% Get updated tags from upstream:

git fetch --tags

% List all tags whose ancestors include a given commit:

git tag --contains <commit>
% git worktree

% Create a new directory with the specified branch checked out into it:

git worktree add <path/to/directory> <branch>

% Create a new directory with a new branch checked out into it:

git worktree add <path/to/directory> -b <new_branch>

% List all the working directories attached to this repository:

git worktree list

% Remove a worktree (after deleting worktree directory):

git worktree prune
% gixy

% Analyze nginx configuration (default path: /etc/nginx/nginx.conf):

gixy

% Analyze nginx configuration but skip specific tests:

gixy --skips <http_splitting>

% Analyze nginx configuration with the specific severity level:

gixy <-l|-ll|-lll>

% Analyze nginx configuration files on the specific path:

gixy <path/to/configuration_file_1> <path/to/configuration_file_2>
% glances

% Run in terminal:

glances

% Run in web server mode to show results in browser:

glances -w

% Run in server mode to allow connections from other Glances clients:

glances -s

% Connect to a Glances server:

glances -c <hostname>

% Require a password in (web) server mode:

glances -s --password
% glib-compile-resources

% Compile resources referenced in "file.gresource.xml" to a .gresource binary:

glib-compile-resources <file.gresource.xml>

% Compile resources referenced in "file.gresource.xml" to a C source file:

glib-compile-resources --generate-source <file.gresource.xml>

% Compile resources in "file.gresource.xml" to a chosen target file, with .c, .h or .gresource extension:

glib-compile-resources --generate --target=<file.ext> <file.gresource.xml>

% Print a list of resource files referenced in "file.gresource.xml":

glib-compile-resources --generate-dependencies <file.gresource.xml>
% gplusplus

% Compile a source code file into an executable binary:

g++ <source.cpp> -o <output_executable>

% Display (almost) all errors and warnings:

g++ <source.cpp> -Wall -o <output_executable>

% Choose a language standard to compile for(C++98/C++11/C++14/C++17):

g++ <source.cpp> -std=<language_standard> -o <output_executable>

% Include libraries located at a different path than the source file:

g++ <source.cpp> -o <output_executable> -I<header_path> -L<library_path> -l<library_name>
% gnomon

% Use UNIX (or DOS) pipes to pipe the `stdout` of any command through gnomon:

<npm test> | gnomon

% Show number of seconds since the start of the process:

<npm test> | gnomon --type=elapsed-total

% Show an absolute timestamp in UTC:

<npm test> | gnomon --type=absolute

% Set a high threshold of 0.5 seconds for the elapsed time; exceeding which the timestamp will be colored bright red:

<npm test> | gnomon --high <0.5>

% Set a medium threshold of 0.2 seconds (Timestamp will be colored bright yellow):

<npm test> | gnomon --medium <0.2>
% gnuplot

% Start the interactive graph plotting shell:

gnuplot

% Plot the graph for the specified graph definition file:

gnuplot <path/to/definition.plt>

% Set the output format by executing a command before loading the definition file:

gnuplot -e "<set output "path/to/filename.png" size 1024,768>" <path/to/definition.plt>

% Persist the graph plot preview window after gnuplot exits:

gnuplot --persist <path/to/definition.plt>
% gocryptfs

% Initialize an encrypted filesystem:

gocryptfs -init <path/to/cipher_dir>

% Mount an encrypted filesystem:

gocryptfs <path/to/cipher_dir> <path/to/mount_point>

% Mount with the explicit master key instead of password:

gocryptfs --masterkey <path/to/cipher_dir> <path/to/mount_point>

% Change the password:

gocryptfs --passwd <path/to/cipher_dir>

% Make an encrypted snapshot of a plain directory:

gocryptfs --reverse <path/to/plain_dir> <path/to/cipher_dir>
% godoc

% Display help for package "fmt":

godoc <fmt>

% Display help for the function "Printf" of "fmt" package:

godoc <fmt> <Printf>

% Serve documentation as a web server on port "6060":

godoc -http=:<6060>

% Create an index file:

godoc -write_index -index_files=<path/to/file>

% Use the given index file to search the docs:

godoc -http=:<6060> -index -index_files=<path/to/file>
% godot

% Run a project if the current directory contains a `project.godot` file, otherwise open the project manager:

godot

% Edit a project (the current directory must contain a `project.godot` file):

godot -e

% Open the project manager even if the current directory contains a `project.godot` file:

godot -p

% Export a project for a given export preset (the preset must be defined in the project):

godot --export <preset> <output_path>

% Execute a standalone GDScript file (the script must inherit from `SceneTree` or `MainLoop`):

godot -s <script.gd>
% gofmt

% Format a file and display the result to the console:

gofmt <source.go>

% Format a file, overwriting the original file in-place:

gofmt -w <source.go>

% Format a file, and then simplify the code, overwriting the original file:

gofmt -s -w <source.go>

% Print all (including spurious) errors:

gofmt -e <source.go>
% goimports

% Display the completed import source file:

goimports <file>.go

% Write the result back to the source file instead of the standard output:

goimports -w <file>.go

% Display diffs and write the result back to the source file:

goimports -w -d <file>.go

% Set the import prefix string after 3rd-party packages (comma-separated list):

goimports -local </path/to/package> <file>.go
% go

% Download and install a package, specified by its import path:

go get <package_path>

% Compile and run a source file (it has to contain a `main` package):

go run <file>.go

% Compile a source file into a named executable:

go build -o <executable> <file>.go

% Compile the package present in the current directory:

go build

% Execute all test cases of the current package (files have to end with `_test.go`):

go test

% Compile and install the current package:

go install
% googler

% Search Google for a keyword:

googler <keyword>

% Search Google and open the first result in web browser:

googler -j <keyword>

% Show N search results (default 10):

googler -n <N> <keyword>

% Disable automatic spelling correction:

googler -x <keyword>

% Search one site for a keyword:

googler -w <site> <keyword>

% Show Google search result in JSON format:

googler --json <keyword>

% Perform in-place self-upgrade:

googler -u

% For more help in interactive mode:

?
% gopass

% Initialise the configuration settings:

gopass init

% Create a new entry:

gopass new

% Show all stores:

gopass mounts

% Mount a shared git store:

gopass mounts add <store_name> <git_repo_url>

% Search interactively using a keyword:

gopass show <keyword>

% Search using a keyword:

gopass find <keyword>

% Sync all mounted stores:

gopass sync

% Show a particular password entry:

gopass <store_name|path/to/directory|email@email.com>
% gops

% Print all go processes running locally:

gops

% Print more information about a process:

gops <pid>

% Display a process tree:

gops tree

% Print the current stack trace from a target program:

gops stack <pid|addr>

% Print the current runtime memory statistics:

gops memstats <pid|addr>
% goreload

% Set the name of the binary file to watch (defaults to ".goreload"):

goreload -b <path/to/binary> <file>.go

% Set a custom log prefix (defaults to "goreload"):

goreload --logPrefix <prefix> <file>.go

% Reload whenever any file changes:

goreload --all
% gotty

% Share result of command:

gotty <command>

% Share with write permission:

gotty -w <shell>

% Share with credential (Basic Auth):

gotty -w -c <username>:<password> <shell>
% gource

% Run gource in a directory (if it isn't the repository's root directory, the root is sought up from there):

gource <path/to/repository>

% Run gource in the current directory, with a custom output resolution:

gource -<width>x<height>

% Set a custom time scale for the animation:

gource -c <time_scale_multiplier>

% Set how long each day should be in the animation (this combines with -c, if provided):

gource -s <seconds>

% Set fullscreen mode and a custom background color:

gource -f -b <hex_color_code>

% Set a title for the animation:

gource --title <title>
% gox

% Compile Go program in the current directory for all operating systems and architecture combinations:

gox

% Download and compile a Go program from a remote URL:

gox <url_1> <url_2>

% Compile current directory for a particular operating system:

gox -os="<os>"

% Compile current directory for a single operating system and architecture combination:

gox -osarch="<os>/<arch>"
% gpg

% List imported keys:

gpg2 --list-keys

% Encrypt a specified file for a specified recipient, writing the output to a new file with `.gpg` appended:

gpg2 --encrypt --recipient <alice@example.com> <path/to/doc.txt>

% Encrypt a specified file with only a passphrase, writing the output to a new file with `.gpg` appended:

gpg2 --symmetric <path/to/doc.txt>

% Decrypt a specified file, writing the result to the standard output:

gpg2 --decrypt <path/to/doc.txt.gpg>

% Import a public key:

gpg2 --import <path/to/public_key.gpg>

% Export the public key of a specified email address to the standard output:

gpg2 --export --armor <alice@example.com>

% Export the private key with a specified email address to the standard output:

gpg2 --export-secret-keys --armor <alice@example.com>
% gpg

% Sign doc.txt without encryption (writes output to doc.txt.asc):

gpg --clearsign <doc.txt>

% Encrypt doc.txt for alice@example.com (output to doc.txt.gpg):

gpg --encrypt --recipient <alice@example.com> <doc.txt>

% Encrypt doc.txt with only a passphrase (output to doc.txt.gpg):

gpg --symmetric <doc.txt>

% Decrypt doc.txt.gpg (output to `stdout`):

gpg --decrypt <doc.txt.gpg>

% Import a public key:

gpg --import <public.gpg>

% Export public key for alice@example.com (output to `stdout`):

gpg --export --armor <alice@example.com>

% Export private key for alice@example.com (output to `stdout`):

gpg --export-secret-keys --armor <alice@example.com>
% gpg-zip

% Encrypt a directory into archive.gpg using a passphrase:

gpg-zip --symmetric --output <archive.gpg> <path/to/directory>

% Decrypt archive.gpg into a directory of the same name:

gpg-zip --decrypt <path/to/archive.gpg>

% List the contents of the encrypted archive.gpg:

gpg-zip --list-archive <path/to/archive.gpg>
% gradle

% Compile a package:

gradle build

% Exclude test task:

gradle build -x <test>

% Run in offline mode to prevent gradle from accessing the network during builds:

gradle build --offline

% Clear the build directory:

gradle clean

% Compile and Release package:

gradle assembleRelease
% grep

% Search for an exact string:

grep <search_string> <path/to/file>

% Search in case-insensitive mode:

grep -i <search_string> <path/to/file>

% Search recursively (ignoring non-text files) in current directory for an exact string:

grep -RI <search_string> .

% Use extended regular expressions (supporting `?`, `+`, `{}`, `()` and `|`):

grep -E <^regex$> <path/to/file>

% Print 3 lines of [C]ontext around, [B]efore, or [A]fter each match:

grep -<C|B|A> 3 <search_string> <path/to/file>

% Print file name with the corresponding line number for each match:

grep -Hn <search_string> <path/to/file>

% Use the standard input instead of a file:

cat <path/to/file> | grep <search_string>

% Invert match for excluding specific strings:

grep -v <search_string>
% groff

% Render a man page as plain text, and display the result:

groff -man -T utf8 <manpage.1>

% Render a man page using the ASCII output device, and display it using a pager:

groff -man -T ascii <manpage.1> | less

% Render a man page into an HTML file:

groff -man -T html <manpage.1> > <page.html>

% Process a roff file using the `tbl` and `pic` preprocessors, and the `me` macro set:

groff -t -p -me -T utf8 <foo.me>

% Run a `groff` command with preprocessor and macro options guessed by the `grog` utility:

eval "$(grog -T utf8 <foo.me>)"
% groups

% Print group memberships for the current user:

groups

% Print group memberships for a specific user:

groups <username>

% Print group memberships for a list of users:

groups <username1> <username2> <username3>
% grumphp

% Register the Git hooks:

grumphp git:init

% Trigger the pre-commit hook manually:

grumphp git:pre-commit

% Check every versioned file:

grumphp run
% grunt

% Run the default task process:

grunt

% Run one or more specific space-separated task(s):

grunt <task_name>

% Specify an alternative configuration file:

grunt --gruntfile <path/to/file>

% Specify an alternative base path for relative files:

grunt --base <path/to/directory>

% Specify an additional directory to scan for tasks in:

grunt --tasks <path/to/directory>

% Perform a dry-run without writing any files:

grunt --no-write

% List all available options:

grunt --help
% gtop

% Show the system stats dashboard:

gtop

% Sort by CPU usage:

c

% Sort by memory usage:

m
% guacd

% Bind to a specific port on localhost:

guacd -b <127.0.0.1> -l <4823>

% Start in debug mode, keeping the process in the foreground:

guacd -f -L <debug>

% Start with TLS support:

guacd -C <my-cert.crt> -K <my-key.pem>

% Write the PID to a file:

guacd -p <path/to/file.pid>
% guetzli

% Compress a JPEG image:

guetzli <input.jpg> <output.jpg>

% Create compressed JPEG image from PNG image:

guetzli <input.png> <output.jpg>

% Compress a JPEG image with desired visual quality (84-100):

guetzli --quality <quality_value> <input.jpg> <output.jpg>
% guile

% Start the Guile Scheme REPL:

guile

% Execute the script in a given Scheme file:

guile <script.scm>

% Execute a Scheme expression:

guile -c "<expression>"

% Listen on a port or a Unix domain socket (the default is port 37146) for remote REPL connections:

guile --listen=<port_or_socket>
% gulp

% Run the default task:

gulp

% Run individual tasks:

gulp <task> <othertask>
% gunzip

% Extract a file from an archive, replacing the original file if it exists:

gunzip <archive.tar.gz>

% Extract a file to a target destination:

gunzip -c <archive.tar.gz> > <archive.tar>

% List the contents of a compressed file:

gunzip -l <file.txt.gz>
% gzip

% Compress a file, replacing it with a gzipped compressed version:

gzip <file.ext>

% Decompress a file, replacing it with the original uncompressed version:

gzip -d <file.ext>.gz

% Compress a file specifying the output filename:

gzip -c <file.ext> > <compressed_file.ext.gz>

% Decompress a gzipped file specifying the output filename:

gzip -c -d <file.ext>.gz > <uncompressed_file.ext>

% Specify the compression level. 1=Fastest (Worst), 9=Slowest (Best), Default level is 6:

gzip -9 -c <file.ext> > <compressed_file.ext.gz>
% handbrakecli

% Convert a video file to MKV (AAC 160kbit audio and x264 CRF20 video):

handbrakecli -i <input.avi> -o <output.mkv> -e x264 -q 20 -B 160

% Resize a video file to 320x240:

handbrakecli -i <input.mp4> -o <output.mp4} -w 320 -l 240

% List available presets:

handbrakecli --preset-list

% Convert an AVI video to MP4 using the Android preset:

handbrakecli --preset="Android" -i <input.ext> -o <output.mp4>
% hangups

% Start hangups:

hangups

% View troubeshooting information and help:

hangups -h

% Set a refresh token for hangups:

hangups --token-path </path/to/token>
% haxelib

% Search for a Haxe library:

haxelib search <keyword>

% Install a Haxe library:

haxelib install <libname>

% Upgrade all installed Haxe libraries:

haxelib upgrade

% Install the development version of a library from a Git repository:

haxelib git <libname> <git_url>
% head

% Output the first few lines of a file:

head -n <count_of_lines> <filename>

% Output the first few bytes of a file:

head -c <size_in_bytes> <filename>

% Output everything but the last few lines of a file:

head -n -<count_of_lines> <filename>

% Output everything but the last few bytes of a file:

head -c -<size_in_bytes> <filename>
% helm

% Create a helm chart:

helm create <chart_name>

% Add a new helm repository:

helm repo add <repo_name>

% List helm repositories:

helm repo list

% Update helm repositories:

helm repo update

% Delete a helm repository:

helm repo remove <repo_name>

% Install a helm chart:

helm install <repo_name>/<chart_name>

% Download helm chart as a tar archive:

helm get <chart_release_name>

% Update helm dependencies:

helm dependency update
% help2man

% Generate a man page for an executable:

help2man <executable>

% Specify the "name" paragraph in the man page:

help2man <executable> --name <name>

% Specify the section for the man page (defaults to 1):

help2man <executable> --section <section>

% Output to a file instead of `stdout`:

help2man <executable> --output <path/to/file>

% Display detailed help:

help2man --help
% heroku

% Login to your heroku account:

heroku login

% Create a heroku app:

heroku create

% Show logs for an app:

heroku logs --app <app_name>

% Run a one-off process inside a dyno (Heroku virtual machine):

heroku run <process_name> --app <app_name>

% List dynos (Heroku virtual machines) for an app:

heroku ps --app <app_name>

% Permanently destroy an app:

heroku destroy --app <app_name>
% hexyl

% Print the hexadecimal representation of a file:

hexyl <path/to/file>

% Print the hexadecimal representation of the first n bytes of a file:

hexyl -n <n> <path/to/file>

% Print bytes 512 through 1024 of a file:

hexyl -r <512>:<1024> <path/to/file>

% Print 512 bytes starting at the 1024th byte:

hexyl -r <1024>:+<512> <path/to/file>
% hg add

% Add files or directories to the staging area:

hg add <path/to/file>

% Add all unstaged files matching a specified pattern:

hg add --include <pattern>

% Add all unstaged files, excluding those that match a specified pattern:

hg add --exclude <pattern>

% Recursively add sub-repositories:

hg add --subrepos

% Perform a test-run without performing any actions:

hg add --dry-run
% hg branch

% Show the name of the currently active branch:

hg branch

% Create a new branch for the next commit:

hg branch <branch_name>
% hg clone

% Clone a repository to a specified directory:

hg clone <remote_repository_source> <destination_path>

% Clone a repository to the head of a specific branch, ignoring later commits:

hg clone --branch <branch> <remote_repository_source>

% Clone a repository with only the ".hg" directory, without checking out files:

hg clone --noupdate <remote_repository_source>

% Clone a repository to a specific revision, tag or branch, keeping the entire history:

hg clone --updaterev <revision> <remote_repository_source>

% Clone a repository up to a specific revision without any newer history:

hg clone --rev <revision> <remote_repository_source>
% hg commit

% Commit staged files to the repository:

hg commit

% Commit a specific file or directory:

hg commit <path/to/file_or_directory>

% Commit with a specific message:

hg commit --message <message>

% Commit all files matching a specified pattern:

hg commit --include <pattern>

% Commit all files, excluding those that match a specified pattern:

hg commit --exclude <pattern>

% Commit using the interactive mode:

hg commit --interactive
% hg init

% Initialise a new repository in the current directory:

hg init

% Initialise a new repository in the specified directory:

hg init <path/to/directory>
% hg log

% Display the entire revision history of the repository:

hg log

% Display the revision history with an ASCII graph:

hg log --graph

% Display the revision history with file names matching a specified pattern:

hg log --include <pattern>

% Display the revision history, excluding file names that match a specified pattern:

hg log --exclude <pattern>

% Display the log information for a specific revision:

hg log --rev <revision>

% Display the revision history for a specific branch:

hg log --branch <branch>

% Display the revision history for a specific date:

hg log --date <date>

% Display revisions committed by a specific user:

hg log --user <user>
% hg

% Execute Mercurial command:

hg <command>

% Call general help:

hg help

% Call help on a command:

hg help <command>

% Check the Mercurial version:

hg --version
% hg pull

% Pull from the "default" source path:

hg pull

% Pull from a specified source repository:

hg pull <path/to/source_repository>

% Update the local repository to the head of the remote:

hg pull --update

% Pull changes even when the remote repository is unrelated:

hg pull --force

% Specify a specific revision changeset to pull up to:

hg pull --rev <revision>

% Specify a specific branch to pull:

hg pull --branch <branch>

% Specify a specific bookmark to pull:

hg pull --bookmark <bookmark>
% hg push

% Push changes to the "default" remote path:

hg push

% Push changes to a specified remote repository:

hg push <path/to/destination_repository>

% Push a new branch if it does not exist (disabled by default):

hg push --new-branch

% Specify a specific revision changeset to push:

hg push --rev <revision>

% Specify a specific branch to push:

hg push --branch <branch>

% Specify a specific bookmark to push:

hg push --bookmark <bookmark>
% hg remove

% Remove files or directories from the staging area:

hg remove <path/to/file>

% Remove all staged files matching a specified pattern:

hg remove --include <pattern>

% Remove all staged files, excluding those that match a specified pattern:

hg remove --exclude <pattern>

% Recursively remove sub-repositories:

hg remove --subrepos

% Remove files from the repository that have been physically removed:

hg remove --after
% hg root

% Display the root location of the current repository:

hg root

% Display the root location of the specified repository:

hg root --cwd <path/to/directory>
% hg serve

% Start a web server instance:

hg serve

% Start a web server instance on the specified port:

hg serve --port <port>

% Start a web server instance on the specified listening address:

hg serve --address <address>

% Start a web server instance with a specific identifier:

hg serve --name <name>

% Start a web server instance using the specified theme (see the templates directory):

hg serve --style <style>

% Start a web server instance using the specified SSL certificate bundle:

hg serve --certificate <path/to/certificate>
% hg status

% Display the status of changed files:

hg status

% Display only modified files:

hg status --modified

% Display only added files:

hg status --added

% Display only removed files:

hg status --removed

% Display only deleted (but tracked) files:

hg status --deleted

% Display changes in the working directory compared to a specified changeset:

hg status --rev <revision>

% Display only files matching a specified glob pattern:

hg status --include <pattern>

% Display files, excluding those that match a specified glob pattern:

hg status --exclude <pattern>
% hg update

% Update to the tip of the current branch:

hg update

% Update to the specified revision:

hg update --rev <revision>

% Update and discard uncommitted changes:

hg update --clean

% Update to the last commit matching a specified date:

hg update --date <dd-mm-yyyy>
% history

% Display the commands history list with line numbers:

history

% Clear the commands history list (only for current `bash` shell):

history -c

% Overwrite history file with history of current `bash` shell (often combined with `history -c` to purge history):

history -w

% Delete the history entry at the specified offset:

history -d <offset>
% hn

% View stories on Hacker News:

hn

% View _number_ of stories on Hacker News:

hn --limit <number>

% View stories on Hacker News, and keep the list open after selecting a link:

hn --keep-open

% View stories on Hacker News sorted by submission date:

hn --latest
% home-manager

% Activate the configuration defined in `~/.config/nixpkgs/home.nix`:

home-manager build

% Activate the configuration and switch to it:

home-manager switch
% hostess

% List domains, target ips and on/off status:

hostess list

% Add a domain pointing to your machine to your hosts file:

hostess add <local.example.com> <127.0.0.1>

% Remove a domain from your hosts file:

hostess del <local.example.com>

% Disable a domain (but don't remove it completely):

hostess off <local.example.com>
% hostid

% Display the numeric identifier for the current host in hexadecimal:

hostid
% host

% Lookup A, AAAA, and MX records of a domain:

host <domain>

% Lookup a field (CNAME, TXT,...) of a domain:

host -t <field> <domain>

% Reverse lookup an IP:

host <ip_address>

% Specify an alternate DNS server to query:

host <domain> <8.8.8.8>
% hping

% Ping localhost over TCP:

hping3 <localhost>

% Ping an IP address over TCP on a specific port:

hping3 -p <80> -S <192.168.1.1>

% Ping an IP address over UDP on port 80:

hping3 --udp -p <80> -S <192.168.1.1>

% Scan a set of TCP ports on a specific IP address:

hping3 --scan <80,3000,9000> -S <192.168.1.1>

% Perform a charge test on port 80:

hping3 --flood -p <80> -S <192.168.1.1>
% hr

% Print a horizontal rule:

hr

% Print a horizontal rule with a custom string:

hr <string>

% Print a multiline horizontal rule:

hr <string_a> <string_b> <string_c>
% hsd-cli

% Retrieve information about the current server:

hsd-cli info

% Broadcast a local transaction:

hsd-cli broadcast <transaction_hex>

% Retrieve a mempool snapshot:

hsd-cli mempool

% View a transaction by address or hash:

hsd-cli tx <address_or_hash>

% View a coin by its hash index or address:

hsd-cli coin <hash_index_or_address>

% View a block by height or hash:

hsd-cli block <height_or_hash>

% Reset the chain to the specified block:

hsd-cli reset <height_or_hash>

% Execute an RPC command:

hsd-cli rpc <command> <args>
% hsw-cli

% Unlock the current wallet (timeout in seconds):

hsw-cli unlock <passphrase> <timeout>

% Lock the current wallet:

hsw-cli lock

% View the current wallet's details:

hsw-cli get

% View the current wallet's balance:

hsw-cli balance

% View the current wallet's transaction history:

hsw-cli history

% Send a transaction with the specified coin amount to an address:

hsw-cli send <address> <1.05>

% View the current wallet's pending transactions:

hsw-cli pending

% View details about a transaction:

hsw-cli tx <transaction_hash>
% html5validator

% Validate a specific file:

html5validator <path/to/file>

% Validate all HTML files in a specific directory:

html5validator --root <path/to/directory>

% Show warnings as well as errors:

html5validator --show-warnings <path/to/file>

% Match multiple files using a glob pattern:

html5validator --root <path/to/directory> --match "<*.html *.php>"

% Ignore specific directory names:

html5validator --root <path/to/directory> --blacklist "<node_modules vendor>"

% Output the results in a specific format:

html5validator --format <gnu|xml|json|text> <path/to/file>

% Output the log at a specific verbosity level:

html5validator --root <path/to/directory> --log <debug|info|warning>
% htpasswd

% Create/overwrite htpasswd file:

htpasswd -c <path/to/file> <username>

% Add user to htpasswd file or update existing user:

htpasswd <path/to/file> <username>

% Add user to htpasswd file in batch mode without an interactive password prompt (for script usage):

htpasswd -b <path/to/file> <username> <password>

% Delete user from htpasswd file:

htpasswd -D <path/to/file> <username>

% Verify user password:

htpasswd -v <path/to/file> <username>

% Display a string with username (plain text) and password (md5):

htpasswd -nbm <username> <password>
% httping

% Ping the specified url:

httping -g <url>

% Ping the web server on `host` and `port`:

httping -h <host> -p <port>

% Ping the web server on `host` using a TLS connection:

httping -l -g https://<host>

% Ping the web server on `host` using HTTP basic authentication:

httping -g http://<host> -U <username> -P <password>
% http

% Download a URL to a file:

http -d <example.org>

% Send form-encoded data:

http -f <example.org> <name='bob'> <profile_picture@'bob.png'>

% Send JSON object:

http <example.org> <name='bob'>

% Specify an HTTP method:

http <HEAD> <example.org>

% Include an extra header:

http <example.org> <X-MyHeader:123>

% Pass a user name and password for server authentication:

http -a <username:password> <example.org>

% Specify raw request body via `stdin`:

cat <data.txt> | http PUT <example.org>
% hub

% Clone a repository you own, using just the repository name rather than the full URL:

hub clone <repo_name>

% Clone another user's repository, using their github username and the repository name:

hub clone <username>/<repo_name>

% Create a fork of the current repository (cloned from another user) under your github profile:

hub fork

% Push the current local branch to github and create a PR for it in the original repository:

hub push <remote_name> && hub pull-request

% Create a PR of the current (already pushed) branch, reusing the message from the first commit:

hub pull-request --no-edit

% Create a new branch with the contents of a pull request and switch to it:

hub pr checkout <pr_number>

% Upload the current (local-only) repository to your github account:

hub create
% hugo

% Create a new Hugo site:

hugo new site <path/to/site>

% Create a new Hugo theme (themes may also be downloaded from https://themes.gohugo.io/):

hugo new theme <theme_name>

% Create a new page:

hugo new <section_name>/<filename>

% Build a site to the `./public/` directory:

hugo

% Build a site including pages that are marked as a "draft":

hugo --buildDrafts

% Build a site to a given directory:

hugo --destination <path/to/destination>

% Build a site, start up a webserver to serve it, and automatically reload when pages are edited:

hugo server
% hyperfine

% Run a basic benchmark, performing at least 10 runs:

hyperfine '<make>'

% Run a comparative benchmark:

hyperfine '<make target1>' '<make target2>'

% Change minimum number of benchmarking runs:

hyperfine --min-runs <7> '<make>'

% Perform benchmark with warmup:

hyperfine --warmup <5> '<make>'

% Run a command before each benchmark run (to clear caches, etc.):

hyperfine --prepare '<make clean>' '<make>'

% Run a benchmark where a single parameter changes for each run:

hyperfine --prepare '<make clean>' --parameter-scan <num_threads> <1> <10> '<make -j {num_threads>}'
% iconv

% Convert file to a specific encoding, and print to `stdout`:

iconv -f <from_encoding> -t <to_encoding> <input_file>

% Convert file to the current locale's encoding, and output to a file:

iconv -f <from_encoding> <input_file> > <output_file>

% List supported encodings:

iconv -l
% id3tag

% Set artist and title tag of an MP3 file:

id3tag --artist=<artist> --title=<title> <path/to/file.mp3>

% Set album title of all MP3 files in the current directory:

id3tag --album=<album> <*.mp3>

% Get more help:

id3tag --help
% id

% Display current user's id (UID), group id (GID) and groups to which they belong:

id

% Display the current user identity as a number:

id -u

% Display the current group identity as a number:

id -g

% Display an arbitrary user's id (UID), group id (GID) and groups to which they belong:

id <username>
% ifconfig

% View network settings of an ethernet adapter:

ifconfig eth0

% Display details of all interfaces, including disabled interfaces:

ifconfig -a

% Disable eth0 interface:

ifconfig eth0 down

% Enable eth0 interface:

ifconfig eth0 up

% Assign IP address to eth0 interface:

ifconfig eth0 <ip_address>
% if

% Echo a different thing depending on a command's success:

<command> && echo "success" || echo "failure"

% Full if syntax:

if <condition>; then echo "true"; else echo "false"; fi

% List available if conditions:

help test

% Test if a given variable is empty:

if [[ -z $GIT_BRANCH ]]; then echo "true"; else echo "false"; fi

% Test if a file exists:

if [[ -e <filename> ]]; then echo "true"; else echo "false"; fi

% If directory not exists:

if [[ ! -d <path/to/directory> ]]; then echo "true"; else echo "false"; fi
% ignite

% Create a new React Native project:

ignite new <project_name>

% Generate file from a plugin:

ignite generate <plugin_name> <file_name>

% Add an Ignite plugin to the project:

ignite add <plugin_name>

% Remove an Ignite plugin from the project:

ignite remove <plugin_name>
% imapsync

% Synchronize imap account between host1 and host2:

imapsync --host1 <host1> --user1 <user1> --password1 <secret1> --host2 <host2> --user2 <user2> --password2 <secret2>
% import

% Capture the entire X server screen in the PostScript image format:

import -window root <output.postscript>

% Capture contents of a remote X server screen in the PNG image format:

import -window root -display <remote_host>:{screen}.{display} <output.png>

% Capture a specific window, given its ID as displayed by `xwininfo`, into the JPEG format:

import -window <window_id> <output.jpg>
% in2csv

% Convert an XLS file to CSV:

in2csv <data.xls>

% Convert a DBF file to a CSV file:

in2csv <data.dbf> > <data.csv>

% Convert a specific sheet from an XLSX file to CSV:

in2csv --sheet=<sheet_name> <data.xlsx>

% Pipe a JSON file to in2csv:

cat <data.json> | in2csv -f json > <data.csv>
% infection

% Analyse code using the configuration file (or create one if it does not exist):

infection

% Use a specific number of threads:

infection --threads <number_of_threads>

% Specify a minimum Mutation Score Indicator (MSI):

infection --min-msi <percentage>

% Specify a minimum covered code MSI:

infection --min-covered-msi <percentage>

% Use a specific test framework (defaults to phpunit):

infection --test-framework <phpunit|phpspec>

% Only mutate lines of code that are covered by tests:

infection --only-covered

% Display the mutation code that has been applied:

infection --show-mutations

% Specify the log verbosity:

infection --log-verbosity <default|all|none>
% influx

% Connect to an InfluxDB running on localhost with no credentials:

influx

% Connect with a specific username (will prompt for a password):

influx -username <username> -password ""

% Connect to a specific host:

influx -host <hostname>

% Use a specific database:

influx -database <database_name>

% Execute a given command:

influx -execute "<influxql_command>"

% Return output in a specific format:

influx -execute "<influxql_command>" -format <json|csv|column>
% info

% Start reading top-level directory menu:

info

% Start reading at given menu item node from top-level directory:

info <menu_item>

% Start reading at second menu item within first menu item manual:

info <first_menu_item> <second_menu_item>
% initdb

% Create a database at /usr/local/var/postgres:

initdb -D /usr/local/var/postgres
% inkscape

% Open an SVG file in the Inkscape GUI:

inkscape <filename.svg>

% Export an SVG file into a bitmap with the default format (PNG) and the default resolution (90 DPI):

inkscape <filename.svg> -e <filename.png>

% Export an SVG file into a bitmap of 600x400 pixels (aspect ratio distortion may occur):

inkscape <filename.svg> -e <filename.png> -w <600> -h <400>

% Export a single object, given its ID, into a bitmap:

inkscape <filename.svg> -i <id> -e <object.png>

% Export an SVG document to PDF, converting all texts to paths:

inkscape <filename.svg> --export-pdf=<filename.pdf> --export-text-to-path

% Duplicate the object with id="path123", rotate the duplicate 90 degrees, save the file, and quit Inkscape:

inkscape <filename.svg> --select=path123 --verb=EditDuplicate --verb=ObjectRotate90 --verb=FileSave --verb=FileQuit
% inkview

% Preview an SVG:

inkview <path/to/file.svg>

% Preview multiple SVGs (use arrow keys to navigate):

inkview <path/to/file_a.svg> <path/to/file_b.svg> <path/to/file_c.svg>
% install

% Copy files to destination:

install <path/to/source> <path/to/destination>

% Copy files to destination, setting their ownership:

install -o <user> <path/to/source> <path/to/destination>

% Copy files to destination, setting their group ownership:

install -g <user> <path/to/source> <path/to/destination>

% Copy files to destination, setting their `mode`:

install -m <+x> <path/to/source> <path/to/destination>

% Copy files and apply access/modification times of source to destination:

install -p <path/to/source> <path/to/destination>
% ionice

% Set I/O scheduling class of a running process:

ionice -c <scheduling_class> -p <pid>

% Run a command with custom I/O scheduling class and priority:

ionice -c <scheduling_class> -n <priority> <command>

% Print the I/O scheduling class and priority of a running process:

ionice -p <pid>
% ionic

% Create a new project:

ionic start

% Start a local dev server for app dev/testing:

ionic serve

% Generate new app component, directive, page, pipe, provider or tabs:

ionic g <page>

% Show versions of ionic, cordova, environment, etc.:

ionic info

% Run app on an android/ios device:

ionic cordova run <android|ios> --device

% Check the health of a ionic app:

ionic doctor <check>
% ioping

% Show disk I/O latency using the default values and the current directory:

ioping .

% Measure latency on /tmp using 10 requests of 1 megabyte each:

ioping -c 10 -s 1M /tmp

% Measure disk seek rate on /dev/sda:

ioping -R /dev/sda

% Measure disk sequential speed on /dev/sda:

ioping -RL /dev/sda
% iotop

% Start top-like I/O monitor:

iotop

% Show only processes or threads actually doing I/O:

iotop -o

% Show I/O usage in non-interactive mode:

iotop -b

% Show only I/O usage of processes(Default is to show all threads):

iotop -P

% Show I/O usage of given PID(s):

iotop -p <PID>

% Show I/O usage of a given user:

iotop -u <user>

% Show accumulated I/O instead of bandwidth:

iotop -a
% ipcs

% Specific information about the Message Queue which has the id 32768:

ipcs -qi 32768

% General information about all the IPC:

ipcs -a
% iperf3

% Run iperf3 as a server:

iperf3 -s

% Run an iperf3 server on a specific port:

iperf3 -s -p <port>

% Start bandwidth test:

iperf3 -c <server>

% Run iperf3 in multiple parallel streams:

iperf3 -c <server> -P <streams>

% Reverse direction of the test. Server sends data to the client:

iperf3 -c <server> -R
% iperf

% Run on server:

iperf -s

% Run on client:

iperf -c <server_address>

% Run on client with 5 parallel threads:

iperf -c <server_address> -P <5>
% ipfs

% Add a file from local to the file system, pin it and print the relative hash:

ipfs add <filename>

% Add a directory and its files recursively from local to the file system and print the relative hash:

ipfs add -r <directory>

% Save a remote file and give it a name but not pin it:

ipfs get <hash> -o <filename>

% Pin a remote file locally:

ipfs pin add <hash>

% Display pinned files:

ipfs pin ls

% Unpin a file from the local storage:

ipfs pin rm <hash>

% Remove unpinned files from local storage:

ipfs repo gc
% IPython

% Start an interactive IPython session:

ipython

% Enter an interactive IPython session after running a Python script:

ipython -i <script.py>

% Create default IPython profile:

ipython profile create

% Print the path to the directory for the default IPython profile:

ipython locate profile

% Clear the IPython history database, deleting all entries:

ipython history clear
% irssi

% Open irssi and connect to a server with a nickname:

irssi -n <nickname> -c <irc.example.com>

% Open irssi and connect with a specific server on a given port:

irssi -c <irc.example.com> -p <port>

% View the help:

irssi --help

% Join a channel:

/join <#channelname>

% Change active window (starts at 1):

/win <window_number>

% Exit the application cleanly and quitting any server(s):

/quit
% is-up

% Check the status of the specified website:

is-up <example.com>
% iverilog

% Compile a source file into an executable:

iverilog <source.v> -o <executable>

% Also display all warnings:

iverilog <source.v> -Wall -o <executable>

% Compile and run explicitly using the VVP runtime:

iverilog -o <execuable> -tvvp <source.v>

% Compile using Verilog library files from a different path:

iverilog <source.v> -o <executable> -I<path/to/library_directory>

% Preprocess Verilog code without compiling:

iverilog -E <source.v>
% jar

% Recursively archive all files in the current directory into a .jar file:

jar cf <file.jar> *

% Unzip .jar/.war file to the current directory:

jar -xvf <file.jar>

% List a .jar/.war file content:

jar tf <path/to/file.jar>

% List a .jar/.war file content with verbose output:

jar tvf <path/to/file.jar>
% jarsigner

% Sign a JAR file:

jarsigner <path/to/file.jar> <keystore_alias>

% Sign a JAR file with a specific algorithm:

jarsigner -sigalg <algorithm> <path/to/file.jar> <keystore_alias>

% Verify the signature of a JAR file:

jarsigner -verify <path/to/file.jar>
% javac

% Compile a .java file:

javac <file.java>

% Compile several .java files:

javac <file1.java> <file2.java> <file3.java>

% Compile all .java files in current directory:

javac <*.java>

% Compile a .java file and place the resulting class file in a specific directory:

javac -d <path/to/some/directory> <file.java>
% javadoc

% Generate documentation for Java source code and save the result in a directory:

javadoc -d <path/to/directory/> <path/to/java_source_code>

% Generate documentation with a specific encoding:

javadoc -docencoding <UTF-8> <path/to/java_source_code>

% Generate documentation excluding some packages:

javadoc -exclude <package_list> <path/to/java_source_code>
% java

% Execute a java .class file that contains a main method by using just the class name:

java <classname>

% Execute a .jar program:

java -jar <filename.jar>

% Display JDK, JRE and HotSpot versions:

java -version

% Display usage information for the java command:

java -help
% jdupes

% Search a single directory:

jdupes <directory>

% Search multiple directories:

jdupes <directory1> <directory2>

% Search all directories recursively:

jdupes --recurse <directory>

% Search directory recursively and let user choose files to preserve:

jdupes --delete --recurse <directory>

% Search multiple directories and follow subdirectores under directory2, not directory1:

jdupes <directory1> --recurse: <directory2>

% Search multiple directories and keep the directory order in result:

jdupes -O <directory1> <directory2> <directory3>
% jekyll

% Generate a development server that will run at http://localhost:4000/:

jekyll serve

% Enable incremental regeneration:

jekyll serve --incremental

% Generate the current directory into "./_site":

jekyll build
% jest

% Run all available tests:

jest

% Run the test suites from files whose paths match the given regex patterns:

jest <test_file1> <path/to/test_file2.js>

% Run the tests whose names match the given regex pattern:

jest --testNamePattern <spec_name>

% Run test suites related to a given source file:

jest --findRelatedTests <path/to/source_file.js>

% Run test suites related to all uncommitted files:

jest --onlyChanged

% Watch files for changes and automatically re-run related tests:

jest --watch

% Show help:

jest --help
% jhat

% Analyze a heap dump (from jmap), view via http on port 7000:

jhat <dump_file.bin>

% Analyze a heap dump, specifying an alternate port for the http server:

jhat -p <port> <dump_file.bin>

% Analyze a dump letting jhat use up to 8GB RAM (2-4x dump size recommended):

jhat -J-mx8G <dump_file.bin>
% jigsaw

% Initialise a project:

jigsaw init

% Initialise a project using a starter template:

jigsaw init <template_name>

% Build the site for development:

jigsaw build

% Preview the site from the "build_local" directory:

jigsaw serve

% Build the site for production:

jigsaw build production

% Preview the site from the "build_production" directory:

jigsaw serve <build_production>
% jmap

% Print shared object mappings for a java process (output like pmap):

jmap <java_pid>

% Print heap summary information:

jmap -heap <filename.jar> <java_pid>

% Print histogram of heap usage by type:

jmap -histo <java_pid>

% Dump contents of the heap into a binary file for analysis with jhat:

jmap -dump:format=b,file=<filename> <java_pid>
% jobs

% Show status of all jobs:

jobs

% Show status of a particular job:

jobs <job_id>

% Show status and process IDs of all jobs:

jobs -l

% Show process IDs of all jobs:

jobs -p
% join

% Join two files on the first (default) field:

join <file1> <file2>

% Join two files using a comma (instead of a space) as the field separator:

join -t <','> <file1> <file2>

% Join field3 of file1 with field1 of file2:

join -1 <3> -2 <1> <file1> <file2>

% Produce a line for each unpairable line for file1:

join -a <1> <file1> <file2>
% jpegoptim

% Optimise a set of JPEG images, retaining all associated data:

jpegoptim <image1.jpeg> <image2.jpeg> <imageN.jpeg>

% Optimise JPEG images, stripping all non-essential data:

jpegoptim --strip-all <image1.jpeg> <image2.jpeg> <imageN.jpeg>

% Force the output images to be progressive:

jpegoptim --all-progressive <image1.jpeg> <image2.jpeg> <imageN.jpeg>

% Force the output images to have a fixed maximum filesize:

jpegoptim --size=<250k> <image1.jpeg> <image2.jpeg> <imageN.jpeg>
% jps

% List all JVM processes:

jps

% List all JVM processes with only PID:

jps -q

% Display the arguments passed to the processes:

jps -m

% Display the full package name of all processes:

jps -l

% Display the arguments passed to the JVM:

jps -v
% jq

% Output a JSON file, in pretty-print format:

jq . <file.json>

% Output all elements from arrays (or all key-value pairs from objects) in a JSON file:

jq '.[]' <file.json>

% Read JSON objects from a file into an array, and output it (inverse of `jq .[]`):

jq --slurp . <file.json>

% Output the first element in a JSON file:

jq '.[0]' <file.json>

% Output the value of a given key of the first element in a JSON text from `stdin`:

cat <file.json> | jq '.[0].<key_name>'

% Output the value of a given key of each element in a JSON text from `stdin`:

cat <file.json> | jq 'map(.<key_name>)'

% Combine multiple filters:

cat <file.json> | jq 'unique | sort | reverse'

% Output the value of a given key to a string (and disable JSON output):

cat <file.json> | jq --raw-output '"some text: \(.<key_name>)"'
% jrnl

% Insert a new entry with your editor:

jrnl

% Quickly insert a new entry:

jrnl <today at 3am>: <title>. <content>

% View the last ten entries:

jrnl -n <10>

% View everything that happened from the start of last year to the start of last march:

jrnl -from <"last year"> -until <march>

% Edit all entries tagged with "texas" and "history":

jrnl <@texas> -and <@history> --edit
% json5

% Convert JSON5 stdin to JSON `stdout`:

echo <input> | json5

% Convert a JSON5 file to JSON and output to `stdout`:

json5 <path/to/input_file.json5>

% Convert a JSON5 file to the specified JSON file:

json5 <path/to/input_file.json5> --out-file <path/to/output_file.json>

% Validate a JSON5 file:

json5 <path/to/input_file.json5> --validate

% Specify the number of spaces to indent by (or "t" for tabs):

json5 --space <indent_amount>

% View available options:

json5 --help
% jstack

% Print java stack traces for all threads in a java process:

jstack <java_pid>

% Print mixed mode (java/c++) stack traces for all threads in a java process:

jstack -m <java_pid>

% Print stack traces from java core dump:

jstack </usr/bin/java> <file.core>
% julia

% Start a Julia REPL session:

julia

% Execute a Julia program and exit:

julia <program.jl>

% Execute a Julia program that takes arguments:

julia <program.jl> <arguments>

% Evaluate a string containing Julia code:

julia -e '<julia_code>'

% Evaluate a string of Julia code, passing arguments to it:

julia -e '<for x in ARGS; println(x); end>' <arguments>

% Start Julia in parallel mode, using N worker processes:

julia -p <N>
% jupyter

% Start a Jupyter notebook server in the current directory:

jupyter notebook

% Open a specific Jupyter notebook:

jupyter notebook <example.ipynb>

% Start a server on a specific port:

jupyter notebook --port=<port>

% List currently running notebook servers:

jupyter notebook list

% Stop the currently running server:

jupyter notebook stop

% Start JupyterLab, if installed, in the current directory:

jupyter lab
% jwt

% Decode a JWT:

jwt decode <jwt_string>

% Decode a JWT as a JSON string:

jwt decode -j <jwt_string>

% Encode a JSON string to a JWT:

jwt encode --alg <HS256> --secret <1234567890> '<json_string>'

% Encode key pair payload to JWT:

jwt encode --alg <HS256> --secret <1234567890> -P key=value
% k6

% Run load test locally:

k6 run <script.js>

% Run load test locally with a given number of virtual users and duration:

k6 run --vus <10> --duration <30s> <script.js>

% Run load test locally with a given environment variable:

k6 run -e <HOSTNAME=example.com> <script.js>

% Run load test locally using InfluxDB to store results:

k6 run --out influxdb=<http://localhost:8086/k6db> <script.js>

% Login to cloud service using secret token:

k6 login cloud --token <secret>

% Run load test on cloud infrastructure:

k6 cloud <script.js>
% k8sec

% List all secrets:

k8sec list

% List a specific secret as a base64-encoded string:

k8sec list <secret_name> --base64

% Set a secret's value:

k8sec set <secret_name> <key=value>

% Set a base64-encoded value:

k8sec set --base64 <secret_name> <key=encoded_value>

% Unset a secret:

k8sec unset <secret_name>

% Load secrets from a file:

k8sec load -f <path/to/file> <secret_name>

% Dump secrets to a file:

k8sec dump -f <path/to/file> <secret_name>
% k8s-unused-secret-detector

% Detect unused secrets:

k8s-unused-secret-detector

% Detect unused secrets in a specific namespace:

k8s-unused-secret-detector -n <namespace>

% Delete unused secrets in a specific namespace:

k8s-unused-secret-detector -n <namespace> | kubectl delete secret -n <namespace>
% kafkacat

% Consume messages starting with the newest offset:

kafkacat -C -t <topic> -b <brokers>

% Consume messages starting with the oldest offset and exit after the last message is received:

kafkacat -C -t <topic> -b <brokers> -o beginning -e

% Consume messages as a Kafka consumer group:

kafkacat -G <group_id> <topic> -b <brokers>

% Publish message by reading from `stdin`:

 echo <message> | kafkacat -P -t <topic> -b <brokers>

% Publish messages by reading from a file:

kafkacat -P -t <topic> -b <brokers> <path/to/file>

% List metadata for all topics and brokers:

kafkacat -L -b <brokers>

% List metadata for a specific topic:

kafkacat -L -t <topic> -b <brokers>

% Get offset for a topic/partition for a specific point in time:

kafkacat -Q -t <topic>:<partition>:<unix_timestamp> -b <brokers>
% kaggle

% View current configuration values:

kaggle config view

% Download a specific file from a competition dataset:

kaggle competitions download <competition> -f <filename>
% kahlan

% Run all specifications in the "spec" directory:

kahlan

% Run specifications using a specific configuration file:

kahlan --config=<path/to/configuration_file>

% Run specifications and output using a reporter:

kahlan --reporter=<dot|bar|json|tap|verbose>

% Run specifications with code coverage (detail can be between 0 and 4):

kahlan --coverage=<detail_level>
% kak

% Open a file and enter normal mode, to execute commands:

kak <path/to/file>

% Enter insert mode from normal mode, to write text into the file:

i

% Escape insert mode, to go back to normal mode:

<Escape>

% Replace all instances of "foo" in the current file with "bar":

%s<foo><Enter>c<bar><Escape>

% Un-select all secondary selections, and keep only the main one:

<Space>

% Search for numbers and select the first two:

/\d+<Enter>N

% Insert the contents of a file:

!cat <path/to/file><Enter>

% Save the current file:

:w<Enter>
% keepass2

% Start KeePass 2, opening the most recently-opened password database:

keepass2

% Start KeePass 2, opening a specific password database:

keepass2 <path/to/database.kbdx>

% Use a specific key file to open a password database:

keepass2 <path/to/database.kbdx> -keyfile:<path/to/key/file.key>
% keybase

% Follow another user:

keybase follow <username>

% Add a new proof:

keybase prove <service> <service_username>

% Sign a file:

keybase sign --infile <input_file> --outfile <output_file>

% Verify a signed file:

keybase verify --infile <input_file> --outfile <output_file>

% Encrypt a file:

keybase encrypt --infile <input_file> --outfile <output_file> <receiver>

% Decrypt a file:

keybase decrypt --infile <input_file> --outfile <output_file>

% Revoke current device, log out, and delete local data:

keybase deprovision
% killall

% Terminate a process using the default SIGTERM (terminate) signal:

killall <process_name>

% List available signal names (to be used without the 'SIG' prefix):

killall --list

% Interactively ask for confirmation before termination:

killall -i <process_name>

% Terminate a process using the SIGINT (interrupt) signal, which is the same signal sent by pressing `Ctrl + C`:

killall -INT <process_name>

% Force kill a process:

killall -KILL <process_name>
% kill

% Terminate a program using the default SIGTERM (terminate) signal:

kill <process_id>

% List available signal names (to be used without the `SIG` prefix):

kill -l

% Terminate a background job:

kill %<job_id>

% Terminate a program using the SIGHUP (hang up) signal. Many daemons will reload instead of terminating:

kill -<1|HUP> <process_id>

% Terminate a program using the SIGINT (interrupt) signal. This is typically initiated by the user pressing `Ctrl + C`:

kill -<2|INT> <process_id>

% Signal the operating system to immediately terminate a program (which gets no chance to capture the signal):

kill -<9|KILL> <process_id>

% Signal the operating system to pause a program until a SIGCONT ("continue") signal is received:

kill -<17|STOP> <process_id>

% Send a `SIGUSR1` signal to all processes with the given GID (group id):

kill -<SIGUSR1> -<group_id>
% knife

% Bootstrap a new node:

knife bootstrap <fqdn_or_ip>

% List all registered nodes:

knife node list

% Show a node:

knife node show <node_name>

% Edit a node:

knife node edit <node_name>

% Edit a role:

knife role edit <role_name>

% View a data bag:

knife data bag show <data_bag_name> <data_bag_item>

% Upload a local cookbook to the Chef server:

knife cookbook upload <cookbook_name>
% kompose

% Deploy a dockerized application to Kubernetes:

kompose up -f <docker-compose.yml>

% Delete instantiated services/deployments from Kubernetes:

kompose down -f <docker-compose.yml>

% Convert a docker-compose file into Kubernetes resources file:

kompose convert -f <docker-compose.yml>
% kops

% Create a cluster from the configuration specification:

kops create cluster -f <cluster_name.yaml>

% Create a new ssh public key:

kops create secret sshpublickey <key_name> -i <~/.ssh/id_rsa.pub>

% Export the cluster configurations into the ~/.kube/config file:

kops export kubecfg <cluster_name>

% Get the cluster configuration as yaml:

kops get cluster <cluster_name> -o yaml

% Delete a cluster:

kops delete cluster <cluster_name> --yes
% kotlin

% Run a jar file:

kotlin <filename.jar>

% Display Kotlin and JVM version:

kotlin -version
% ksh

% Start interactive command line interpreter:

ksh

% Execute a command:

ksh -c <command>

% Run commands from a file:

ksh <file>

% Run commands from a file and print them as they are executed:

ksh -x <file>
% kubeadm

% Create a Kubernetes master node:

kubeadm init

% Bootstrap a Kubernetes worker node and join it to a cluster:

kubeadm join --token <token>

% Create a new bootstrap token with a TTL of 12 hours:

kubeadm token create --ttl <12h0m0s>

% Check if the Kubernetes cluster is upgradeable and which versions are available:

kubeadm upgrade plan

% Upgrade Kubernetes cluster to a specified version:

kubeadm upgrade apply <version>

% View the kubeadm ConfigMap containing the cluster's configuration:

kubeadm config view

% Revert changes made to the host by 'kubeadm init' or 'kubeadm join':

kubeadm reset
% kube-capacity

% Output a list of nodes with the total CPU and Memory resource requests and limits:

kube-capacity

% Include pods:

kube-capacity -p

% Include utilization:

kube-capacity -u
% kubectl

% List all information about a resource with more details:

kubectl get <pod|service|deployment|ingress|...> -o wide

% Update specified pod with the label 'unhealthy' and the value 'true':

kubectl label pods <name> unhealthy=true

% List all resources with different types:

kubectl get all

% Display resource (CPU/Memory/Storage) usage of nodes or pods:

kubectl top <pod|node>

% Print the address of the master and cluster services:

kubectl cluster-info

% Display an explanation of a specific field:

kubectl explain <pods.spec.containers>

% Print the logs for a container in a pod or specified resource:

kubectl logs <pod_name>

% Run command in an existing pod:

kubectl exec <pod_name> -- <ls />
% kubectx

% List the contexts:

kubectx

% Switch to a named context:

kubectx <name>

% Switch to the previous context:

kubectx -

% Delete a named context:

kubectx -d <name>
% kube-fzf

% Get pod details (from current namespace):

findpod

% Get pod details (from all namespaces):

findpod -a

% Describe a pod:

describepod

% Tail pod logs:

tailpod

% Exec into a pod's container:

execpod <shell_command>

% Port-forward a pod:

pfpod <port_number>
% kubens

% List the namespaces:

kubens

% Change the active namespace:

kubens <name>

% Switch to the previous namespace:

kubens -
% kubetail

% Tail the logs of multiple pods (whose name starts with "my_app") in one go:

kubetail <my_app>

% Tail only a specific container from multiple pods:

kubetail <my_app> -c <my_container>

% To tail multiple containers from multiple pods:

kubetail <my_app> -c <my_container_1> -c <my_container_2>

% To tail multiple applications at the same time separate them by comma:

kubetail <my_app_1>,<my_app_2>
% kustomize

% Create kustomization file with resources and namespace:

kustomize create --resources <deployment.yaml,service.yaml> --namespace <staging>

% Build kustomization file and deploy it with `kubectl`:

kustomize build . | kubectl apply -f -

% Set an image in the kustomization file:

kustomize edit set image <busybox=alpine:3.6>

% Search for kubernetes resources in the current directory to be added to the kustomization file:

kustomize create --autodetect
% laravel

% Create a new Laravel application:

laravel new <name>

% Use the latest development release:

laravel new <name> --dev

% Overwrite if the directory already exists:

laravel new <name> --force

% Install the Laravel authentication scaffolding:

laravel new <name> --auth

% List the available installer commands:

laravel list
% laravel-zero

% Create a new Laravel Zero application:

laravel-zero new <name>

% List the available installer commands:

laravel-zero list
% last

% View last logins, their duration and other information as read from /var/log/wtmp:

last

% Specify how many of the last logins to show:

last -n <login_count>

% Print the full date and time for entries and then display the hostname column last to prevent truncation:

last -F -a

% View all logins by a specific user and show the ip address instead of the hostname:

last <username> -i

% View all recorded reboots (i.e., the last logins of the pseudo user "reboot"):

last reboot

% View all recorded shutdowns (i.e., the last logins of the pseudo user "shutdown"):

last shutdown
% latexmk

% Compile a dvi (DeVice Independent file) document from every source:

latexmk

% Compile a dvi document from a specific source file:

latexmk <source.tex>

% Compile a pdf document:

latexmk -pdf <source.tex>

% Force the generation of a document even if there are errors:

latexmk -f <source.tex>

% Clean up temporary tex files created for a specific tex file:

latexmk -c <source.tex>

% Clean up all temporary tex files in the current directory:

latexmk -c
% ldapsearch

% Query an LDAP server for all items that are a member of the given group and return the object's displayName value:

ldapsearch -D '<admin_DN>' -w '<password>' -h <ldap_host> -b <base_ou> '<memberOf=group1>' displayName

% Query an LDAP server with a no-newline password file for all items that are a member of the given group and return the object's displayName value:

ldapsearch -D '<admin_DN>' -y '<password_file>' -h <ldap_host> -b <base_ou> '<memberOf=group1>' displayName

% Return 5 items that match the given filter:

ldapsearch -D '<admin_DN>' -w '<password>' -h <ldap_host> -b <base_ou> '<memberOf=group1>' -z 5 displayName

% Wait up to 7 seconds for a response:

ldapsearch -D '<admin_DN>' -w '<password>' -h <ldap_host> -b <base_ou> '<memberOf=group1>' -l 7 displayName

% Invert the filter:

ldapsearch -D '<admin_DN>' -w '<password>' -h <ldap_host> -b <base_ou> '(!(memberOf=<group1>))' displayName

% Return all items that are part of multiple groups, returning the display name for each item:

ldapsearch -D '<admin_DN>' -w '<password>' -h <ldap_host> '(&(<memberOf=group1>)(<memberOf=group2>)(<memberOf=group3>))' "displayName"

% Return all items that are members of at least 1 of the specified groups:

ldapsearch -D '<admin_DN>' -w '<password>' -h <ldap_host> '(|(<memberOf=group1>)(<memberOf=group1>)(<memberOf=group3>))' displayName

% Combine multiple boolean logic filters:

ldapsearch -D '<admin_DN>' -w '<password>' -h <ldap_host> '(&(<memberOf=group1>)(<memberOf=group2>)(!(<memberOf=group3>)))' displayName
% leave

% Set a reminder at a given time:

leave <time_to_leave>

% Remind to leave at noon:

leave <1200>

% Set a reminder in a specific amount of time:

leave +<amount_of_time>

% Remind to leave in 4 hours and 4 minutes:

leave +<0404>
% lebab

% Display a list of the available transformations:

lebab --help

% Transpile using one or more comma-separated transformations:

lebab --transform <transformation>

% Transpile a file to `stdout`:

lebab <path/to/input_file>

% Transpile a file to the specified output file:

lebab <path/to/input_file> --out-file <path/to/output_file>

% Replace all `.js` files in-place in the specified directory, glob or file:

lebab --replace <directory|glob|file>
% lein

% Generate scaffolding for a new project based on a template:

lein new <template_name> <project_name>

% Start a REPL session either with the project or standalone:

lein repl

% Run the project's "-main" function with optional args:

lein run <args>

% Run the project's tests:

lein test

% Package up the project files and all its dependencies into a jar file:

lein uberjar
% less

% Open a file:

less <source_file>

% Page down / up:

<Space> (down), b (up)

% Go to end / start of file:

G (end), g (start)

% Forward search for a string (press `n`/`N` to go to next/previous match):

/<something>

% Backward search for a string (press `n`/`N` to go to next/previous match):

?<something>

% Follow the output of the currently opened file:

F

% Open the current file in an editor:

v

% Exit:

q
% lex

% Generate an analyser from a Lex file:

lex <analyser.l>

% Specify the output file:

lex <analyser.l> --outfile <analyser.c>

% Compile a C file generated by Lex:

cc <path/to/lex.yy.c> --output <executable>
% license

% Print a license to `stdout`, using the defaults (auto-detected author name, and current year):

license <license_name>

% Generate a license and save it to a file:

license -o <filename> <license_name>

% List all available licenses:

license ls

% Generate a license with custom author name and year:

license --name <author> --year <release_year> <license_name>
% light-arionum-cli

% Generate a new public/private key pair:

light-arionum-cli

% Display the balance of the current address:

light-arionum-cli balance

% Display the balance of the specified address:

light-arionum-cli balance <address>

% Send a transaction with an optional message:

light-arionum-cli send <address> <value> <optional_message>

% Export the current wallet information:

light-arionum-cli export

% Display information about the current block:

light-arionum-cli block

% Display information about the current address' transactions:

light-arionum-cli transactions

% Display information about a specific transaction:

light-arionum-cli transaction <transaction_id>
% linkchecker

% Find broken links on https://example.com/:

linkchecker <https://example.com/>

% Also check URLs that point to external domains:

linkchecker --check-extern <https://example.com/>

% Ignore URLs that match a specific regex:

linkchecker --ignore-url <regex> <https://example.com/>

% Output results to a CSV file:

linkchecker --file-output <csv>/<path/to/file> <https://example.com/>
% link

% Create a hard link from a new file to an existing file:

link <path/to/existing_file> <path/to/new_file>
% live-server

% Serve an index.html file and reload on changes:

live-server

% Specify a port (default is 8080) from which to serve a file:

live-server --port=<8081>

% Specify a given file to serve:

live-server --open=<about.html>

% Proxy all requests for ROUTE to URL:

live-server --proxy=</>:<http:localhost:3000>
% ln

% Create a symbolic link to a file or directory:

ln -s <path/to/file_or_directory> <path/to/symlink>

% Overwrite an existing symbolic to point to a different file:

ln -sf <path/to/new_file> <path/to/symlink>

% Create a hard link to a file:

ln <path/to/file> <path/to/hardlink>
% loc

% Print lines of code in the current directory:

loc

% Print lines of code in the target directory:

loc <path/to/directory>

% Print lines of code with stats for individual files:

loc --files

% Print lines of code without .gitignore (etc.) files (e.g. two -u flags will additionally count hidden files and dirs):

loc -u
% locust

% Load-test "example.com" with web interface using locustfile.py:

locust --host=<http://example.com>

% Use a different test file:

locust --locustfile=<test_file.py> --host=<http://example.com>

% Run test without web interface, spawning 1 user a second until there are 100 users:

locust --no-web --clients=<100> --hatch-rate=<1> --host=<http://example.com>

% Start locust in master mode:

locust --master --host=<http://example.com>

% Connect locust slave to master:

locust --slave --host=<http://example.com>

% Connect locust slave to master on a different machine:

locust --slave --master-host=<master_hostname> --host=<http://example.com>
% logname

% Display the currently logged in user's name:

logname
% logstash

% Check validity of a logstash configuration:

logstash --configtest --config <logstash_config.conf>

% Run logstash using configuration:

sudo logstash --config <logstash_config.conf>

% Run logstash with the most basic inline configuration string:

sudo logstash -e 'input {} filter {} output {}'
% lolcat

% Print a file to the console in rainbow colors:

lolcat <path/to/file>

% Print the result of a text-producing command in rainbow colors:

<fortune> | lolcat

% Print a file to the console with animated rainbow colors:

lolcat -a <path/to/file>

% Print a file to the console with 24-bit (truecolor) rainbow colors:

lolcat -t <path/to/file>
% lorem

% Print the specified number of words:

lorem -n <20>

% Print 10 lines of Goethe's Faust:

lorem -l <10> --faust

% Print 5 sentences of Poe's Raven:

lorem -s <5> --raven

% Print 40 random characters from Boccacio's Decameron:

lorem --randomize -c <40> --decamerone
% lpass

% Login to your LastPass account, by entering your master password when prompted:

lpass login <username>

% Show login status:

lpass status

% List all sites grouped by category:

lpass ls

% Generate a new password for "gmail.com" with identifier "myinbox" and add to LastPass:

lpass generate --username <username> --url <gmail.com> <myinbox> <password_length>

% Show password for a specified entry:

lpass show <myinbox> --password
% lp

% Print the output of a command to the default printer (see `lpstat` command):

echo "test" | lp

% Print a file to the default printer:

lp <path/to/filename>

% Print a file to a named printer (see `lpstat` command):

lp -d <printer_name> <path/to/filename>

% Print N copies of file to default printer (replace N with desired number of copies):

lp -n <N> <path/to/filename>

% Print only certain pages to the default printer (print pages 1, 3-5, and 16):

lp -P 1,3-5,16 <path/to/filename>

% Resume printing a job:

lp -i <job_id> -H resume
% lpstat

% List printers present on the machine and whether they are enabled for printing:

lpstat -p

% Show the default printer:

lpstat -d

% Display all available status information:

lpstat -t

% Show a list of print jobs queued by the specified user:

lpstat -u <user>
% ls

% List files one per line:

ls -1

% List all files, including hidden files:

ls -a

% Long format list (permissions, ownership, size and modification date) of all files:

ls -la

% Long format list with size displayed using human readable units (KB, MB, GB):

ls -lh

% Long format list sorted by size (descending):

ls -lS

% Long format list of all files, sorted by modification date (oldest first):

ls -ltr
% lsof

% Find the processes that have a given file open:

lsof <path/to/file>

% Find the process that opened a local internet port:

lsof -i :<port>

% Only output the process ID (PID):

lsof -t <path/to/file>

% List files opened by the given user:

lsof -u <username>

% List files opened by the given command or process:

lsof -c <process_or_command_name>

% List files opened by a specific process, given its PID:

lsof -p <PID>

% List open files in a directory:

lsof +D <path/to/directory>

% Find the process that is listening on a local TCP port:

lsof -iTCP:<port> -sTCP:LISTEN
% luac

% Compile a Lua source file to Lua bytecode:

luac -o <byte_code.luac> <source.lua>

% Do not include debug symbols in the output:

luac -s -o <byte_code.luac> <source.lua>
% lua

% Start an interactive Lua shell:

lua

% Execute a Lua script:

lua <script_name.lua> <--optional-argument>

% Execute a Lua expression:

lua -e '<print( "Hello World" )>
% lumen

% Create a new Lumen application:

lumen new <application_name>

% List the available installer commands:

lumen list
% lwp-request

% Make a simple GET request:

lwp-request -m GET <http://example.com/some/path>

% Upload a file with a POST request:

cat </path/to/file> | lwp-request -m POST <http://example.com/some/path>

% Make a request with a custom user agent:

lwp-request -H 'User-Agent: <user_agent> -m <METHOD> <http://example.com/some/path>

% Make a request with HTTP authentication:

lwp-request -C <username>:<password> -m <METHOD> <http://example.com/some/path>

% Make a request and print request headers:

lwp-request -U -m <METHOD> <http://example.com/some/path>

% Make a request and print response headers and status chain:

lwp-request -E -m <METHOD> <http://example.com/some/path>
% lz4

% Compress a file:

lz4 <file>

% Decompress a file:

lz4 -d <file.lz4>

% Decompress a file and write to `stdout`:

lz4 -dc <file.lz4>

% Package and compress a directory and its contents:

tar cvf - <path/to/dir> | lz4 - <dir.tar.lz4>

% Decompress and unpack a directory and its contents:

lz4 -d <dir.tar.lz4> | tar -xv

% Compress a file using the best compression:

lz4 -9 <file>
% lzop

% Compress a file into a new file with the .lzo suffix:

lzop <file>

% Decompress a file:

lzop -d <file>.lzo

% Compress a file, while specifing the compression level. 0 = Worst, 9 = Best (Default level is 3):

lzop -<level> <file>
% m4

% Process macros in a file:

m4 <path/to/file>

% Define a macro before processing files:

m4 -D<macro_name>=<macro_value> <path/to/file>
% magento

% Enable one or more space-separated modules:

magento module:enable <module(s)>

% Disable one or more space-separated modules:

magento module:disable <module(s)>

% Update the database after enabling modules:

magento setup:upgrade

% Update code and dependency injection configuration:

magento setup:di:compile

% Deploy static assets:

magento setup:static-content:deploy

% Enable maintenance mode:

magento maintenance:enable

% Disable maintenance mode:

magento maintenance:disable

% List all available commands:

magento list
% magick

% Convert file type:

magick <image.png> <image.jpg>

% Resize an image, making a new copy:

magick convert -resize <100x100> <image.jpg> <image.jpg>

% Create a GIF using images:

magick <*.jpg> <images.gif>

% Create checkerboard pattern:

magick -size <640x480> pattern:checkerboard <checkerboard.png>

% Convert images to individual PDF pages:

magick <*.jpg> +adjoin <page-%d.pdf>
% mail

% Send a typed email message. The commandline below continues after pressing Enter key. Input CC email-id (optional) press Enter key. Input message text (can be multi-line). Press "Ctrl-D" key to complete the message text:

mail --subject=<"subject line"> <to_user@example.com>

% Send an email that contains file content:

mail --subject=<"$HOSTNAME filename.txt"> <to_user@example.com> < <path/to/filename.txt>

% Send a tar.gz file as an attachment:

tar cvzf - <path/to/directory1 path/to/directory2> | uuencode <data.tar.gz> | mail --subject=<"subject line"> <to_user@example.com>
% mailx

% Send mail (the content should be typed after the command, and ended with `Ctrl+D`):

mailx -s "<subject>" <to_addr>

% Send mail with content passed from another command:

echo "<content>" | mailx -s "<subject>" <to_addr>

% Send mail with content read from a file:

mailx -s "<subject>" <to_addr> < <content.txt>

% Send mail to a recipient and CC to another address:

mailx -s "<subject>" -c <cc_addr> <to_addr>

% Send mail specifying the sender address:

mailx -s "<subject>" -r <from_addr> <to_addr>

% Send mail with an attachment:

mailx -a <file> -s "<subject>" <to_addr>
% makebuildserver

% Create a new virtual machine or update an existing one (if available):

makebuildserver

% Force creating a fresh virtual machine:

makebuildserver --clean
% make

% Call the first target specified in the Makefile (usually named "all"):

make

% Call a specific target:

make <target>

% Call a specific target, executing 4 jobs at a time in parallel:

make -j<4> <target>

% Use a specific Makefile:

make --file <file>

% Execute make from another directory:

make --directory <directory>

% Force making of a target, even if source files are unchanged:

make --always-make <target>
% makensis

% Compile a NSIS script:

makensis <path/to/file.nsi>

% Compile a NSIS script in strict mode (treat warnings as errors):

makensis -WX <path/to/file.nsi>

% Print help for a specific command:

makensis -CMDHELP <command>
% makepasswd

% Generate a random password (8 to 10 characters long, containing letters and numbers):

makepasswd

% Generate a 10 characters long password:

makepasswd --chars <10>

% Generate a 5 to 10 characters long password:

makepasswd --minchars <5> --maxchars <10>

% Generate a password containing only the characters "b", "a" or "r":

makepasswd --string <bar>
% man

% Display the man page for a command:

man <command>

% Display the man page for a command from section 7:

man <command>.<7>

% Display the path searched for manpages:

man --path

% Display the location of a manpage rather than the manpage itself:

man -w <command>

% Search for manpages containing a search string:

man -k "<search string>"
% mat2

% List supported file formats:

mat2 --list

% Remove metadata from a file:

mat2 <path/to/file>

% Remove metadata from a file and print detailed output to the console:

mat2 --verbose <path/to/file>

% Show metadata in a file without removing it:

mat2 --show <path/to/file>

% Partially remove metadata from a file:

mat2 --lightweight <path/to/file>
% mc

% Start mc:

mc

% Start in black and white:

mc -b
% md5sum

% Calculate the MD5 checksum for a file:

md5sum <filename1>

% Calculate MD5 checksums for multiple files:

md5sum <filename1> <filename2>

% Read a file of MD5SUMs and verify all files have matching checksums:

md5sum -c <filename.md5>
% mdp

% Launch a presentation in the terminal from a markdown file:

mdp <presentation.md>

% Disable fading transitions:

mdp --nofade <presentation.md>

% Invert font colors to use in terminals with light background:

mdp --invert <presentation.md>

% Disable transparency in transparent terminals:

mdp --notrans <presentation.md>
% mediainfo

% Display metadata for a given file in the console:

mediainfo <file>

% Store the output to a given file along with displaying in the console:

mediainfo --Logfile=<out.txt> <file>

% Display the list of metadata attributes that can be extracted:

mediainfo --Info-Parameters
% meld

% Start meld:

meld

% Compare 2 files:

meld <path/to/file_1> <path/to/file_2>

% Compare 2 directories:

meld <path/to/directory_1> <path/to/directory_2>

% Compare 3 files:

meld <path/to/file_1> <path/to/file_2> <path/to/file_3>

% Open a comparison as a new tab in a pre-existing meld instance:

meld --newtab <path/to/file_1> <path/to/file_2>

% Compare multiple sets of files:

meld --diff <path/to/file_1> <path/to/file_2> --diff <path/to/file_3> <path/to/file_4>
% mesg

% Check terminal's openness to write messages:

mesg

% Disable receiving messages from the write command:

mesg n

% Enable receiving messages from the write command:

mesg y
% meshlabserver

% Convert an STL file to an OBJ file:

meshlabserver -i <input.stl> -o <output.obj>

% Convert a WRL file to a OFF file, including the vertex and face normals in the output mesh:

meshlabserver -i <input.wrl> -o <output.off> -om vn fn

% Dump a list of all the available processing filters into a file:

meshlabserver -d <filename>

% Process a 3D file using a filter script created in the MeshLab GUI (Filters > Show current filter script > Save Script):

meshlabserver -i <input.ply> -o <output.ply> -s <filter_script.mlx>

% Process a 3D file using a filter script, writing the output of the filters into a log file:

meshlabserver -i <input.x3d> -o <output.x3d> -s <filter_script.mlx> -l <logfile>
% meteor

% Run a meteor project from its root directory in development mode:

meteor

% Create a project under the given directory:

meteor create <path/to/directory>

% Display the list of packages the project is currently using:

meteor list

% Add a package to the project:

meteor add <package_name>

% Remove a package from the project:

meteor remove <package_name>

% Create a production build of the project as a tarball under the given directory:

meteor build <path/to/directory>
% micro

% Open a file:

micro <file>

% Cut the entire line:

Ctrl + K

% Search for a pattern in the file (press `Ctrl + N`/`Ctrl + P` to go to next/previous match):

Ctrl + F "<pattern>" <Enter>

% Execute a command:

Ctrl + E <command> <Enter>

% Perform a substitution in the whole file:

Ctrl + E replaceall "<pattern>" "<replacement>" <Enter>

% Quit:

Ctrl + Q
% middleman

% Install the Middleman gem:

gem install middleman

% Create a new Middleman project:

middleman init "<project_name>"

% Start local server for current project on port 4567:

middleman server

% Start local server for current project on a specified port:

middleman server -p "<port>"

% Build your project to prepare to deploy:

bundle exec middleman build

% Deploy your Middleman project:

middleman deploy
% minetest

% Start minetest in client mode:

minetest

% Start minetest in server mode:

minetest --server

% Write logs to a specific file:

minetest --logfile <path/to/file>

% Only write errors to the console:

minetest --quiet
% minetestserver

% Start the server:

minetestserver

% List available worlds:

minetestserver --world list

% Specify the world name to load:

minetestserver --world <world_name>

% List the available game IDs:

minetestserver --gameid list

% Specify a game to use:

minetestserver --gameid <game_id>

% Listen on a specific port:

minetestserver --port <34567>

% Migrate to a different data backend:

minetestserver --migrate <sqlite3|leveldb|redis>

% Start an interactive terminal after starting the server:

minetestserver --terminal
% minikube

% Start the cluster:

minikube start

% Get the IP address of the cluster:

minikube ip

% Access a service named my_service exposed via a node port and get the url:

minikube service <my_service> --url

% Open kubernetes dashboard in a browser:

minikube dashboard
% mitmdump

% Start a proxy and save all output to a file:

mitmdump -w <filename>

% Filter a saved traffic file to just POST requests:

mitmdump -nr <input_filename> -w <output_filename> <"~m post">

% Replay a saved traffic file:

mitmdump -nc <filename>
% mitmproxy

% Start mitmproxy with default settings:

mitmproxy

% Start mitmproxy bound to custom address and port:

mitmproxy -b <ip_address> -p <port>
% mix

% Execute a particular file:

mix run <my_script.exs>

% Create a new project:

mix new <project_name>

% Compile project:

mix compile

% Run project tests:

mix test

% List all mix commands:

mix help
% mkcert

% Install the local CA in the system trust store:

mkcert -install

% Generate certificate and private key for a given domain:

mkcert <example.org>

% Generate certificate and private key for multiple domains:

mkcert <example.org> <myapp.dev> <127.0.0.1>

% Generate wildcard certificate and private key for a given domain and its subdomains:

mkcert <"*.example.it">

% Uninstall the local CA:

mkcert -uninstall
% mkdir

% Create a directory in current directory or given path:

mkdir <directory>

% Create directories recursively (useful for creating nested dirs):

mkdir -p <path/to/directory>
% mkfifo

% Create a named pipe at a given path:

mkfifo <path/to/pipe>
% mktemp

% Create an empty temporary file and return the absolute path to it:

mktemp

% Create a temporary directory and return the absolute path to it:

mktemp -d

% Create a temporary file with a specified suffix:

mktemp --suffix "<.txt>"
% mlr

% Pretty-print a CSV file in a tabular format:

mlr --icsv --opprint cat <example.csv>

% Receive JSON data and pretty print the output:

echo '{"hello":"world"}' | mlr --ijson --opprint cat

% Sort alphabetically on a field:

mlr --icsv --opprint sort -f <field> <example.csv>

% Sort in descending numerical order on a field:

mlr --icsv --opprint sort -nr <field> <example.csv>

% Convert CSV to JSON, performing calculations and display those calculations:

mlr --icsv --ojson put '$<newField1> = $<oldFieldA>/$<oldFieldB>' <example.csv>

% Receive JSON and format the output as vertical JSON:

echo '{"hello":"world", "foo":"bar"}' | mlr --ijson --ojson --jvstack cat

% Filter lines of a compressed CSV file treating numbers as strings:

mlr --prepipe 'gunzip' --csv filter -S '$<fieldName> =~ "<regexp>"' <example.csv.gz>
% mmls

% Display the partition table stored in an image file:

mmls <path/to/image_file>

% Display the partition table with an additional column for the partition size:

mmls -B -i <path/to/image_file>

% Display the partition table in a split EWF image:

mmls -i ewf <image.e01> <image.e02>

% Display nested partition tables:

mmls -t <nested_table_type> -o <offset> <path/to/image_file>
% mmv

% Rename all files with a certain extension to a different extension:

mmv "*<.old_extension>" "#1<.new_extension>"

% Copy report6part4.txt to ./french/rapport6partie4.txt along with all similarly named files:

mmv -c <"report*part*.txt"> <"./french/rapport#1partie#2.txt">

% Append all .txt files into one file:

mmv -a <"*.txt"> <"all.txt">

% Convert dates in filenames from "M-D-Y" format to "D-M-Y" format:

mmv <"[0-1][0-9]-[0-3][0-9]-[0-9][0-9][0-9][0-9].txt"> <"#3#4-#1#2-#5#6#7#8.txt">
% mocha

% Run tests with default configuration or as configured in `mocha.opts`:

mocha

% Run tests contained at a specific location:

mocha <directory/with/tests>

% Run tests that match a specific grep pattern:

mocha --grep <^regex$>

% Run tests on changes to JavaScript files in the current directory and once initially:

mocha --watch

% Run tests with a specific reporter:

mocha --reporter <reporter>
% mogrify

% Resize all JPEG images in the directory to 50% of their initial size:

mogrify -resize <50%> <*.jpg>

% Resize all images starting with "DSC" to 800x600:

mogrify -resize <800x600> <DSC*>

% Convert all PNG images in the directory to JPEG:

mogrify -format <jpg> <*.png>

% Halve the saturation of all image files in the current directory:

mogrify -modulate <100,50> <*>

% Double the brightness of all image files in the current directory:

mogrify -modulate <200> <*>
% molecule

% Create a new ansible role:

molecule init role --role-name <role_name>

% Run tests:

molecule test

% Start the instance:

molecule create

% Configure the instance:

molecule converge

% Login into the instance:

molecule login
% mongod

% Specify a config file:

mongod --config <filename>

% Specify the port to listen on:

mongod --port <port>

% Specify database profiling level. 0 is off, 1 is only slow operations, 2 is all:

mongod --profile <0|1|2>
% mongodump

% Create a dump of all databases (this will place the files inside a directory called "dump"):

mongodump

% Specify an output location for the dump:

mongodump --out <path/to/directory>

% Create a dump of a given database:

mongodump --db <database_name>

% Create a dump of a given collection within a given database:

mongodump --collection <collection_name> --db <database_name>

% Connect to a given host running on a given port, and create a dump:

mongodump --host <host> --port <port>

% Create a dump of a given database with a given username; user will be prompted for password:

mongodump --username <username> <database> --password
% mongo

% Connect to a database:

mongo <database>

% Connect to a database running on a given host on a given port:

mongo --host <host> --port <port> <database>

% Connect to a database with a given username; user will be prompted for password:

mongo --username <username> <database> --password

% Evaluate a javascript expression on the database:

mongo --eval '<JSON.stringify(db.foo.findOne())>' <database>
% mongorestore

% Import a bson data dump from a directory to a MongoDB database:

mongorestore --db <database_name> <path/to/directory>

% Import a bson data dump from a directory to a given database in a MongoDB server host, running at a given port, with user authentication (user will be prompted for password):

mongorestore --host <database_host:port> --db <database_name> --username <username> <path/to/directory> --password

% Import a collection from a bson file to a MongoDB database:

mongorestore --db <database_name> <path/to/file>

% Import a collection from a bson file to a given database in a MongoDB server host, running at a given port, with user authentication (user will be prompted for password):

mongorestore --host <database_host:port> --db <database_name> --username <username> <path/to/file> --password
% monodevelop

% Start Monodevelop:

monodevelop

% Open a specific file:

monodevelop <path/to/file>

% Open a specific file with the caret at a specific position:

monodevelop <path/to/file>;<line_number>;<column_number>

% Force opening a new window instead of switching to an existing one:

monodevelop --new-window

% Disable redirection of `stdout` and stderr to a log file:

monodevelop --no-redirect

% Enable performance monitoring:

monodevelop --perf-log
% monodis

% Disassemble an assembly to textual CIL:

monodis <path/to/assembly.exe>

% Save the output to a file:

monodis --output=<path/to/output.il> <path/to/assembly.exe>

% Show information about an assembly:

monodis --assembly <path/to/assembly.dll>

% List the references of an assembly:

monodis --assemblyref <path/to/assembly.exe>

% List all the methods in an assembly:

monodis --method <path/to/assembly.exe>

% Show a list of resources embedded within an assembly:

monodis --manifest <path/to/assembly.dll>

% Extract all the embedded resources to the current directory:

monodis --mresources <path/to/assembly.dll>
% monop

% Show the structure of a Type built-in of the .NET Framework:

monop <System.String>

% List the types in an assembly:

monop -r:<path/to/assembly.exe>

% Show the structure of a Type in a specific assembly:

monop -r:<path/to/assembly.dll> <Namespace.Path.To.Type>

% Only show members defined in the specified Type:

monop -r:<path/to/assembly.dll> --only-declared <Namespace.Path.To.Type>

% Show private members:

monop -r:<path/to/assembly.dll> --private <Namespace.Path.To.Type>

% Hide obsolete members:

monop -r:<path/to/assembly.dll> --filter-obsolete <Namespace.Path.To.Type>

% List the other assemblies that a specified assembly references:

monop -r:<path/to/assembly.dll> --refs
% montage

% Tile images into a grid, automatically resizing images larger than the grid cell size:

montage <image1.png> <image2.jpg> <imageN.png> montage.jpg

% Tile images into a grid, automatically calculating the grid cell size from the largest image:

montage <image1.png> <image2.jpg> <imageN.png> -geometry +0+0 montage.jpg

% Set the grid cell size and resize images to fit it before tiling:

montage <image1.png> <image2.jpg> <imageN.png> -geometry 640x480+0+0 montage.jpg

% Limit the number of rows and columns in the grid, causing input images to overflow into multiple output montages:

montage <image1.png> <image2.jpg> <imageN.png> -geometry +0+0 -tile 2x3 montage_%d.jpg

% Resize and crop images to completely fill their grid cells before tiling:

montage <image1.png> <image2.jpg> <imageN.png> -geometry +0+0 -resize 640x480^ -gravity center -crop 640x480+0+0 montage.jpg
% more

% Open a file:

more <source_file>

% Page down:

<Space>

% Search for a string (press `n` to go to the next match):

/<something>

% Exit:

q
% moro

% Invoke `moro` without parameters, to set the current time as the start of the working day:

moro

% Specify a custom time for the start of the working day:

moro hi <09:30>

% Invoke `moro` without parameters a second time, to set the current time at the end of the working day:

moro

% Specify a custom time for the end of the working day:

moro bye <17:30>

% Add a note on the current working day:

moro note <3 hours on project Foo>

% Show a report of time logs and notes for the current working day:

moro report

% Show a report of time logs and notes for all working days on record:

moro report --all
% mosh

% Connect to a remote server:

mosh <username>@<remote_host>

% Connect to a remote server with a specific identity (private key):

mosh --ssh="ssh -i </path/to/key_file>" <username>@<remote_host>

% Connect to a remote server using a specific port:

mosh --ssh="ssh -p <2222>" <username>@<remote_host>

% Run a command on a remote server:

mosh <remote_host> -- <command -with -flags>

% Select Mosh UDP port (useful when `<remote_host>` is behind a NAT):

mosh -p <124> <username>@<remote_host>

% Usage when `mosh-server` binary is outside standard path:

mosh --server=</path/to/bin/>mosh-server <remote_host>
% mosquitto

% Start mosquitto:

mosquitto

% Specify a configuration file to use:

mosquitto --config-file <path/to/file.conf>

% Listen on a specific port:

mosquitto --port <8883>

% Daemonize by forking into the background:

mosquitto --daemon
% mosquitto_passwd

% Add a new user to a password file (will prompt to enter the password):

mosquitto_passwd <path/to/password_file> <username>

% Create the password file if it doesn't already exist:

mosquitto_passwd -c <path/to/password_file> <username>

% Delete the specified username instead:

mosquitto_passwd -D <path/to/password_file> <username>

% Upgrade an old plain-text password file to a hashed password file:

mosquitto_passwd -U <path/to/password_file>
% mosquitto_pub

% Publish a temperature value of 32 on the topic `sensors/temperature` to 192.168.1.1 (defaults to `localhost`) with Quality of Service (`QoS`) set to 1:

mosquitto_pub -h <192.168.1.1> -t <sensors/temperature> -m <32> -q <1>

% Publish timestamp and temperature data on the topic `sensors/temperature` to a remote host on a non-standard port:

mosquitto_pub -h <192.168.1.1> -p <1885> -t <sensors/temperature> -m <"1266193804 32">

% Publish light switch status and retain the message on the topic `switches/kitchen_lights/status` to a remote host because there may be a long period of time between light switch events:

mosquitto_pub -r -h <"iot.eclipse.org"> -t <switches/kitchen_lights/status> -m <"on">

% Send the contents of a file (`data.txt`) as a message and publish it to `sensors/temperature` topic:

mosquitto_pub -t <sensors/temperature> -f <data.txt>

% Send the contents of a file (`data.txt`), by reading from `stdin` and send the entire input as a message and publish it to `sensors/temperature` topic:

mosquitto_pub -t <sensors/temperature> -s < <data.txt>

% Read newline delimited data from `stdin` as a message and publish it to `sensors/temperature` topic:

<echo data.txt> | mosquitto_pub -t <sensors/temperature> -l
% mosquitto_sub

% Subscribe to the topic `sensors/temperature` information with Quality of Service (`QoS`) set to 1. (The default hostname is `localhost` and port `1883`):

mosquitto_sub -t <sensors/temperature> -q <1>

% Subscribe to all broker status messages publishing on `iot.eclipse.org` port `1885` and print published messages verbosely:

mosquitto_sub -v -h "iot.eclipse.org" -p 1885 -t <\$SYS/#>

% Subscribe to multiple topics matching a given pattern. (+ takes any metric name):

mosquitto_sub -t <sensors/machines/+/temperature/+>
% most

% Open a file:

most <path/to/file>

% Open several files:

most <path/to/file1> <path/to/file2>

% Open a file at the first occurrence of "string":

most <file> +/<string>

% Move through opened files:

:O n

% Jump to the 100th line:

<100>j

% Edit current file:

e

% Split the current window in half:

<CTRL-x> o

% Exit:

Q
% mount

% Show all mounted filesystems:

mount

% Mount a device to a directory:

mount -t <filesystem_type> <path/to/device_file> <path/to/target_directory>

% Mount a CD-ROM device (with the filetype ISO9660) to /cdrom (readonly):

mount -t <iso9660> -o ro </dev/cdrom> </cdrom>

% Mount all the filesystem defined in /etc/fstab:

mount -a

% Mount a specific filesystem described in /etc/fstab (e.g. "/dev/sda1 /my_drive ext2 defaults 0 2"):

mount </my_drive>

% Mount a directory to another directory:

mount --bind <path/to/old_dir> <path/to/new_dir>
% mp4box

% Display information about an existing MP4 file:

mp4box -info <filename>

% Add an SRT subtitle file into an MP4 file:

mp4box -add <input_subs.srt>:lang=eng -add <input.mp4> <output.mp4>

% Combine audio from one file and video from another:

mp4box -add <input1.mp4>#audio -add <input2.mp4>#video <output.mp4}
% mpc

% Toggle play/pause:

mpc toggle

% Stop playing:

mpc stop

% Show information about the currently playing song:

mpc status

% Play next song:

mpc next

% Play previous song:

mpc prev

% Forward or rewind the currently playing song:

mpc [+-]<seconds>
% mpv

% Play a video or audio file:

mpv <file>

% Jump backward/forward 5 seconds:

LEFT <or> RIGHT

% Jump backward/forward 1 minute:

DOWN <or> UP

% Decrease or increase playback speed by 10 %:

[ <or> ]

% Play a file at a specified speed (0.01 to 100, default 1):

mpv --speed <speed> <file>

% Play a file using a profile defined in the `mpv.conf` file:

mpv --profile <profile_name> <file>
% mr

% Register a repository:

mr register

% Update repositories in 5 concurent jobs:

mr -j<5> update

% Print the status of all repositories:

mr status

% Checkout all repositories to the latest version:

mr checkout
% msbuild

% Build the first project file in the current directory:

msbuild

% Build a specific project file:

msbuild <path/to/project_file>

% Set one or more semicolon-separated targets to build:

msbuild <path/to/project_file> /target:<targets>

% Set one or more semicolon-separated properties:

msbuild <path/to/project_file> /property:<name=value>

% Set the build tools version to use:

msbuild <path/to/project_file> /toolsversion:<version>

% Display detailed information at the end of the log about how the project was configured:

msbuild <path/to/project_file> /detailedsummary

% Display detailed help information:

msbuild /help
% msfvenom

% List payloads:

msfvenom -l payloads

% List formats:

msfvenom -l formats

% Show payload options:

msfvenom -p <payload> --list-options

% Create an ELF binary with a reverse TCP handler:

msfvenom -p linux/x64/meterpreter/reverse_tcp LHOST=<local_ip> LPORT=<local_port> -f elf > <path/to/binary>

% Create an EXE binary with a reverse TCP handler:

msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=<local_ip> LPORT=<local_port> -f exe > <path/to/binary.exe>
% msmtp

% Send an email using the default account configured in `~/.msmtprc`:

echo <"Hello world"> | msmtp <to@example.org>

% Send an email using a specific account configured in `~/.msmtprc`:

echo <"Hello world"> | msmtp --account=<account_name> <to@example.org>

% Send an email without a configured account. The password should be specified in the `~/.msmtprc` file:

echo <"Hello world"> | msmtp --host=<localhost> --port=<999> --from=<from@example.org> <to@example.org>
% mtr

% Traceroute to a host and continuously ping all intermediary hops:

mtr <host>

% Disable IP address and host name mapping:

mtr -n <host>

% Generate output after pinging each hop 10 times:

mtr -w <host>

% Force IP IPv4 or IPV6:

mtr -4 <host>

% Wait for a given time (in seconds) before sending another packet to the same hop:

mtr -i <seconds> <host>
% multitail

% Tail all files matching a pattern in a single stream:

multitail -Q 1 '<pattern>'

% Tail all files in a directory in a single stream:

multitail -Q 1 '<directory>/*'

% Automatically add new files to a window:

multitail -Q <pattern>

% Show 5 logfiles while merging 2 and put them in 2 columns with only one in the left column:

multitail -s 2 -sn 1,3 <mergefile> -I <file1> <file2> <file3> <file4>
% mutool

% Convert pages 1-10 into 10 PNG images:

mutool convert -o <image%d.png> <file.pdf> <1-10>

% Convert pages 2, 3 and 5 of a PDF into text in the standard output:

mutool draw -F <txt> <file.pdf> <2,3,5>

% Concatenate two PDFs:

mutool merge -o <output.pdf> <input1.pdf> <input2.pdf>

% Query information about all content embedded in a PDF:

mutool info <input.pdf>

% Extract all images, fonts and resources embedded in a PDF out into the current directory:

mutool extract <input.pdf>
% mutt

% Open the specified mailbox:

mutt -f <mailbox>

% Send an email and specify a subject and a cc recipient:

mutt -s <subject> -c <cc@example.com> <recipient@example.com>

% Send an email with files attached:

mutt -a <file1> <file2> -- <recipient@example.com>

% Specify a file to include as the message body:

mutt -i <file> <recipient@example.com>

% Specify a draft file containing the header and the body of the message, in RFC 5322 format:

mutt -H <file> <recipient@example.com>
% mv

% Move files in arbitrary locations:

mv <source> <target>

% Do not prompt for confirmation before overwriting existing files:

mv -f <source> <target>

% Prompt for confirmation before overwriting existing files, regardless of file permissions:

mv -i <source> <target>

% Do not overwrite existing files at the target:

mv -n <source> <target>

% Move files in verbose mode, showing files after they are moved:

mv -v <source> <target>
% mvn

% Compile a project:

mvn compile

% Compile and package the compiled code in its distributable format, such as a `jar`:

mvn package

% Compile and package, skipping unit tests:

mvn package -Dmaven.test.skip=true

% Install the built package in local maven repository. (This will invoke the compile and package commands too):

mvn install

% Delete build artifacts from the target directory:

mvn clean

% Do a clean and then invoke the package phase:

mvn clean package

% Clean and then package the code with a given build profile:

mvn clean -P<profile> package

% Run a class with a main method:

mvn exec:java -Dexec.mainClass="<com.example.Main>" -Dexec.args="<arg1 arg2>"
% mycli

% Connect to a local database on port 3306, using the current user's username:

mycli <database_name>

% Connect to a database (user will be prompted for a password):

mycli -u <username> <database_name>

% Connect to a database on another host:

mycli -h <database_host> -P <port> -u <username> <database_name>
% mysqldump

% Create a backup (user will be prompted for a password):

mysqldump --user <user> --password <database_name> -r <path/to/file.sql>

% Backup all databases redirecting the output to a file (user will be prompted for a password):

mysqldump --user <user> --password --all-databases > <path/to/file.sql>
% mysql

% Connect to a database:

mysql <database_name>

% Connect to a database, user will be prompted for a password:

mysql -u <user> --password <database_name>

% Connect to a database on another host:

mysql -h <database_host> <database_name>

% Connect to a database through a Unix socket:

mysql --socket <path/to/socket.sock>

% Execute SQL statements in a script file (batch file):

mysql -e "source <filename.sql>" <database_name>

% Restore a database from a backup (user will be prompted for a password):

mysql --user <user> --password <database_name> < <path/to/backup.sql>

% Restore all databases from a backup (user will be prompted for a password):

mysql --user <user> --password < <path/to/backup.sql>
% mytop

% Start mytop:

mytop

% Connect with a specified username and password:

mytop -u <user> -p <password>

% Connect with a specified username (the user will be prompted for a password):

mytop -u <user> --prompt

% Do not show any idle (sleeping) threads:

mytop -u <user> -p <password> --noidle
% nano

% Open a specific file:

nano <path/to/file>

% Open a file positioning the cursor at the specified line and column:

nano +<line>,<column> <path/to/file>

% Enable smooth scrolling:

nano -S <filename>

% Indent new lines to the previous lines' indentation:

nano -i <filename>
% nasm

% Assemble `source.asm` into a binary file `source`, in the (default) raw binary format:

nasm <source.asm>

% Assemble `source.asm` into a binary file `output_file`, in the specified format:

nasm -f <format> <source.asm> -o <output_file>

% List valid output formats (along with basic nasm help):

nasm -hf

% Assemble and generate an assembly listing file:

nasm -l <list_file> <source.asm>

% Add a directory (must be written with trailing slash) to the include file search path before assembling:

nasm -i </path/to/include_dir/> <source.asm>
% nc

% Listen on a specified port and print any data received:

nc -l <port>

% Connect to a certain port (you can then write to this port):

nc <ip_address> <port>

% Set a timeout:

nc -w <timeout_in_seconds> <ipaddress> <port>

% Serve a file:

nc -l <port> < <file>

% Receive a file:

nc <ip_address> <port> > <file>

% Server stay up after client detach:

nc -k -l <port>

% Client stay up after EOF:

nc -q <timeout> <ip_address>

% Scan the open ports of a specified host:

nc -v -z <ip_address> <port>

% Act as proxy and forward data from a local TCP port to the given remote host:

nc -l <local_port> | nc <hostname> <remote_port>
% ncmpcpp

% Connect to a music player daemon on a given host and port:

ncmpcpp --host <ip> --port <port>

% Display metadata of the current song to console:

ncmpcpp --current-song

% Use a specified configuration file:

ncmpcpp --config <file>

% Use a different set of key bindings from a file:

ncmpcpp --bindings <file>
% ned

% Recursively search starting in the current directory, ignoring case:

ned --ignore-case --recursive '<^[dl]og>' <.>

% Search always showing colored output:

ned --colors '<^[dl]og>' <.>

% Search never showing colored output:

ned --colors=never '<^[dl]og>' <.>

% Search ignoring certain files:

ned --recursive --exclude '<*.htm>' '<^[dl]og>' <.>

% Simple replace:

ned '<dog>' --replace '<cat>' <.>

% Replace using numbered group references:

ned '<the ([a-z]+) dog and the ([a-z]+) dog>' --replace '<the $2 dog and the $1 dog>' <.>

% Replace changing case:

ned '<([a-z]+) dog>' --case-replacements --replace '<\U$1\E! dog>' --stdout <.>

% Preview results of a find and replace without updating the target files:

ned '<^[sb]ad>' --replace '<happy>' --stdout <.>
% neofetch

% Return the default config, and create it if it's the first time the program runs:

neofetch

% Trigger an info line from appearing in the output, where 'infoname' is the function name in the config file, e.g. memory:

neofetch --<enable|disable> <infoname>

% Hide/Show OS architecture:

neofetch --os_arch <on|off>

% Enable/Disable CPU brand in output:

neofetch --cpu_brand <on|off>
% netlify

% Login to the Netlify account:

netlify login

% Deploy the contents of a directory to Netlify:

netlify deploy

% Configure continuous deployment for a new or an existing site:

netlify init

% Start a local dev server:

netlify dev
% nextflow

% Run a pipeline, use cached results from previous runs:

nextflow run <main.nf> -resume

% Run a specific release of a remote workflow from GitHub:

nextflow run <user/repo> -revision <release_tag>

% Run with a given work directory for intermediate files, save execution report:

nextflow run <workflow> -work-dir </path/to/directory> -with-report <report.html>

% Show details of previous runs in current directory:

nextflow log

% Remove cache and intermediate files for a specific run:

nextflow clean -force <run_name>

% List all downloaded projects:

nextflow list

% Pull the latest version of a remote workflow from Bitbucket:

nextflow pull <user/repo> -hub bitbucket

% Update Nextflow:

nextflow self-update
% nf-core

% List existing pipelines on nf-core:

nf-core list

% Create a new pipeline skeleton:

nf-core create

% Lint the pipeline code:

nf-core lint <path/to/directory>

% Bump software versions in pipeline recipe:

nf-core bump-version <path/to/directory> <new_version>

% Launch an nf-core pipeline:

nf-core launch <pipeline_name>

% Download an nf-core pipeline for offline use:

nf-core download <pipeline_name>
% nginx

% Start server with the default config file:

nginx

% Start server with a custom config file:

nginx -c <config_file>

% Start server with a prefix for all relative paths in the config file:

nginx -c <config_file> -p <prefix/for/relative/paths>

% Test the configuration without affecting the running server:

nginx -t

% Reload the configuration by sending a signal with no downtime:

nginx -s reload
% ng

% Create a new Angular application inside a directory:

ng new <project_name>

% Add a new component to one's application:

ng generate component <component_name>

% Add a new class to one's application:

ng generate class <class_name>

% Add a new directive to one's application:

ng generate directive <directive_name>

% Run the application with the following command in its root directory:

ng serve

% Build the application:

ng build

% Run unit tests:

ng test

% Check the version of your current Angular installation:

ng version
% ngrep

% Capture traffic of all interfaces:

ngrep -d any

% Capture traffic of a specific interface:

ngrep -d <eth0>

% Capture traffic crossing port 22 of interface eth0:

ngrep -d <eth0> port <22>

% Capture traffic from or to a host:

ngrep host <www.example.com>

% Filter keyword 'User-Agent:' of interface eth0:

ngrep -d <eth0> '<User-Agent:>'
% ngrok

% Expose a local HTTP service on a given port:

ngrok http <80>

% Expose a local HTTP service on a specific host:

ngrok http <foo.dev>:<80>

% Expose a local HTTPS server:

ngrok http https://localhost

% Expose TCP traffic on a given port:

ngrok tcp <22>

% Expose TLS traffic for a specific host and port:

ngrok tls -hostname=<foo.com> <443>
% nice

% Launch a program with altered priority:

nice -n <niceness_value> <command>
% nikto

% Perform a basic Nikto scan against a target host:

perl nikto.pl -h <192.168.0.1>

% Specify the port number when performing a basic scan:

perl nikto.pl -h <192.168.0.1> -p <443>

% Scan ports and protocols with full URL syntax:

perl nikto.pl -h <https://192.168.0.1:443/>

% Scan multiple ports in the same scanning session:

perl nikto.pl -h <192.168.0.1> -p <80,88,443>

% Update to the latest plugins and databases:

perl nikto.pl -update
% nimble

% Search for packages:

nimble search <search_string>

% Install a package:

nimble install <package_name>

% List installed packages:

nimble list -i

% Create a new Nimble package in the current directory:

nimble init

% Build a Nimble package:

nimble build

% Install a Nimble package:

nimble install
% nim

% Compile a source file:

nim compile <file.nim>

% Compile and run a source file:

nim compile -r <file.nim>

% Compile a source file with release optimizations enabled:

nim compile -d:release <file.nim>

% Build a release binary optimized for low file size:

nim compile -d:release --opt:size <file.nim>

% Generate HTML documentation for a module (output will be placed in the current directory):

nim doc <file.nim>
% ninja

% Build in the current directory:

ninja

% Build a program in a given directory:

ninja -C <path/to/directory>

% Show targets (e.g. `install` and `uninstall`):

ninja -t targets

% Show help:

ninja -h
% nix-build

% Build a Nix expression:

nix-build --attr <expression_name>

% Build a sandboxed Nix expression (on non-nixOS):

nix-build --attr <expression_name> --option sandbox true
% nix-collect-garbage

% Delete all store paths unused by current generations of each profile:

sudo nix-collect-garbage --delete-old

% Simulate the deletion of old store paths:

sudo nix-collect-garbage --delete-old --dry-run

% Delete all store paths older than 30 days:

sudo nix-collect-garbage --delete-older-than <30d>
% nix-env

% List all installed packages:

nix-env -q

% Query installed packages:

nix-env -q <search_term>

% Query available packages:

nix-env -qa <search_term>

% Install package:

nix-env -i <pkg_name>

% Install a package from a URL:

nix-env -i <pkg_name> --file <example.com>

% Uninstall package:

nix-env -e <pkg_name>

% Upgrade one package:

nix-env -u <pkg_name>

% Upgrade all packages:

nix-env -u
% nix

% Search for a package via its name or description:

nix search <search_term>

% Start a Nix shell with the specified packages available:

nix run <nixpkgs.pkg1 nixpkgs.pkg2 nixpkgs.pkg3...>

% Optimise Nix store disk usage by combining duplicate files:

nix optimise-store

% Start an interactive environment for evaluating Nix expressions:

nix repl

% Upgrade Nix to the latest stable version:

nix upgrade-nix
% nkf

% Convert to UTF-8 encoding:

nkf -w <path/to/file.txt>

% Convert to SHIFT_JIS encoding:

nkf -s <path/to/file.txt>

% Convert to UTF-8 encoding and overwrite the file:

nkf -w --overwrite <path/to/file.txt>

% Set new line code to LF and overwrite (unix type):

nkf -d --overwrite <path/to/file.txt>

% Set new line code to CRLF and overwrite (windows type):

nkf -c --overwrite <path/to/file.txt>

% Decrypt mime file and overwrite:

nkf -m --overwrite <path/to/file.txt>
% nl

% Number non-blank lines in a file:

nl <file>

% Read from standard output:

cat <file> | nl <options> -

% Number only the lines with printable text:

nl -t <file>

% Number all lines including blank lines:

nl -b a <file>

% Number only the body lines that match a basic regular expression (BRE) pattern:

nl -b p'FooBar[0-9]' <file>
% nmap

% Try to determine whether the specified hosts are up and what are their names:

nmap -sn <ip_or_hostname> <optional_another_address>

% Like above, but also run a default 1000-port TCP scan if host seems up:

nmap <ip_or_hostname> <optional_another_address>

% Also enable scripts, service detection, OS fingerprinting and traceroute:

nmap -A <address_or_addresses>

% Assume good network connection and speed up execution:

nmap -T4 <address_or_addresses>

% Scan a specific list of ports (use -p- for all ports 1-65535):

nmap -p <port1,port2,…,portN> <address_or_addresses>

% Perform TCP and UDP scanning (use -sU for UDP only, -sZ for SCTP, -sO for IP):

nmap -sSU <address_or_addresses>

% Perform TLS cipher scan against a host to determine supported ciphers and SSL/TLS protocols:

nmap --script ssl-enum-ciphers <address_or_addresses> -p 443
% node

% Run a JavaScript file:

node <file>.js

% Start a REPL (interactive shell):

node

% Evaluate JavaScript by passing it in the command:

node -e "<code>"

% Evaluate and print result, useful to see node's dependencies versions:

node -p "<process.versions>"
% nohup

% Run process that can live beyond the terminal:

nohup <command options>
% nokogiri

% Parse the contents of a url or file:

nokogiri <url|path/to/file>

% Parse as a specific type:

nokogiri <url|path/to/file> --type <xml|html>

% Load a specific initialisation file before parsing:

nokogiri <url|path/to/file> -C <path/to/config_file>

% Parse using a specific encoding:

nokogiri <url|path/to/file> --encoding <encoding>

% Validate using a RELAX NG file:

nokogiri <url|path/to/file> --rng <url|path/to/file>
% noti

% Display a notification when tar finishes compressing files:

noti <tar -cjf example.tar.bz2 example/>

% Display a notification even when you put it after the command to watch:

<command_to_watch>; noti

% Monitor a process by PID and trigger a notification when the PID disappears:

noti -w <process_id>
% now

% Deploy the current directory:

now

% Display a list of deployments:

now list

% Display information related to a deployment:

now inspect <deployment_url>

% Remove a deployment:

now remove <deployment_id>

% Log in into an account or create a new one:

now login

% Initialize an example project (a new directory will be created):

now init
% npm-check

% Display a report of outdated, incorrect, and unused dependencies:

npm-check

% Interactively update out-of-date packages:

npm-check --update

% Update everything without prompting:

npm-check --update-all

% Don't check for unused packages:

npm-check --skip-unused
% npm

% Interactively create a package.json file:

npm init

% Download all the packages listed as dependencies in package.json:

npm install

% Download a specific version of a package and add it to the list of dependencies in package.json:

npm install <module_name>@<version>

% Download a package and add it to the list of dev dependencies in package.json:

npm install <module_name> --save-dev

% Download a package and install it globally:

npm install -g <module_name>

% Uninstall a package and remove it from the list of dependencies in package.json:

npm uninstall <module_name>

% Print a tree of locally-installed dependencies:

npm list

% List top-level globally installed modules:

npm list -g --depth=<0>
% npm-why

% Show why an npm package is installed:

npm-why <package-name>
% nproc

% Display the number of available processing units:

nproc

% Display the number of installed processing units, including any inactive ones:

nproc --all

% If possible, subtract a given number of units from the returned value:

nproc --ignore <count>
% npx

% Execute the binary from a given npm module:

npx <module_name>

% In case a package has multiple binaries, specify the package name along with the binary:

npx -p <package_name> <module_name>

% View help contents:

npx --help
% nrm

% List all registries:

nrm ls

% Change to a particular registry:

nrm use <registry>

% Show the response time for all registries:

nrm test

% Add a custom registry:

nrm add <registry> <url>

% Delete a registry:

nrm del <registry>
% nslookup

% Query your system's default name server for an IP address (A record) of the domain:

nslookup <example.com>

% Query a given name server for a NS record of the domain:

nslookup -type=NS <example.com> <8.8.8.8>

% Query for a reverse lookup (PTR record) of an IP address:

nslookup -type=PTR <54.240.162.118>

% Query for ANY available records using TCP protocol:

nslookup -vc -type=ANY <example.com> 

% Query a given name server for the whole zone file (zone transfer) of the domain using TCP protocol:

nslookup -vc -type=AXFR <example.com> <name_server>

% Query for a mail server (MX record) of the domain, showing details of the transaction:

nslookup -type=MX -debug <example.com>

% Query a given name server on a specific port number for a TXT record of the domain:

nslookup -port=<port_number> -type=TXT <example.com> <name_server>
% numfmt

% Convert 1.5K (SI Units) to 1500:

numfmt --from=<si> <1.5K>

% Convert 5th field (1-indexed) to IEC Units without converting header:

ls -l | numfmt --header=<1> --field=<5> --to=<iec>

% Convert to IEC units, pad with 5 characters, left aligned:

du -s * | numfmt --to=<iec> --format=<"%-5f">
% nvim

% Open a file:

nvim <file>

% Enter text editing mode (insert mode):

<Esc>i

% Copy ("yank") or cut ("delete") the current line (paste it with `P`):

<Esc><yy|dd>

% Undo the last operation:

<Esc>u

% Search for a pattern in the file (press `n`/`N` to go to next/previous match):

<Esc>/<search_pattern><Enter>

% Perform a regex substitution in the whole file:

<Esc>:%s/<pattern>/<replacement>/g<Enter>

% Save (write) the file, and quit:

<Esc>:wq<Enter>

% Quit without saving:

<Esc>:q!<Enter>
% nvm

% Install a specific version of Node.js:

nvm install <node_version>

% Use a specific version of Node.js in the current shell:

nvm use <node_version>

% Set the default Node.js version:

nvm alias default <node_version>

% List all available Node.js versions and highlight the default one:

nvm list

% Uninstall a given Node.js version:

nvm uninstall <node_version>

% Launch the REPL of a specific version of Node.js:

nvm run <node_version> --version

% Execute a script in a specific version of Node.js:

nvm exec <node_version> node <app.js>
% objdump

% Display the file header information:

objdump -f <binary>

% Display the dis-assembled output of executable sections:

objdump -d <binary>

% Display a complete binary hex dump of all sections:

objdump -s <binary>
% ocamlc

% Create a binary from a source file:

ocamlc <path/to/source_file.ml>

% Create a named binary from a source file:

ocamlc -o <path/to/binary> <path/to/source_file.ml>
% ocaml

% Read OCaml commands from the user and execute them:

ocaml

% Read OCaml commands from a file and execute them:

ocaml <path/to/file.ml>
% oc

% Log in to the OpenShift Container Platform server:

oc login

% Create a new project:

oc new-project <project_name>

% Add a new application to a project:

oc new-app <repo_url> --name <application>

% Open a remote shell session to a container:

oc rsh <pod_name>

% List pods in a project:

oc get pods

% Logout from the current session:

oc logout
% od

% Display file using default settings: octal format, 8 bytes per line, byte offsets in octal, and duplicate lines replaced with `*`:

od <path/to/file>

% Display file in verbose mode, i.e. without replacing duplicate lines with `*`:

od -v <path/to/file>

% Display file in hexadecimal format (2-byte units), with byte offsets in decimal format:

od --format=<x> --address-radix=<d> -v <path/to/file>

% Display file in hexadecimal format (1-byte units), and 4 bytes per line:

od --format=<x1> --width=<4> -v <path/to/file>

% Display file in hexadecimal format along with its character representation, and do not print byte offsets:

od --format=<xz> --address-radix=<n> -v <path/to/file>

% Read only 100 bytes of a file starting from the 500th byte:

od --read-bytes <100> --skip-bytes=<500> -v <path/to/file>
% odps auth

% Add a user to the current project:

add user <username>;

% Grant a set of authorities to a user:

grant <action_list> on <object_type> <object_name> to user <username>;

% Show authorities of a user:

show grants for <username>;

% Create a user role:

create role <role_name>;

% Grant a set of authorities to a role:

grant <action_list> on <object_type> <object_name> to role <role_name>;

% Describe authorities of a role:

desc role <role_name>;

% Grant a role to a user:

grant <role_name> to <username>;
% odps func

% Show functions in the current project:

list functions;

% Create a Java function using a .jar resource:

create function <func_name> as <path.to.package.Func> using '<package.jar>';

% Create a Python function using a .py resource:

create function <func_name> as <script.Func> using '<script.py>';

% Delete a function:

drop function <func_name>;
% odps inst

% Show instances created by current user:

show instances;

% Describe the details of an instance:

desc instance <instance_id>;

% Check the status of an instance:

status <instance_id>;

% Wait on the termination of an instance, printing log and progress information until then:

wait <instance_id>;

% Kill an instance:

kill <instance_id>;
% odps

% Start the command line with a custom configuration file:

odpscmd --config=<odps_config.ini>

% Switch current project:

use <project_name>;

% Show tables in the current project:

show tables;

% Describe a table:

desc <table_name>;

% Show table partitions:

show partitions <table_name>;

% Describe a partition:

desc <table_name> partition (<partition_spec>);
% odps resource

% Show resources in the current project:

list resources;

% Add file resource:

add file <file_name> as <alias>;

% Add archive resource:

add archive <archive.tar.gz> as <alias>;

% Add .jar resource:

add jar <package.jar>;

% Add .py resource:

add py <script.py>;

% Delete resource:

drop resource <resource_name>;
% odps table

% Create a table with partition and lifecycle:

create table <table_name> (<col> <type>) partitioned by (<col> <type>) lifecycle <days>;

% Create a table based on the definition of another table:

create table <table_name> like <another_table>;

% Add partition to a table:

alter table <table_name> add partition (<partition_spec>);

% Delete partition from a table:

alter table <table_name> drop partition (<partition_spec>);

% Delete table:

drop table <table_name>;
% odps tunnel

% Download table to local file:

tunnel download <table_name> <file>;

% Upload local file to a table partition:

tunnel upload <file> <table_name>/<partition_spec>;

% Upload table specifying field and record delimiters:

tunnel upload <file> <table_name> -fd <field_delim> -rd <record_delim>;

% Upload table using multiple threads:

tunnel upload <file> <table_name> -threads <num>;
% ogr2ogr

% Convert a Shapefile into a GeoPackage:

ogr2ogr -f GPKG <output>.gpkg <input>.shp

% Change coordinate reference system of a GeoPackage from `EPSG:4326` to `EPSG:3857`:

ogr2ogr -s_srs <EPSG:4326> -t_srs <EPSG:3857> -f GPKG <output>.gpkg <input>.gpkg

% Convert a CSV file into a GeoPackage, specifying the names of the coordinate columns and assigning a coordinate reference system:

ogr2ogr -f GPKG <output>.gpkg <input>.csv -oo X_POSSIBLE_NAMES=<longitude> -oo Y_POSSIBLE_NAMES=<latitude> -a_srs <EPSG:4326>

% Load a GeoPackage into a PostGIS database:

ogr2ogr -f "PostgreSQL" PG:dbname="<database_name>" <input>.gpkg

% Clip layers of a GeoPackage file to the given bounding box:

ogr2ogr -spat <min_x> <min_y> <max_x> <max_y> -f GPKG <output>.gpkg <input>.gpkg
% ogrinfo

% List layers of a GeoPackage:

ogrinfo <input>.gpkg

% Get detailed information about a specific layer of a GeoPackage:

ogrinfo <input>.gpkg <layer_name>

% Only show summary information about a specific layer of a GeoPackage:

ogrinfo -so <input>.gpkg <layer_name>
% omf

% Install one or more packages:

omf install <name>

% List installed packages:

omf list

% List available themes:

omf theme

% Apply a theme:

omf theme <name>

% Remove a theme or package:

omf remove <name>

% Uninstall Oh My Fish:

omf destroy
% opam

% Initialize opam for first use:

opam init

% Search for packages:

opam search <package_name>

% Install a package and all of its dependencies:

opam install <package_name>

% Display detailed information about a package:

opam show <package_name>

% List all installed packages:

opam list

% Update the local package database:

opam update

% Upgrade all installed packages:

opam upgrade

% Display all commands:

opam help
% openssl

% Generate a 2048bit RSA private key and save it to a file:

openssl genrsa -out <filename.key> 2048

% Generate a certificate signing request to be sent to a certificate authority:

openssl req -new -sha256 -key <filename.key> -out <filename.csr>

% Generate a self-signed certificate from a certificate signing request valid for some number of days:

openssl x509 -req -days <days> -in <filename.csr> -signkey <filename.key> -out <filename.crt>

% Display certificate information:

openssl x509 -in <filename.crt> -noout -text

% Display a certificate's expiration date:

openssl x509 -enddate -noout -in <filename.pem>

% Display the start and expiry dates for a domain's certificate:

openssl s_client -connect <host>:<port> 2>/dev/null | openssl x509 -noout -dates

% Display the certificate presented by an SSL/TLS server:

openssl s_client -connect <host>:<port> </dev/null

% Display the complete certificate chain of an HTTPS server:

openssl s_client -connect <host>:443 -showcerts </dev/null
% optipng

% Compress a PNG with default settings:

optipng <path/to/file.png>

% Compress a PNG with best compression:

optipng -o<7> <path/to/file.png>

% Compress a PNG with fastest compression:

optipng -o<0> <path/to/file.png>

% Compress a PNG and add interlacing:

optipng -i <1> <path/to/file.png>

% Compress a PNG and preserve all metadata (including file timestamps):

optipng -preserve <path/to/file.png>

% Compress a PNG and remove all metadata:

optipng -strip all <path/to/file.png>
% opt

% Run an optimization or analysis on a bitcode file:

opt -<passname> <path/to/file.bc> -S -o <file_opt.bc>

% Output the Control Flow Graph of a function to a "dot" file:

opt <-dot-cfg> -S <path/to/file.bc> -disable-output

% Optimize the program at level 2 and output the result to another file:

opt -O2 <path/to/file.bc> -S -o <path/to/output_file.bc>
% p4

% Log in to the Perforce service:

p4 login -a

% Create a client:

p4 client

% Copy files from depot into the client workspace:

p4 sync

% Create or edit changelist description:

p4 change

% Open a file to edit:

p4 edit -c <changelist_number> <file_name>

% Open a new file to add it to the depot:

p4 add

% Display list of files modified by changelist:

p4 describe -c <changelist_number>

% Submit a changelist to the depot:

p4 submit -c <changelist_number>
% p5

% Create a new p5 collection:

p5 new <collection_name>

% Generate a new p5 project (should be run from collection directory):

p5 generate <project_name>

% Run the p5 manager server:

p5 server

% Update libraries to their latest versions:

p5 update
% p7zip

% Archive a file, replacing it with a 7zipped compressed version:

p7zip <path/to/file>

% Archive a file keeping the input file:

p7zip -k <path/to/file>

% Decompress a file, replacing it with the original uncompressed version:

p7zip -d <compressed.ext>.7z

% Decompress a file keeping the input file:

p7zip -d -k <compressed.ext>.7z

% Skip some checks and force compression or decompression:

p7zip -f <path/to/file>
% paci

% Update the list of available packages and versions (it's recommended to run this before other `paci` commands):

paci refresh

% Configure its behaviour:

paci configure

% Search for a given package:

paci search <package>

% Install a package:

paci install <package>

% Update a package:

paci update <package>
% packer

% Build an image:

packer build <path/to/config.json>

% Check the syntax of a Packer image config:

packer validate <path/to/config.json>
% pactl

% List all sinks (or other types - sinks are outputs and sink-inputs are active audio streams):

pactl list <sinks> short

% Change the default sink (output) to 1 (the number can be retrieved via the `list` subcommand):

pactl set-default-sink <1>

% Move sink-input 627 to sink 1:

pactl move-sink-input <627> <1>

% Set the volume of sink 1 to 75%:

pactl set-sink-volume <1> <0.75>

% Toggle mute on the default sink (using the special name `@DEFAULT_SINK@`):

pactl set-sink-mute <@DEFAULT_SINK@> toggle
% pageres

% Take multiple screenshots of multiple URLs at different resolutions:

pageres <https://example.com/> <https://example2.com/> <1366x768> <1600x900>

% Provide specific options for a URL, overriding global options:

pageres [<https://example.com/> <1366x768> --no-crop] [<https://example2.com/> <1024x768>] --crop

% Provide a custom filename template:

pageres <https://example.com/> <1024x768> --filename=<'<%= date %> - <%= url %>'>

% Capture a specific element on a page:

pageres <https://example.com/> <1366x768> --selector='<.page-header>'

% Hide a specific element:

pageres <https://example.com/> <1366x768> --hide='<.page-header>'

% Capture a screenshot of a local file:

pageres <local_file_path.html> <1366x768>
% pamixer

% List all sinks and sources with their corresponding IDs:

pamixer --list-sinks --list-sources

% Set the volume to 75% on the default sink:

pamixer --set-volume <75>

% Toggle mute on a sink other than the default:

pamixer --toggle-mute --sink <ID>

% Increase the volume on default sink by 5%:

pamixer --increase <5>

% Decrease the volume on a source by 5%:

pamixer --decrease <5> --source <ID>

% Use the allow boost option to increase, decrease, or set the volume above 100%:

pamixer --set-volume <105> --allow-boost

% Mute the default sink (use `--unmute` instead to unmute):

pamixer --mute
% pandoc

% Convert file to pdf (the output format is determined by file extension):

pandoc <input.md> -o <output.pdf>

% Force conversion to use a specific format:

pandoc <input.docx> --to <gfm> -o <output.md>

% Convert to a standalone file with the appropriate headers/footers (for LaTeX, HTML, etc.):

pandoc <input.md> -s -o <output.tex>

% List all supported input formats:

pandoc --list-input-formats

% List all supported output formats:

pandoc --list-output-formats
% parallel-lint

% Lint a specific directory:

parallel-lint <path/to/directory>

% Lint a directory using the specified number of parallel processes:

parallel-lint -j <processes> <path/to/directory>

% Lint a directory, excluding the specified directory:

parallel-lint --exclude <path/to/excluded_directory> <path/to/directory>

% Lint a directory of files using a comma-separated list of extension(s):

parallel-lint -e <php,html,phpt> <path/to/directory>

% Lint a directory and output the results as JSON:

parallel-lint --json <path/to/directory>

% Lint a directory and show Git Blame results for rows containing errors:

parallel-lint --blame <path/to/directory>
% parallel

% Gzip several files at once, using all cores:

parallel gzip ::: <file1> <file2> <file3>

% Read arguments from `stdin`, run 4 jobs at once:

ls *.txt | parallel -j4 gzip

% Convert JPG images to PNG using replacement strings:

parallel convert {} {.}.png ::: *.jpg

% Parallel xargs, cram as many args as possible onto one command:

<args> | parallel -X <command>

% Break stdin into ~1M blocks, feed each block to `stdin` of new command:

cat <big_file.txt> | parallel --pipe --block 1M <command>

% Run on multiple machines via SSH:

parallel -S <machine1>,<machine2> <command> ::: <arg1> <arg2>
% particle

% Log in or create an account for the Particle CLI:

particle setup

% Display a list of devices:

particle list

% Create a new Particle project interactively:

particle project create

% Compile a Particle project:

particle compile <device_type> <path/to/source_code.ino>

% Update a device to use a specific app remotely:

particle flash <device_name> <path/to/program.bin>

% Update a device to use the latest firmware via serial:

particle flash --serial <path/to/firmware.bin>

% Execute a function on a device:

particle call <device_name> <function_name> <function_arguments>
% pass

% Initialize the storage using a gpg-id for encryption:

pass init <gpg_id>

% Save a new password (prompts you for the value without echoing it):

pass insert <path/to/data>

% Copy a password (first line of the data file) to the clipboard:

pass -c <path/to/data>

% List the whole store tree:

pass

% Generate a new random password with a given length, and copy it to the clipboard:

pass generate -c <path/to/data> <num>

% Run any git command against the underlying store repository:

pass git <git_arguments>
% passwd

% Change the password of the current user interactively:

passwd

% Change the password of the current user:

passwd <new_password>

% Change the password of the specified user:

passwd <username> <new_password>

% Get the current status of the user:

passwd -S

% Make the password of the account blank (it will set the named account passwordless):

passwd -d
% pastel

% Convert colors from one format to another. Here from RGB to HSL:

pastel format <hsl> <ff8000>

% Show and analyze colors on the terminal:

pastel color "<rgb(255,50,127)>"

% Pick a color from somewhere on the screen:

pastel pick

% Generate a set of N visually distinct colors:

pastel distinct <8>

% Get a list of all X11 / CSS color names:

pastel list
% paste

% Join all the lines into a single line, using TAB as delimiter:

paste -s <file>

% Join all the lines into a single line, using the specified delimiter:

paste -s -d <delimiter> <file>

% Merge two files side by side, each in its column, using TAB as delimiter:

paste <file1> <file2>

% Merge two files side by side, each in its column, using the specified delimiter:

paste -d <delimiter> <file1> <file2>

% Merge two files, with lines added alternatively:

paste -d '\n' <file1> <file2>
% patch

% Apply a patch using a diff file (filenames must be included in the diff file):

patch < <patch.diff>

% Apply a patch to a specific file:

patch <path/to/file> < <patch.diff>

% Patch a file writing the result to a different file:

patch <path/to/input_file> -o <path/to/output_file> < <patch.diff>

% Apply a patch to the current directory:

patch -p1 < <patch.diff>

% Apply the reverse of a patch:

patch -R < <patch.diff>
% pathchk

% Check pathames for validity in the current system:

pathchk <path1 path2 …>

% Check pathnames for validity on a wider range of POSIX compliant systems:

pathchk -p <path1 path2 …>

% Check pathnames for validity on all POSIX compliant systems:

pathchk --portability <path1 path2 …>

% Only check for empty pathnames or leading dashes (-):

pathchk -P <path1 path2 …>
% pax

% List the contents of an archive:

pax -f <archive.tar>

% List the contents of a gzipped archive:

pax -zf <archive.tar.gz>

% Create an archive from files:

pax -wf <target.tar> <path/to/file1> <path/to/file2> <path/to/file3>

% Create an archive from files, using output redirection:

pax -w <path/to/file1> <path/to/file2> <path/to/file3> > <target.tar>

% Extract an archive into the current directory:

pax -rf <source.tar>

% Copy to a directory, while keeping the original metadata; `target/` must exist:

pax -rw <path/to/file1> <path/to/dir1> <path/to/dir2> <target/>
% pdfimages

% Extract all images from a PDF file and save them as PNGs:

pdfimages -png <path/to/file.pdf> <filename_prefix>

% Extract images from pages 3 to 5:

pdfimages -f <3> -l <5> <path/to/file.pdf> <filename_prefix>

% Extract images from a PDF file and include the page number in the output filenames:

pdfimages -p <path/to/file.pdf> <filename_prefix>

% List information about all the images in a PDF file:

pdfimages -list <path/to/file.pdf>
% pdfjoin

% Merge two PDFs:

pdfjoin <file1> <file2> --outfile <output_file>

% Save pages 3 to 5 followed by page 1 to a new PDF:

pdfjoin <file 3-5,1> --outfile <output_file>

% Merge subranges from two PDFs:

pdfjoin <file1 3-5,1> <file2 4-6> --outfile <output_file>
% pdflatex

% Compile a pdf document:

pdflatex <source.tex>

% Compile a pdf document specifying an output directory:

pdflatex -output-directory=<path/to/directory> <source.tex>

% Compile a pdf document, halting on each error:

pdflatex -halt-on-error <source.tex>
% pdfposter

% Convert an A2 poster into 4 A4 pages:

pdfposter --poster-size a2 <input_file.pdf> <output_file.pdf>

% Scale an A4 poster to A3 and then generate 2 A4 pages:

pdfposter --scale 2 <input_file.pdf> <output_file.pdf>
% pdftk

% Extract pages 1-3, 5 and 6-10 from a PDF file and save them as another one:

pdftk <input.pdf> cat <1-3 5 6-10> output <output.pdf>

% Merge (concatenate) a list of PDF files and save the result as another one:

pdftk <file1.pdf file2.pdf …> cat output <output.pdf>

% Split each page of a PDF file into a separate file, with a given filename output pattern:

pdftk <input.pdf> burst output <out_%d.pdf>

% Rotate all pages by 180 degrees clockwise:

pdftk <input.pdf> cat <1-endsouth> output <output.pdf>

% Rotate third page by 90 degrees clockwise and leave others unchanged:

pdftk <input.pdf> cat <1-2 3east 4-end> output <output.pdf>
% pdftocairo

% Convert a PDF file to JPEG:

pdftocairo <path/to/file.pdf> -jpeg

% Convert to PDF expanding the output to fill the paper:

pdftocairo <path/to/file.pdf> <output.pdf> -pdf -expand

% Convert to SVG specifying the first/last page to convert:

pdftocairo <path/to/file.pdf> <output.svg> -svg -f <first_page> -l <last_page>

% Convert to PNG with 200ppi resolution:

pdftocairo <path/to/file.pdf> <output.png> -png -r 200

% Convert to grayscale TIFF setting paper size to A3:

pdftocairo <path/to/file.pdf> -tiff -gray -paper A3

% Convert to PNG cropping x and y pixels from the top left corner:

pdftocairo <path/to/file.pdf> -png -x <x_pixels> -y <y_pixels>
% pdftotext

% Convert filename.pdf to plain text and print it to standard output:

pdftotext <filename.pdf> -

% Convert filename.pdf to plain text and save it as filename.txt:

pdftotext <filename.pdf>

% Convert filename.pdf to plain text and preserve the layout:

pdftotext -layout <filename.pdf>

% Convert input.pdf to plain text and save it as output.txt:

pdftotext <input.pdf> <output.txt>

% Convert pages 2, 3 and 4 of input.pdf to plain text and save them as output.txt:

pdftotext -f <2> -l <4> <input.pdf> <output.txt>
% pdfunite

% Merge 2 PDFs into a single PDF:

pdfunite <path/to/fileA.pdf> <path/to/fileB.pdf> <path/to/merged_output.pdf>

% Merge a directory of PDFs into a single PDF:

pdfunite <path/to/directory/*.pdf> <path/to/merged_output.pdf>
% peerflix

% Stream the largest media file in a torrent:

peerflix "<torrent_url|magnet_link>"

% List all streamable files contained in a torrent (given as a magnet link):

peerflix "<magnet:?xt=urn:btih:0123456789abcdef0123456789abcdef01234567>" --list

% Stream the largest file in a torrent, given as a torrent URL, to VLC:

peerflix "<http://example.net/music.torrent>" --vlc

% Stream the largest file in a torrent to MPlayer, with subtitles:

peerflix "<torrent_url|magnet_link>" --mplayer --subtitles <subtitle-file.srt>

% Stream all files from a torrent to Airplay:

peerflix "<torrent_url|magnet_link>" --all --airplay
% perl

% Parse and execute a Perl script:

perl <script.pl>

% Check syntax errors on a Perl script:

perl -c <script.pl>

% Parse and execute a Perl statement:

perl -e <perl_statement>

% Run a Perl script in debug mode, using `perldebug`:

perl -d <script.pl>

% Loo[p] over all lines of a file, editing them [i]n-place using a find/replace [e]xpression:

perl -p -i -e 's/<find>/<replace>/g' <filename>

% Run a find/replace expression on a file, saving the original file with a given extension:

perl -p -i'.old' -e 's/<find>/<replace>/g' <filename>

% Run a multi-line find/replace expression on a file, and save the result in another file:

perl -p0e 's/<foo\nbar>/<foobar>/g' <input_file> > <output_file>

% Run a regular expression on `stdin`, printing out the first capture group for each line:

cat <path/to/input_file> | perl -nle 'if (/.*(<foo>).*/) {print "$1"; last;}'
% pg_ctl

% Initialize a new PostgreSQL database cluster:

pg_ctl -D <data_directory> init

% Start a PostgreSQL server:

pg_ctl -D <data_directory> start

% Stop a PostgreSQL server:

pg_ctl -D <data_directory> stop

% Restart a PostgreSQL server:

pg_ctl -D <data_directory> restart

% Reload the PostgreSQL server configuration:

pg_ctl -D <data_directory> reload
% pg_dump

% Dump database into a SQL-script file:

pg_dump <db_name> > <output_file.sql>

% Same as above, customize username:

pg_dump -U <username> <db_name> > <output_file.sql>

% Same as above, customize host and port:

pg_dump -h <host> -p <port> <db_name> > <output_file.sql>

% Dump a database into a custom-format archive file:

pg_dump -Fc <db_name> > <output_file.dump>

% Dump only database data into an SQL-script file:

pg_dump -a <db_name> > <path/to/output_file.sql>

% Dump only schema (data definitions) into an SQL-script file:

pg_dump -s <db_name> > <path/to/output_file.sql>
% pgrep

% Return PIDs of any running processes with a matching command string:

pgrep <process_name>

% Search full command line with parameters instead of just the process name:

pgrep -f "<process_name> <parameter>"

% Search for process run by a specific user:

pgrep -u root <process_name>
% pg_restore

% Restore an archive into an existing database:

pg_restore -d <db_name> <archive_file.dump>

% Same as above, customize username:

pg_restore -U <username> -d <db_name> <archive_file.dump>

% Same as above, customize host and port:

pg_restore -h <host> -p <port> -d <db_name> <archive_file.dump>

% Clean database objects before creating them:

pg_restore --clean -d <db_name> <archive_file.dump>

% Use multiple jobs to do the restoring:

pg_restore -j <2> -d <db_name> <archive_file.dump>
% phing

% Perform the default task in the "build.xml" file:

phing

% Initialise a new build file:

phing -i <path/to/build.xml>

% Perform a specific task:

phing <task_name>

% Specify a custom build file path:

phing -f <path/to/build.xml> <task_name>

% Specify a log file to output to:

phing -b <path/to/log_file> <task_name>

% Specify custom properties to use in the build:

phing -D<property>=<value> <task_name>

% Specify a custom listener class:

phing -listener <class_name> <task_name>

% Build using verbose output:

phing -verbose <task_name>
% phive

% Display a list of available aliased Phars:

phive list

% Install a specified Phar to the local directory:

phive install <alias|url>

% Install a specified Phar globally:

phive install <alias|url> --global

% Install a specified Phar to a target directory:

phive install <alias|url> --target <path/to/directory>

% Update all Phar files to the latest version:

phive update

% Remove a specified Phar file:

phive remove <alias|url>

% Remove unused Phar files:

phive purge

% List all available commands:

phive help
% php artisan

% Start PHP's built-in web server for the current Laravel application:

php artisan serve

% Start an interactive PHP command line interface:

php artisan tinker

% Generate a new Eloquent model class with a migration, factory and resource controller:

php artisan make:model <ModelName> --all

% Display a list of all available commands:

php artisan help
% phpbu

% Run backups using the default "phpbu.xml" configuration file:

phpbu

% Run backups using a specific configuration file:

phpbu --configuration=<path/to/configuration_file.xml>

% Only run the specified backups:

phpbu --limit=<backup_task_name>

% Simulate the actions that would have been performed:

phpbu --simulate
% phpcpd

% Analyse duplicated code for a specific file or directory:

phpcpd <path/to/file_or_directory>

% Analyse using fuzzy matching for variable names:

phpcpd --fuzzy <path/to/file_or_directory>

% Specify a minimum number of identical lines (defaults to 5):

phpcpd --min-lines <number_of_lines> <path/to/file_or_directory>

% Specify a minimum number of identical tokens (defaults to 70):

phpcpd --min-tokens <number_of_tokens> <path/to/file_or_directory>

% Exclude a directory from analysis (must be relative to the source):

phpcpd --exclude <path/to/excluded_directory> <path/to/file_or_directory>

% Output the results to a PHP-CPD XML file:

phpcpd --log-pmd <path/to/log_file> <path/to/file_or_directory>
% phpcs

% Sniff the specified directory for issues (defaults to the PEAR standard):

phpcs <path/to/directory>

% Display a list of installed coding standards:

phpcs -i

% Specify a coding standard to validate against:

phpcs <path/to/directory> --standard <standard>

% Specify file extension(s) to include when sniffing:

phpcs <path/to/directory> --extensions <file_extension(s)>

% Specify the format of the output report (e.g. `full`, `xml`, `json`, `summary`):

phpcs <path/to/directory> --report <format>

% Set config variables to be used during the process:

phpcs <path/to/directory> --config-set <key> <value>

% A comma-separated list of files to load before processing:

phpcs <path/to/directory> --bootstrap <file(s)>

% Don't recurse into subdirectories:

phpcs <path/to/directory> -l
% phpenv

% Install a PHP version globally:

phpenv install <version>

% Refresh shim files for all PHP binaries known to `phpenv`:

phpenv rehash

% List all installed PHP versions:

phpenv versions

% Display the currently active PHP version:

phpenv version

% Set the global PHP version:

phpenv global <version>

% Set the local PHP version, which overrides the global version:

phpenv local <version>

% Unset the local PHP version:

phpenv local --unset
% phpize

% Prepare the PHP extension in the current directory for compiling:

phpize

% Delete files previously created by phpize:

phpize --clean
% phploc

% Analyse a directory and print the result:

phploc <path/to/directory>

% Include only specific files from a comma-separated list (globs are allowed):

phploc <path/to/directory> --names <files>

% Exclude specific files from a comma-separated list (globs are allowed):

phploc <path/to/directory> --names-exclude <files>

% Exclude a specific directory from analysis:

phploc <path/to/directory> --exclude <path/to/exclude_directory>

% Log the results to a specific CSV file:

phploc <path/to/directory> --log-csv <path/to/file>

% Log the results to a specific XML file:

phploc <path/to/directory> --log-xml <path/to/file>

% Count PHPUnit test case classes and test methods:

phploc <path/to/directory> --count-tests
% php

% Parse and execute a php script:

php <file>

% Check syntax on (i.e. lint) a PHP script:

php -l <file>

% Run PHP interactively:

php -a

% Run PHP code (Notes: Don't use <? ?> tags; escape double quotes with backslash):

php -r "<code>"

% Start a PHP built-in web server in the current directory:

php -S <host:port>

% Get a list of installed PHP extensions:

php -m

% Display information about the current PHP configuration:

php -i
% phpmd

% Display a list of available rulesets and formats:

phpmd

% Scan a file or directory for problems using comma-separated rulesets:

phpmd <path/to/file_or_directory> <xml|text|html> <rulesets>

% Specify the minimum priority threshold for rules:

phpmd <path/to/file_or_directory> <xml|text|html> <rulesets> --minimumpriority <priority>

% Include only the specified extensions in analysis:

phpmd <path/to/file_or_directory> <xml|text|html> <rulesets> --suffixes <extensions>

% Exclude the specified comma-separated directories:

phpmd <path/to/file_or_directory> <xml|text|html> <rulesets> --exclude <directory_patterns>

% Output the results to a file instead of `stdout`:

phpmd <path/to/file_or_directory> <xml|text|html> <rulesets> --reportfile <path/to/report_file>

% Ignore the use of warning-suppressive PHPDoc comments:

phpmd <path/to/file_or_directory> <xml|text|html> <rulesets> --strict
% phpspec

% Create a specification for a class:

phpspec describe <class_name>

% Run all specifications in the "spec" directory:

phpspec run

% Run a single specification:

phpspec run <path/to/class_specification_file>

% Run specifications using a specific configuration file:

phpspec run -c <path/to/configuration_file>

% Run specifications using a specific bootstrap file:

phpspec run -b <path/to/bootstrap_file>

% Disable code generation prompts:

phpspec run --no-code-generation

% Enable fake return values:

phpspec run --fake
% phpstan

% Display available options for analysis:

phpstan analyse --help

% Analyse the specified space-separated directories:

phpstan analyse <path/to/directory>

% Analyse a directory using a configuration file:

phpstan analyse <path/to/directory> --configuration <path/to/config>

% Analyse using a specific rule level (0-7, higher is stricter):

phpstan analyse <path/to/directory> --level <level>

% Specify an autoload file to load before analysing:

phpstan analyse <path/to/directory> --autoload-file <path/to/autoload_file>

% Specify a memory limit during analysis:

phpstan analyse <path/to/directory> --memory-limit <memory_limit>
% phpstorm

% Open a specific directory:

phpstorm <path/to/directory>

% Open a file:

phpstorm <path/to/file>

% Open a file at a specific line:

phpstorm --line <line_number> <path/to/file>

% View the differences between two files:

phpstorm diff <path/to/left_file> <path/to/right_file>
% phpunit

% Run tests in the current directory. Note: Expects you to have a 'phpunit.xml':

phpunit

% Run tests in a specific file:

phpunit <path/to/TestFile.php>

% Run tests annotated with the given group:

phpunit --group <name>

% Run tests and generate a coverage report in HTML:

phpunit --coverage-html <directory>
% php yii

% Display a list of all available commands:

php yii <help>

% Start PHP's built-in web server for the current Yii application:

php yii <serve>

% Generate a controller, views and related files for the CRUD actions on the specified model class:

php yii <gii/crud> --modelClass=<ModelName> --controllerClass=<ControllerName>
% picard

% Start Picard:

picard

% Open a set of files:

picard <path/to/file1.mp3> <path/to/file2.mp3>

% Display the version of Picard installed:

picard --long-version
% pickle

% Install a specific PHP extension:

pickle install <extension_name>

% Convert an existing PECL extension configuration to a Pickle configuration file:

pickle convert <path/to/directory>

% Validate a PECL extension:

pickle validate <path/to/directory>

% Package a PECL extension for release:

pickle release <path/to/directory>
% pigz

% Compress a file with default options:

pigz <filename>

% Compress a file using the best compression method:

pigz -9 <filename>

% Compress a file using no compression and 4 processors:

pigz -0 -p<4> <filename>

% Compress a directory using tar:

tar cf - <path/to/directory> | pigz > <filename>.tar.gz

% Decompress a file:

pigz -d <archive.gz>

% List the contents of an archive:

pigz -l <archive.tar.gz>
% ping6

% Ping a host:

ping6 <host>

% Ping a host only a specific number of times:

ping6 -c <count> <host>

% Ping a host, specifying the interval in seconds between requests (default is 1 second):

ping6 -i <seconds> <host>

% Ping a host without trying to lookup symbolic names for addresses:

ping6 -n <host>

% Ping a host and ring the bell when a packet is received (if your terminal supports it):

ping6 -a <host>
% ping

% Ping host:

ping <host>

% Ping a host only a specific number of times:

ping -c <count> <host>

% Ping host, specifying the interval in seconds between requests (default is 1 second):

ping -i <seconds> <host>

% Ping host without trying to lookup symbolic names for addresses:

ping -n <host>

% Ping host and ring the bell when a packet is received (if your terminal supports it):

ping -a <host>

% Also display a message if no response was received:

ping -O <host>
% pinky

% Display details about the current user:

pinky

% Display details for a specific user:

pinky <user>

% Display details in the long format:

pinky <user> -l

% Omit the user's home directory and shell in long format:

pinky <user> -lb

% Omit the user's project file in long format:

pinky <user> -lh

% Omit the column headings in short format:

pinky <user> -f
% pip3

% Find available packages:

pip3 search <package_name>

% Install a package:

pip3 install <package_name>

% Install a specific version of a package:

pip3 install <package_name>==<package_version>

% Upgrade a package:

pip3 install --upgrade <package_name>

% Uninstall a package:

pip3 uninstall <package_name>

% Save the list of installed packages to a file:

pip3 freeze > <requirements.txt>

% Install packages from a file:

pip3 install --requirements <requirements.txt>

% Show installed package info:

pip3 show <package_name>
% pipenv

% Create a new project:

pipenv

% Create a new project using Python 3:

pipenv --three

% Install a package:

pipenv install <package_name>

% Install all the dependencies for a project (including dev):

pipenv install --dev

% Uninstall a package:

pipenv uninstall <package_name>

% Start a shell within the created virtual environment:

pipenv shell

% Generate a requirements.txt for a project:

pipenv lock --requirements
% pip

% Install a package:

pip install <package_name>

% Install a specific version of a package:

pip install <package_name>==<package_version>

% Upgrade a package:

pip install -U <package_name>

% Uninstall a package:

pip uninstall <package_name>

% Save installed packages to file:

pip freeze > <requirements.txt>

% Install packages from file:

pip install -r <requirements.txt>

% Show installed package info:

pip show <package_name>
% pkill

% Kill all processes which match:

pkill -9 <process_name>

% Kill all processes which match their full command instead of just the process name:

pkill -9 -f "<command_name>"

% Send SIGUSR1 signal to processes which match:

pkill -USR1 <process_name>
% play

% Play the given audio file:

play <audiofile>

% Play the given audio files:

play <audiofile1> <audiofile2>

% Play the given audio at twice the speed:

play <audiofile> speed 2.0

% Play the given audio in reverse:

play <audiofile> reverse
% pm2

% Start a process with a name that can be used for later operations:

pm2 start <app.js> --name <myapp>

% List processes:

pm2 list

% Monitor all processes:

pm2 monit

% Stop a process:

pm2 stop <myapp>

% Restart a process:

pm2 restart <myapp>

% Dump all processes for resurrecting them later:

pm2 save

% Resurrect previously dumped processes:

pm2 resurrect

% Launch monitoring:

pm2 monit
% pngcrush

% Compress a PNG file:

pngcrush <in.png> <out.png>

% Compress all PNGs and output to directory:

pngcrush -d <path/to/output> *.png

% Compress PNG file with all 114 available algorithms and pick the best result:

pngcrush -rem allb -brute -reduce <in.png> <out.png>
% podman

% Print out information about containers:

podman ps

% List all containers (both running and stopped):

podman ps --all

% Start one or more containers:

podman start <container_name> <container_id>

% Stop one or more running containers:

podman stop <container_name> <container_id>

% Pull an image from a registry (defaults to the Docker Hub):

podman pull <image_name>:<image_tag>

% Open a shell inside of an already running container:

podman exec --interactive --tty <container_name> <sh>

% Remove one or more stopped containers:

podman rm <container_name> <container_id>

% Display the logs of one or more containers and follow log output:

podman logs --follow <container_name> <container_id>
% poetry

% Create a new Poetry project in the directory with a specific name:

poetry new <project_name>

% Install a dependency and its subdependencies:

poetry add <dependency>

% Interactively initialize the current directory as a new Poetry project:

poetry init

% Get the latest version of all dependencies and update poetry.lock:

poetry update

% Execute a command inside the project's virtual environment:

poetry run <command>
% popeye

% Scan the current Kubernetes cluster:

popeye

% Scan a specific namespace:

popeye -n <namespace>

% Scan specific Kubernetes context:

popeye --context=<context>

% Use a spinach configuration file for scanning:

popeye -f <spinach.yaml>
% postcss

% Parse and transform a CSS file:

postcss <path/to/file>

% Parse and transform a CSS file and output to a specific file:

postcss <path/to/file> --output <path/to/file>

% Parse and transform a CSS file and output to a specific directory:

postcss <path/to/file> --dir <path/to/directory>

% Parse and transform a CSS file in-place:

postcss <path/to/file> --replace

% Specify a custom PostCSS parser:

postcss <path/to/file> --parser <parser>

% Specify a custom PostCSS syntax:

postcss <path/to/file> --syntax <syntax>

% Watch for changes to a CSS file:

postcss <path/to/file> --watch

% Display available options and examples:

postcss --help
% powerstat

% Measure power with the default of 10 samples with an interval of 10 seconds:

powerstat

% Measure power with custom number of samples and interval duration:

powerstat <interval> <number_of_samples>

% Measure power using Intel's RAPL interface:

powerstat -R <interval> <number_of_samples>

% Show an histogram of the power measurements:

powerstat -H <interval> <number_of_samples>

% Enable all statistics gathering options:

powerstat -a <interval> <number_of_samples>
% pprof

% Generate a text report from a specific profiling file, on fibbo binary:

pprof -top <./fibbo> <./fibbo-profile.pb.gz>

% Generate a graph and open it on a web browser:

pprof -svg <./fibbo> <./fibbo-profile.pb.gz>

% Run pprof in interactive mode to be able to manually launch `pprof` on a file:

pprof <./fibbo> <./fibbo-profile.pb.gz>

% Run a web server that serves a web interface on top of `pprof`:

pprof -http=<localhost:8080> <./fibbo> <./fibbo-profile.pb.gz>

% Fetch a profile from an HTTP server and generate a report:

pprof <http://localhost:8080/debug/pprof>
% printenv

% Display key-value pairs of all environment variables:

printenv

% Display the value of a specific variable:

printenv <HOME>

% Display the value of a variable and end with NUL instead of newline:

printenv --null <HOME>
% printf

% Print a text message:

printf <"%s\n"> <"Hello world">

% Print an integer in bold blue:

printf <"\e[1;34m%.3d\e[0m\n"> <42>

% Print a float number with the unicode Euro sign:

printf <"\u20AC %.2f\n"> <123.4>

% Print a text message composed with environment variables:

printf <"var1: %s\tvar2: %s\n"> <"$VAR1"> <"$VAR2">

% Store a formatted message in a variable (does not work on zsh):

printf -v <myvar> <"This is %s = %d\n" "a year" 2016>
% pr

% Print multiple files with a default header and footer:

pr <file1> <file2> <file3>

% Print with a custom centered header:

pr -h "<header>" <file1> <file2> <file3>

% Print with numbered lines and a custom date format:

pr -n -D "<format>" <file1> <file2> <file3>

% Print all files together, one in each column, without a header or footer:

pr -m -T <file1> <file2> <file3>

% Print, beginning at page 2 up to page 5, with a given page length (including header and footer):

pr +<2>:<5> -l <page_length> <file1> <file2> <file3>

% Print with an offset for each line and a truncating custom page width:

pr -o <offset> -W <width> <file1> <file2> <file3>
% progpilot

% Analyse the current directory:

progpilot

% Analyse a specific file or directory:

progpilot <path/to/file_or_directory>

% Specify a custom configuration file:

progpilot --configuration <path/to/configuration.yml>
% prosodyctl

% Show the status of the Prosody server:

sudo prosodyctl status

% Reload the server's configuration files:

sudo prosodyctl reload

% Add a user to the Prosody XMPP server:

sudo prosodyctl adduser <user@example.com>

% Set a user's password:

sudo prosodyctl passwd <user@example.com>

% Permanently delete a user:

sudo prosodyctl deluser <user@example.com>
% protoc

% Generate Python code from a `.proto` file:

protoc --python_out=<path/to/output_directory> <input_file.proto>

% Generate Java code from a `.proto` file that imports other `.proto` files:

protoc --java_out=<path/to/output_directory> --proto_path=<path/to/import_search_path> <input_file.proto>

% Generate code for multiple languages:

protoc --csharp_out=<path/to/c#_output_directory> --js_out=<path/to/js_output_directory> <input_file.proto>
% psgrep

% Find process lines containing a specific string:

psgrep <process_name>

% Find process lines containing a specific string, excluding headers:

psgrep -n <process_name>

% Search using a simplified format (PID, user, command):

psgrep -s <process_name>
% ps

% List all running processes:

ps aux

% List all running processes including the full command string:

ps auxww

% Search for a process that matches a string:

ps aux | grep <string>

% List all processes of the current user in extra full format:

ps --user $(id -u) -F

% List all processes of the current user as a tree:

ps --user $(id -u) f

% Get the parent pid of a process:

ps -o ppid= -p <pid>
% psql

% Connect to database. It connects to localhost using default port 5432 with default user as currently logged in user:

psql <database>

% Connect to database on given server host running on given port with given username, without a password prompt:

psql -h <host> -p <port> -U <username> <database>

% Connect to database; user will be prompted for password:

psql -h <host> -p <port> -U <username> -W <database>

% Execute a single SQL query or PostgreSQL command on the given database (useful in shell scripts):

psql -c '<query>' <database>

% Execute commands from a file on the given database:

psql <database> -f <file.sql>
% pssh

% Run a command on two hosts, and print its output on each server inline:

pssh -i -H "<host1> <host2>" <hostname -i>

% Run a command and save the output to separate files:

pssh -H <host1> -H <host2> -o <path/to/output_dir> <hostname -i>

% Run a command on multiple hosts, specified in a new-line separated file:

pssh -i -h <path/to/hosts_file> <hostname -i>

% Run a command as root (this asks for the root password):

pssh -i -h <path/to/hosts_file> -A -l <root_username> <hostname -i>

% Run a command with extra SSH arguments:

pssh -i -h <path/to/hosts_file> -x "<-O VisualHostKey=yes>" <hostname -i>

% Run a command limiting the number of parallel connections to 10:

pssh -i -h <path/to/hosts_file> -p <10> '<cd dir; ./script.sh; exit>'
% psysh

% Open a shell in the current directory:

psysh

% Open a shell in a specific directory:

psysh --cwd <path/to/directory>

% Use a specific configuration file:

psysh --config <path/to/file>
% pt

% Find files containing "foo" and print the files with highlighted matches:

pt <foo>

% Find files containing "foo" and display count of matches in each file:

pt -c <foo>

% Find files containing "foo" as a whole word and ignore its case:

pt -wi <foo>

% Find "foo" in files with a given extension using a regular expression:

pt -G='<\.bar$>' <foo>

% Find files whose contents match the regular expression, up to 2 directories deep:

pt --depth=<2> -e '<^ba[rz]*$>'
% pup

% Transform a raw HTML file into a cleaned, indented, and colored format:

cat <index.html> | pup --color

% Filter HTML by element tag name:

cat <index.html> | pup '<tag>'

% Filter HTML by id:

cat <index.html> | pup '<div#id>'

% Filter HTML by attribute value:

cat <index.html> | pup '<input[type="text"]>'

% Print all text from the filtered HTML elements and their children:

cat <index.html> | pup '<div> text{}'

% Print HTML as JSON:

cat <index.html> | pup '<div> json{}'
% pv

% Print the contents of the file and display a progress bar:

pv <file>

% Measure the speed and amount of data flow between pipes (`-s` is optional):

command1 | pv -s <expected_amount_of_data_for_eta> | command2

% Filter a file, see both progress and amount of output data:

pv -cN in <big_text_file> | grep <pattern> | pv -cN out > <filtered_file>

% Attach to an already running process and see its file reading progress:

pv -d <PID>

% Read an erroneous file, skip errors as `dd conv=sync,noerror` would:

pv -EE <path/to/faulty_media> > image.img

% Stop reading after reading specified amount of data, rate limit to 1K/s:

pv -L 1K -S <maximum_file_size_to_be_read>
% pwd

% Print the current directory:

pwd

% Print the current directory, and resolve all symlinks (i.e. show the "physical" path):

pwd -P
% pycodestyle

% Check the style of a single file:

pycodestyle <file.py>

% Check the style of multiple files:

pycodestyle <file1.py> <file2.py> <file3.py>

% Show only the first occurrence of an error:

pycodestyle --first <file.py>

% Show the source code for each error:

pycodestyle --show-source <file.py>

% Show the specific PEP 8 text for each error:

pycodestyle --show-pep8 <file.py>
% pyenv

% List all available commands:

pyenv commands

% List all Python versions under the ${PYENV_ROOT}/versions directory:

pyenv versions

% Install a Python version under the ${PYENV_ROOT}/versions directory:

pyenv install <2.7.10>

% Uninstall a Python version under the ${PYENV_ROOT}/versions directory:

pyenv uninstall <2.7.10>

% Set Python version to be used globally in the current machine:

pyenv global <2.7.10>

% Set Python version to be used in the current directory and all directories below it:

pyenv local <2.7.10>
% pyenv virtualenv

% Create a new Python 3.6.6 virtual environment:

pyenv virtualenv <3.6.6> <virtualenv_name>

% List all existing virtual environments:

pyenv virtualenvs

% Activate a virtual environment:

pyenv activate <virtualenv_name>

% Deactivate the virtual environment:

pyenv deactivate
% pyflakes

% Check a single Python file:

pyflakes check <path/to/file>.py

% Check Python files in a specific directory:

pyflakes checkPath <path/to/directory>

% Check Python files in a directory recursively:

pyflakes checkRecursive <path/to/directory>

% Check all Python files found in multiple directories:

pyflakes iterSourceCode <path/to/directory_1> <path/to/directory_2>
% pygmentize

% Highlight file syntax and print to standard output (language is inferred from the file extension):

pygmentize <file.py>

% Explicitly set the language for syntax highlighting:

pygmentize -l <javascript> <input_file>

% List available lexers (processors for input languages):

pygmentize -L lexers

% Save output to a file in HTML format:

pygmentize -f html -o <output_file.html> <input_file.py>

% List available output formats:

pygmentize -L formatters

% Output an HTML file, with additional formatter options (full page, with line numbers):

pygmentize -f html -O "full,linenos=True" -o <output_file.html> <input_file>
% python

% Call a Python interactive shell (REPL):

python

% Execute script in a given Python file:

python <script.py>

% Execute script as part of an interactive shell:

python -i <script.py>

% Execute a Python expression:

python -c "<expression>"

% Run library module as a script (terminates option list):

python -m <module> <arguments>

% Interactively debug a Python script:

python -m pdb <script.py>
% qcp

% Copy a single file (open an editor with the source filename on the left and the target filename on the right):

qcp <source_file>

% Copy multiple JPG files:

qcp <*.jpg>

% Copy files, but swap the positions of the source and the target filenames in the editor:

qcp --option swap <*.jpg>
% qemu-img

% Create disk image with a specific size (in gigabytes):

qemu-img create <image_name.img> <gigabytes>G

% Show information about a disk image:

qemu-img info <image_name.img>

% Increase or decrease image size:

qemu-img resize <image_name.img> <gigabytes>G

% Dump the allocation state of every sector of the specified disk image:

qemu-img map <image_name.img>

% Convert a VMWare .vmdk disk image to a KVM .qcow2 disk image:

qemu-img convert -O qcow2 </path/to/file/foo.vmdk> </path/to/file/foo.qcow2>
% qemu

% Boot from image emulating i386 architecture:

qemu-system-i386 -hda <image_name.img>

% Boot from image emulating x64 architecture:

qemu-system-x86_64 -hda <image_name.img>

% Boot QEMU instance with a live ISO image:

qemu-system-i386 -hda <image_name.img> -cdrom <os_image.iso> -boot d

% Specify amount of RAM for instance:

qemu-system-i386 -m 256 -hda image_name.img -cdrom os-image.iso -boot d

% Boot from physical device (e.g. from USB to test bootable medium):

qemu-system-i386 -hda /dev/<storage_device>
% q

% Query .csv file by specifying the delimiter as ',':

q -d',' "SELECT * from <path/to/file>"

% Query .tsv file:

q -t "SELECT * from <path/to/file>"

% Query file with header row:

q -d<delimiter> -H "SELECT * from <path/to/file>"

% Read data from stdin; '-' in the query represents the data from `stdin`:

<output> | q "select * from -"

% Join two files (aliased as `f1` and `f2` in the example) on column `c1`, a common column:

q "SELECT * FROM <path/to/file> f1 JOIN <path/to/other_file> f2 ON (f1.c1 = f2.c1)"

% Format output using an output delimiter with an output header line (note: command will output column names based on the input file header or the column aliases overridden in the query):

q -D<delimiter> -O "SELECT <column> as <alias> from <path/to/file>"
% qmv

% Move a single file (open an editor with the source filename on the left and the target filename on the right):

qmv <source_file>

% Move multiple JPG files:

qmv <*.jpg>

% Move multiple directories:

qmv -d <path/to/directory1> <path/to/directory2> <path/to/directory3>

% Move all files and directories inside a directory:

qmv --recursive <path/to/directory>

% Move files, but swap the positions of the source and the target filenames in the editor:

qmv --option swap <*.jpg>
% qpdf

% Extract pages 1-3, 5 and 6-10 from a PDF file and save them as another one:

qpdf --empty --pages <input.pdf> <1-3,5,6-10> -- <output.pdf>

% Merge (concatenate) all the pages of a list of PDF files and save the result as a new PDF:

qpdf --empty --pages <file1.pdf> <file2.pdf> <file3.pdf> -- <output.pdf>

% Merge (concatenate) given pages from a list of PDF files and save the result as a new PDF:

qpdf --empty --pages <file1.pdf> <1,6-8> --pages <file2.pdf> <3,4,5> -- <output.pdf>

% Write each group of n pages to a separate output file with a given filename pattern:

qpdf --split-pages=n <input.pdf> <out_%d.pdf>

% Rotate certain pages of a pdf with a given angle:

qpdf --rotate=<90:2,4,6> --rotate=<180:7-8> <input.pdf> <output.pdf>

% Remove the password from a password protected file:

qpdf --password=<password> --decrypt <input.pdf> <output.pdf>
% qrencode

% Convert a string to a QR code and save to an output file:

qrencode -o <path/to/output_file.png> <string>

% Convert an input file to a QR code and save to an output file:

qrencode -o <path/to/output_file.png> -r <path/to/input_file>

% Convert a string to a QR code and print it in terminal:

qrencode -t ansiutf8 <string>

% Convert input from pipe to a QR code and print it in terminal:

echo <string> | qrencode -t ansiutf8
% qr

% Generate a QR code:

echo "<data>" | qr

% Specify the error correction level (defaults to M):

echo "<data>" | qr --error-correction=<L|M|Q|H>
% quota

% Show disk quotas in human readable units for the current user:

quota -s

% Verbose output (also display quotas on filesystems where no storage is allocated):

quota -v

% Quiet output (only display quotas on filesystems where usage is over quota):

quota -q

% Print quotas for the groups of which the current user is a member:

quota -g

% Show disk quotas for another user:

sudo quota -u <username>
% rabin2

% Display general information about a binary (architecture, type, endianness):

rabin2 -I <path/to/binary>

% Display linked libraries:

rabin2 -l <path/to/binary>

% Display symbols imported from libraries:

rabin2 -i <path/to/binary>

% Display strings contained in the binary:

rabin2 -z <path/to/binary>

% Display the output in JSON:

rabin2 -j -I <path/to/binary>
% radare2

% Open a file in write mode without parsing the file format headers:

radare2 -nw <path/to/binary>

% Debug a program:

radare2 -d <path/to/binary>

% Run a script before entering the interactive CLI:

radare2 -i <path/to/script.r2> <path/to/binary>

% Show help text for any command in the interactive CLI:



% Run a shell command from the interactive CLI:



% Dump raw bytes of current block to a file:


% rails db

% Create databases, load the schema, and initialize with seed data:

rails db:setup

% Access the database console:

rails db

% Create the databases defined in the current environment:

rails db:create

% Destroy the databases defined in the current environment:

rails db:drop

% Run pending migrations:

rails db:migrate

% View the status of each migration file:

rails db:migrate:status

% Rollback the last migration:

rails db:rollback

% Fill the current database with data defined in db/seeds.rb:

rails db:seed
% rails generate

% List all available generators:

rails generate

% Generate a new model:

rails generate model <model_name>

% Generate a new controller:

rails generate controller <controller_name>

% Generate a scaffold for a new model:

rails generate scaffold <model_name>
% rails

% Create a new rails project:

rails new "<project_name>"

% Start local server for current project on port 3000:

rails server

% Start local server for current project on a specified port:

rails server -p "<port>"

% Open console to interact with application from command line:

rails console

% Check current version of rails:

rails --version
% rainbowstream

% Open rainbowstream:

rainbowstream

% Show your timeline (optional number of tweets to display, default is 5):

home [<num_of_last_tweets>]

% Show profile of a given user:

whois @<user>

% Tweet the message as-is:

t <message>

% Retweet the tweet with given id (id is beside the time):

rt <tweet_id>

% Favorite the tweet with given id:

fav <tweet_id>

% Perform a search for a given word (with or without hashtag):

s <word>
% ranger

% Launch ranger:

ranger

% Show only directories:

ranger --show-only-dirs

% Change the configuration directory:

ranger --confdir=<path/to/directory>

% Change the data directory:

ranger --datadir=<path/to/directory>

% Print CPU usage statistics on exit:

ranger --profile
% rapper

% Convert an RDF/XML document to Turtle:

rapper -i rdfxml -o turtle <file>

% Count the number of triples in a Turtle file:

rapper -i turtle -c <file>
% rar

% Archive 1 or more files:

rar a <path/to/archive_name.rar> <path/to/file1> <path/to/file2> <path/to/file3>

% Archive a directory:

rar a <path/to/archive_name.rar> <path/to/directory>

% Split the archive into parts of equal size (50M):

rar a -v<50M> -R <path/to/archive_name.rar> <path/to/file_or_directory>

% Password protect the resulting archive:

rar a -p<password> <path/to/archive_name.rar> <path/to/file_or_directory>

% Encrypt file data and headers with password:

rar a -hp<password> <path/to/archive_name.rar> <path/to/file_or_directory>

% Use a specific compression level (0-5):

rar a -m<compression_level> <path/to/archive_name.rar> <path/to/file_or_directory>
% rbac-lookup

% View all RBAC bindings:

rbac-lookup

% View RBAC bindings that match a given expression:

rbac-lookup <search_term>

% View all RBAC bindings along with the source role binding:

rbac-lookup -o wide

% View all RBAC bindings filtered by subject:

rbac-lookup -k <user|group|serviceaccount>

% View all RBAC bindings along with IAM roles (if you are using GKE):

rbac-lookup --gke
% rbash

% Start rbash:

rbash

% Execute a command:

rbash -c "<command>"

% Run commands from a file:

rbash <file.sh>

% Print the version information of rbash:

rbash --version
% rbenv

% Install one or more space-separated versions of Ruby:

rbenv install <version(s)>

% Display a list of installed versions:

rbenv versions

% Use a specific version of Ruby across the whole system:

rbenv global <version>

% Use a specific version of Ruby for an application/project directory:

rbenv local <version>

% Show the currently selected Ruby version:

rbenv version

% Uninstall a version of Ruby:

rbenv uninstall <version>

% Display all ruby versions that contain the specified executable:

rbenv whence <executable>
% rbt

% Post changes to Review Board:

rbt post <change_number>

% Display the diff that will be sent to Review Board:

rbt diff

% Land a change in a local branch or on a review request:

rbt land <branch_name>

% Patch your tree with a change on a review request:

rbt patch <review_request_id>

% Set up RBTool to talk to a repository:

rbt setup-repo
% rclone

% List contents of a directory on an rclone remote:

rclone lsf <remote_name>:<path/to/directory>

% Copy file or directory from local source to remote destination:

rclone copy <path/to/source_file_or_directory> <remote_name>:<path/to/destination_directory>

% Copy file or directory from remote source to local destination:

rclone copy <remote_name>:<path/to/source_file_or_directory> <path/to/destination_directory>

% Sync local source to remote destination, changing the destination only:

rclone sync <path/to/file_or_directory> <remote_name>:<path/to/directory>

% Move file or directory from local source to remote destination:

rclone move <path/to/file_or_directory> <remote_name>:<path/to/directory>

% Delete remote file or directory (use `--dry-run` to test, remove it to actually delete):

rclone --dry-run delete <remote_name>:<path/to/file_or_directory>

% Mount rclone remote (experimental):

rclone mount <remote_name>:<path/to/directory> <path/to/mount_point>

% Unmount rclone remote if CTRL-C fails (experimental):

fusermount -u <path/to/mount_point>
% rdfind

% Identify all duplicates in a given directory and output a summary:

rdfind -dryrun true <path/to/directory>

% Replace all duplicates with hardlinks:

rdfind -makehardlinks true <path/to/directory>

% Replace all duplicates with symlinks/soft links:

rdfind -makesymlinks true <path/to/directory>

% Delete all duplicates and do not ignore empty files:

rdfind -deleteduplicates true -ignoreempty false <path/to/directory>
% readlink

% Get the actual file to which the symlink points:

readlink <filename>

% Get the absolute path to a file:

readlink -f <filename>
% read

% Store data that you type from the keyboard:

read <variable>

% Store each of the next lines you enter as values of an array:

read -a <array>

% Enable backspace and GNU readline hotkeys when entering input with read:

read -e <variable>

% Specify the number of maximum characters to be read:

read -n <character_count> <variable>

% Use a specific character as a delimiter instead of a new line:

read -d <new_delimiter> <variable>

% Do not let backslash (\) act as an escape character:

read -r <variable>

% Display a prompt before the input:

read -p <"Enter your input here: "> <variable>

% Do not echo typed characters (silent mode):

read -s <variable>
% realpath

% Display the absolute path for a file or directory:

realpath <path/to/file_or_directory>

% Require all path components to exist:

realpath --canonicalize-existing <path/to/file_or_directory>

% Resolve ".." components before symlinks:

realpath --logical <path/to/file_or_directory>

% Disable symlink expansion:

realpath --no-symlinks <path/to/file_or_directory>

% Suppress error messages:

realpath --quiet <path/to/file_or_directory>
% rector

% Process a specific directory:

rector process <path/to/directory>

% Process a directory without applying changes (dry run):

rector process <path/to/directory> --dry-run

% Process a directory and apply coding standards:

rector process <path/to/directory> --with-style

% Display a list of available levels:

rector levels

% Process a directory with a specific level:

rector process <path/to/directory> --level <level_name>
% redis-cli

% Connect to the local server:

redis-cli

% Connect to a remote server on the default port (6379):

redis-cli -h <host>

% Connect to a remote server specifying a port number:

redis-cli -h <host> -p <port>

% Specify a password:

redis-cli -a <password>

% Execute Redis command:

redis-cli <redis_command>
% redshift

% Turn on Redshift with 5700K temperature during day and 3600K at night:

redshift -t <5700>:<3600>

% Turn on Redshift with a manually-specified custom location:

redshift -l <latitude>:<longitude>

% Turn on Redshift with 70% screen brightness during day and 40% brightness at night:

redshift -b <0.7>:<0.4>

% Turn on Redshift with custom gamma levels (between 0 and 1):

redshift -g <red>:<green>:<blue>

% Turn on Redshift with a constant unchanging color temperature:

redshift -O <temperature>
% reflac

% Recompress a directory of FLAC files:

reflac <path/to/directory>

% Enable maximum compression (very slow):

reflac --best <path/to/directory>

% Display filenames as they are processed:

reflac --verbose <path/to/directory>

% Recurse into subdirectories:

reflac --recursive <path/to/directory>

% Perserve file modification times:

reflac --preserve <path/to/directory>
% renice

% Change priority of a running process:

renice -n <niceness_value> -p <pid>

% Change priority of all processes owned by a user:

renice -n <niceness_value> -u <user>

% Change priority of all processes that belong to a process group:

renice -n <niceness_value> --pgrp <process_group>
% repren

% Do a dry-run renaming a directory of pngs with a literal string replacement:

repren --dry-run --rename --literal --from '<find_string>' --to '<replacement_string>' <*.png>

% Do a dry-run renaming a directory of jpegs with a regular expression:

repren --rename --dry-run --from '<regular_expression>' --to '<replacement_string>' <*.jpg> <*.jpeg>

% Do a find-and-replace on the contents of a directory of csv files:

repren --from '<([0-9]+) example_string>' --to '<replacement_string \1>' <*.csv>

% Do both a find-and-replace and a rename operation at the same time, using a pattern file:

repren --patterns <path/to/patfile.ext> --full <*.txt>

% Do a case-insensitive rename:

repren --rename --insensitive --patterns <path/to/patfile.ext> *
% restic

% Initialize a backup repository in the specified local directory:

restic init -r <path/to/repository>

% Backup a directory to the repository:

restic -r <path/to/repository> backup <path/to/directory>

% Show backup snapshots currently stored in the repository:

restic -r <path/to/repository> snapshots

% Restore a specific backup snapshot to a target directory:

restic -r <path/to/repository> restore <snapshot_id> <path/to/target>

% Restore a specific path from a specific backup to a target directory:

restic -r <path/to/repository> --include <path/to/restore> --target <path/to/target> restore <snapshot_id>

% Clean up the repository and keep only the most recent snapshot of each unique backup:

restic forget --keep-last 1 --prune
% rev

% Reverse the text string "hello":

echo "hello" | rev

% Reverse an entire file and print to `stdout`:

rev <file>
% ripgrep

% Recursively search the current directory for a regex pattern:

rg <pattern>

% Search for pattern including all .gitignored and hidden files:

rg -uu <pattern>

% Search for a pattern only in a certain filetype (e.g., html, css, etc.):

rg -t <filetype> <pattern>

% Search for a pattern only in a subset of directories:

rg <pattern> <set_of_subdirs>

% Search for a pattern in files matching a glob (e.g., `README.*`):

rg <pattern> -g <glob>

% Only list matched files (useful when piping to other commands):

rg --files-with-matches <pattern>

% Show lines that do not match the given pattern:

rg --invert-match <pattern>
% r

% Start an R interactive shell (REPL):

R

% Check R version:

R --version

% Execute a file:

R -f <file.R>
% rmdir

% Remove directory, provided it is empty. Use `rm` to remove not empty directories:

rmdir <path/to/directory>

% Remove directories recursively (useful for nested dirs):

rmdir -p <path/to/directory>
% rm

% Remove files from arbitrary locations:

rm <path/to/file> <path/to/another/file>

% Recursively remove a directory and all its subdirectories:

rm -r <path/to/directory>

% Forcibly remove a directory, without prompting for confirmation or showing error messages:

rm -rf <path/to/directory>

% Interactively remove multiple files, with a prompt before every removal:

rm -i <file(s)>

% Remove files in verbose mode, printing a message for each removed file:

rm -v <path/to/directory/*>
% roave-backward-compatibility-check

% Check for breaking changes since the last tag:

roave-backward-compatibility-check

% Check for breaking changes since a specific tag:

roave-backward-compatibility-check --from=<git_reference>

% Check for breaking changes between the last tag and a specific reference:

roave-backward-compatibility-check --to=<git_reference>

% Check for breaking changes and output to markdown:

roave-backward-compatibility-check --format=markdown > <results.md>
% robo

% List available commands:

robo list

% Run a specific command:

robo <foo>

% Simulate running a specific command:

robo --simulate <foo>
% roll

% Roll 3 6-sided dice and sums the results:

roll <3d>

% Roll 1 8-sided die, add 3 and sum the results:

roll <d8 + 3>

% Roll 4 6-sided dice, keep the 3 highest results and sum the results:

roll <4d6h3>

% Roll 2 12-sided dice 2 times and show every roll:

roll --verbose <2{2d12>}

% Roll 2 20-sided dice until the result is bigger than 10:

roll "<2d20>10>"

% Roll 2 5-sided dice 3 times and show the total sum:

roll --sum-series <3{2d5>}
% route

% Display the information of route table:

route -n

% Add route rule:

sudo route add -net <ip_address> netmask <netmask_address> gw <gw_address>

% Delete route rule:

sudo route del -net <ip_address> netmask <netmask_address> dev <gw_address>
% rr

% Record an application:

rr record <path/to/binary --arg1 --arg2>

% Replay latest recorded execution:

rr replay
% rsstail

% Show the feed of a given url and wait for new entries appearing at the bottom:

rsstail -u <url>

% Show the feed in reverse chronological order (newer at the bottom):

rsstail -r -u <url>

% Include publication date and link:

rsstail -pl -u <url>

% Set update interval:

rsstail -u <url> -i <interval_in_seconds>

% Show feed and exit:

rsstail -1 -u <url>
% rsync

% Transfer file from local to remote host:

rsync <path/to/local_file> <remote_host>:<path/to/remote_directory>

% Transfer file from remote host to local:

rsync <remote_host>:<path/to/remote_file> <path/to/local_directory>

% Transfer file in [a]rchive (to preserve attributes) and compressed ([z]ipped) mode with [v]erbose and [h]uman-readable [p]rogress:

rsync -azvhP <path/to/local_file> <remote_host>:<path/to/remote_directory>

% Transfer a directory and all its children from a remote to local:

rsync -r <remote_host>:<path/to/remote_directory> <path/to/local_directory>

% Transfer directory contents (but not the directory itself) from a remote to local:

rsync -r <remote_host>:<path/to/remote_directory>/ <path/to/local_directory>

% Transfer a directory [r]ecursively, in [a]rchive to preserve attributes, resolving contained soft[l]inks , and ignoring already transferred files [u]nless newer:

rsync -rauL <remote_host>:<path/to/remote_file> <path/to/local_directory>

% Transfer file over SSH and delete local files that do not exist on remote host:

rsync -e ssh --delete <remote_host>:<path/to/remote_file> <path/to/local_file>

% Transfer file over SSH and show global progress:

rsync -e ssh --info=progress2 <remote_host>:<path/to/remote_file> <path/to/local_file>
% rtmpdump

% Download a file:

rtmpdump --rtmp <rtmp://example.com/path/to/video> -o <file.ext>

% Download a file from a Flash player:

rtmpdump --rtmp <rtmp://example.com/path/to/video> --swfVfy <http://example.com/player> --flashVer "<LNX 10,0,32,18>" -o <file.ext>

% Specify connection parameters if they are not detected correctly:

rtmpdump --rtmp <rtmp://example.com/path/to/video> --app <app_name> --playpath <path/to/video> -o <file.ext>

% Download a file from a server that requires a referrer:

rtmpdump --rtmp <rtmp://example.com/path/to/video> --pageUrl <http://example.com/webpage> -o <file.ext>
% rtv

% Open the front page:

/front

% Open a subreddit:

/r/<subreddit_name>

% Expand/collapse comments:

[space]

% Open link:

o

% Login:

u

% Open the help screen:

?
% ruby

% Open an Interactive Ruby Shell (REPL):

irb

% Execute a Ruby script:

ruby <script.rb>

% Execute a single Ruby command in the command line:

ruby -e <command>

% Check for syntax errors on a given Ruby script:

ruby -c <script.rb>

% Show the version of Ruby you are using:

ruby -v
% rustc

% Compile a single file:

rustc <file.rs>

% Compile with high optimization:

rustc -O <file.rs>

% Compile with debugging information:

rustc -g <file.rs>
% rustfmt

% Format a file, overwriting the original file in-place:

rustfmt <source.rs>

% Check a file for formatting and display any changes on the console:

rustfmt --check <source.rs>

% Backup any modified files before formatting (the original file is renamed with a `.bk` extension):

rustfmt --backup <source.rs>
% rustup

% Install the nightly toolchain for your system:

rustup install nightly

% Switch the default toolchain to nightly so that the `cargo` and `rustc` commands will use it:

rustup default nightly

% Use the nightly toolchain when inside the current project, but leave global settings unchanged:

rustup override set nightly

% Update all toolchains:

rustup update

% List installed toolchains:

rustup show

% Run cargo build with a certain toolchain:

rustup run <toolchain_name> cargo build
% rvm

% Install one or more space-separated versions of Ruby:

rvm install <version(s)>

% Display a list of installed versions:

rvm list

% Use a specific version of Ruby:

rvm use <version>

% Set the default Ruby version:

rvm --default use <version>

% Upgrade a version of Ruby to a new version:

rvm upgrade <current_version> <new_version>

% Uninstall a version of Ruby and keep its sources:

rvm uninstall <version>

% Remove a version of Ruby and its sources:

rvm remove <version>

% Show specific dependencies for your OS:

rvm requirements
% safe

% Add a safe target:

safe target <vault_addr> <target_name>

% Authenticate the CLI client against the Vault server, using an authentication token:

safe auth <authentication_token>

% Print the environment variables describing the current target:

safe env

% Display a tree hierarchy of all reachable keys for a given path:

safe tree <path>

% Move a secret from one path to another:

safe move <old/path/to/secret> <new/path/to/secret>

% Generate a new 2048-bit SSH keypair and store it:

safe ssh <2048> <path/to/secret>

% Set non-sensitive keys for a secret:

safe set <path/to/secret> <key>=<value>

% Set auto-generated password in a secret:

safe gen <path/to/secret> <key>
% sails

% Start Sails:

sails lift

% Create new Sails project:

sails new <projectName>

% Generate Sails API:

sails generate <name>

% Generate Sails Controller:

sails generate controller <name>

% Generate Sails Model:

sails generate model <name>
% salt-call

% Perform a highstate on this minion:

salt-call state.highstate

% Perform a highstate dry-run, compute all changes but don't actually perform them:

salt-call state.highstate test=true

% Perform a highstate with verbose debugging output:

salt-call -l debug state.highstate

% List this minion's grains:

salt-call grains.items
% salt-key

% List all accepted, unaccepted and rejected minion keys:

salt-key -L

% Accept a minion key by name:

salt-key -a <MINION_ID>

% Reject a minion key by name:

salt-key -r <MINION_ID>

% Print fingerprints of all public keys:

salt-key -F
% salt

% List connected minions:

salt '*' test.ping

% Execute a highstate on all connected minions:

salt '*' state.highstate

% Upgrade packages using the OS package manager (apt, yum, brew) on a subset of minions:

salt '*.example.com' pkg.upgrade

% Execute an arbitrary command on a particular minion:

salt '<minion_id>' cmd.run "ls "
% salt-run

% Show status of all minions:

salt-run manage.status

% Show all minions which are disconnected:

salt-run manage.up
% samtools

% Convert a SAM input file to BAM stream and save to file:

samtools view -S -b <input.sam> > <output.bam>

% Take input from stdin (-) and print the SAM header and any reads overlapping a specific region to `stdout`:

<other_command> | samtools view -h - chromosome:start-end

% Sort file and save to BAM (the output format is automatically determined from the output file's extension):

samtools sort <input> -o <output.bam>

% Index a sorted BAM file (creates <sorted_input.bam.bai>):

samtools index <sorted_input.bam>

% Print alignment statistics about a file:

samtools flagstat <sorted_input>

% Count alignments to each index (chromosome / contig):

samtools idxstats <sorted_indexed_input>

% Merge multiple files:

samtools merge <output> <input1 input2 …>

% Split input file according to read groups:

samtools split <merged_input>
% sass

% Convert a SCSS or Sass file to CSS and print out the result:

sass <inputfile.scss|inputfile.sass>

% Convert a SCSS or Sass file to CSS and save the result to a file:

sass <inputfile.scss|inputfile.sass> <outputfile.css>

% Watch a SCSS or Sass file for changes and output or update the CSS file with same filename:

sass --watch <inputfile.scss|inputfile.sass>

% Watch a SCSS or Sass file for changes and output or update the CSS file with the given filename:

sass --watch <inputfile.scss|inputfile.sass>:<outputfile.css>
% satis

% Initialise a Satis configuration:

satis init <satis.json>

% Add a VCS repository to the Satis configuration:

satis add <repository_url>

% Build the static output from the configuration:

satis build <satis.json> <path/to/output_directory>

% Build the static output by updating only the specified repository:

satis build --repository-url <repository_url> <satis.json> <path/to/output_directory>

% Remove useless archive files:

satis purge <satis.json> <path/to/output_directory>
% sbt

% Start the SBT interactive shell (REPL):

sbt

% Create a new Scala project from an existing Giter8 template hosted on GitHub:

sbt new <scala/hello-world.g8>

% Use the specified version of sbt:

sbt -sbt-version <version>

% Use a specific jar file as the sbt launcher:

sbt -sbt-jar <path>

% List all sbt options:

sbt -h
% scala

% Start a Scala interactive shell (REPL):

scala

% Execute a Scala script:

scala <script.scala>

% Execute a .jar program:

scala <filename.jar>

% Execute a single Scala command in the command line:

scala -e <command>
% scheme

% Open an interactive shell (REPL):

scheme

% Run a scheme program (with no REPL output):

scheme --quiet < <script.scm>

% Load a scheme program into the REPL:

scheme --load <script.scm>

% Load scheme expressions into the REPL:

scheme --eval <"(define foo 'x)">

% Open the REPL in quiet mode:

scheme --quiet
% SC-IM

% Start SC-IM:

scim <file_name>.csv

% Enter a string into the current cell:

< or >

% Enter a numeric constant into the current cell:

=

% Edit string in the current cell:

E

% Edit number in the current cell:

e

% Center align the current cell:

|
% scp

% Copy a local file to a remote host:

scp <path/to/local_file> <remote_host>:<path/to/remote_file>

% Copy a file from a remote host to a local directory:

scp <remote_host>:<path/to/remote_file> <path/to/local_directory>

% Recursively copy the contents of a directory from a remote host to a local directory:

scp -r <remote_host>:<path/to/remote_directory> <path/to/local_directory>

% Copy a file between two remote hosts transferring through the local host:

scp -3 <host1>:<path/to/remote_file> <host2>:<path/to/remote_directory>

% Use a specific username when connecting to the remote host:

scp <path/to/local_file> <remote_username>@<remote_host>:<path/to/remote_directory>

% Use a specific ssh private key for authentication with the remote host:

scp -i <~/.ssh/private_key> <local_file> <remote_host>:</path/remote_file>
% scrapy

% Create a project:

scrapy startproject <project_name>

% Create a spider (in project directory):

scrapy genspider <spider_name> <website_domain>

% Edit spider (in project directory):

scrapy edit <spider_name>

% Run spider (in project directory):

scrapy crawl <spider_name>

% Fetch a webpage as scrapy sees it and print source in `stdout`:

scrapy fetch <url>

% Open a webpage in the default browser as scrapy sees it (disable javascript for extra fidelity):

scrapy view <url>

% Open scrapy shell for url, which allows interaction with the page source in python shell (or ipython if available):

scrapy shell <url>
% screenfetch

% Start screenfetch:

screenfetch

% Take a screenshot (requires 'scrot'):

screenfetch -s

% Specify distribution logo:

screenfetch -A '<distribution_name>'

% Specify distribution logo and text:

screenfetch -D '<distribution_name>'

% Strip all color:

screenfetch -N
% screen

% Start a new screen session:

screen

% Start a new named screen session:

screen -S <session_name>

% Start a new daemon and log the output to screenlog.x:

screen -dmLS <session_name> <command>

% Show open screen sessions:

screen -ls

% Reattach to an open screen:

screen -r <session_name>

% Detach from inside a screen:

Ctrl + A, D

% Kill the current screen session:

Ctrl + A, K

% Kill a detached screen:

screen -X -S <session_name> quit
% script

% Start recording in file named "typescript":

script

% Stop recording:

exit

% Start recording in a given file:

script <logfile.log>

% Append to an existing file:

script -a <logfile.log>

% Execute quietly without start and done messages:

script -q <logfile.log>
% sdiff

% Compare 2 files:

sdiff <path/to/file1> <path/to/file2>

% Compare 2 files, ignoring all tabs and whitespace:

sdiff -W <path/to/file1> <path/to/file2>

% Compare 2 files, ignoring whitespace at the end of lines:

sdiff -Z <path/to/file1> <path/to/file2>

% Compare 2 files in a case-insensitive manner:

sdiff -i <path/to/file1> <path/to/file2>

% Compare and then merge, writing the output to a new file:

sdiff -o <path/to/merged_file> <path/to/file1> <path/to/file2>
% sdk

% Install a specific version of Gradle:

sdk install <gradle> <gradle_version>

% Switch to a specific version of Gradle:

sdk use <gradle> <gradle_version>

% Check current Gradle version:

sdk current <gradle>

% List all Software Development Kits available to install:

sdk list

% Update Gradle to the latest version:

sdk upgrade <gradle>

% Uninstall a particular version of Gradle:

sdk rm <gradle> <gradle_version>
% sd

% Trim some whitespace using regex:

<echo 'lorem ipsum 23   '> | sd '\s+$' ''

% Replace words using capture groups:

<echo 'cargo +nightly watch'> | sd '(\w+)\s+\+(\w+)\s+(\w+)' 'cmd: $1, channel: $2, subcmd: $3'

% Find and replace in a file:

sd -i <'window.fetch'> <'fetch'> <http.js>

% Find and replace across a project:

sd -i <'from "react"'> <'from "preact"'> $(find . -type f)
% secrethub

% Print a secret to stdout:

secrethub read <path/to/secret>

% Generate a random value and store it as a new or updated secret:

secrethub generate <path/to/secret>

% Store a value from the clipboard as a new or updated secret:

secrethub write --clip <path/to/secret>

% Store a value supplied on stdin as a new or updated secret:

echo "<secret_value>" | secrethub write <path/to/secret>

% Audit a repository or secret:

secrethub audit <path/to/repo_or_secret>
% sed

% Replace the first occurrence of a regular expression in each line of a file, and print the result:

sed 's/<regex>/<replace>/' <filename>

% Replace all occurrences of an extended regular expression in a file, and print the result:

sed -r 's/<regex>/<replace>/g' <filename>

% Replace all occurrences of a string in a file, overwriting the file (i.e. in-place):

sed -i 's/<find>/<replace>/g' <filename>

% Replace only on lines matching the line pattern:

sed '/<line_pattern>/s/<find>/<replace>/' <filename>

% Delete lines matching the line pattern:

sed '/<line_pattern>/d' <filename>

% Print only text between n-th line till the next empty line:

sed -n '<n>,/^$/p' <filename>

% Apply multiple find-replace expressions to a file:

sed -e 's/<find>/<replace>/' -e 's/<find>/<replace>/' <filename>

% Replace separator / by any other character not used in the find or replace patterns, e.g., #:

sed 's#<find>#<replace>#' <filename>

% Print only the n-th line of a file:

sed '<n>q;d' <filename>
% sendmail

% Send a message with the content of message.txt to the mail directory of local user `username`:

sendmail <username> < <message.txt>

% Send an email from you@yourdomain.com (assuming the mail server is configured for this) to test@gmail.com containing the message in `message.txt`:

sendmail -f <you@yourdomain.com> <test@gmail.com> < <message.txt>

% Send an email from you@yourdomain.com (assuming the mail server is configured for this) to test@gmail.com containing the file `file.zip`:

sendmail -f <you@yourdomain.com> <test@gmail.com> < <file.zip>
% seq

% Sequence from 1 to 10:

seq 10

% Every 3rd number from 5 to 20:

seq 5 3 20

% Separate the output with a space instead of a newline:

seq -s " " 5 3 20

% Format output width to a minimum of 4 digits padding with zeros as necessary:

seq -f "%04g" 5 3 20
% sequelize

% Create a model and a migration file:

sequelize model:generate --name <table_name>

% Run the migration file:

sequelize db:migrate

% Revert all migrations:

sequelize db:migrate:undo:all

% Create a seed file with the specified name to populate the database:

sequelize seed:generate --name <seed_filename>

% Populate database using all seed files:

sequelize db:seed:all
% serverless

% Create a serverless project:

serverless create

% Create a serverless project from a template:

serverless create --template <template_name>

% Deploy to a cloud provider:

serverless deploy

% Display information about a serverless project:

serverless info

% Invoke a deployed function:

serverless invoke -f <function_name>

% Follow the logs for a project:

serverless logs -t
% set

% Display the names and values of shell variables:

set

% Mark variables that are modified or created for export:

set -a

% Notify of job termination immediately:

set -b

% Set various options, e.g. enable `vi` style line editing:

set -o <vi>
% sftp

% Connect to a remote server and enter an interactive command mode:

sftp <remote_user>@<remote_host>

% Connect using an alternate port:

sftp -P <remote_port> <remote_user>@<remote_host>

% Transfer remote file to the local system:

get </path/remote_file>

% Transfer local file to the remote system:

put </path/local_file>

% Transfer remote directory to the local system recursively (works with `put` too):

get -R </path/remote_directory>

% Get list of files on local machine:

lls

% Get list of files on remote machine:

ls
% sha1sum

% Calculate the SHA1 checksum for a file:

sha1sum <filename1>

% Calculate SHA1 checksums for multiple files:

sha1sum <filename1> <filename2>

% Read a file of SHA1 sums and verify all files have matching checksums:

sha1sum -c <filename.sha1>
% sha224sum

% Calculate the SHA224 checksum for a file:

sha224sum <filename1>

% Calculate SHA224 checksums for multiple files:

sha224sum <filename1> <filename2>

% Read a file of SHA224 sums and verify all files have matching checksums:

sha224sum -c <filename.sha224>
% sha256sum

% Calculate the SHA256 checksum for a file:

sha256sum <filename1>

% Calculate SHA256 checksums for multiple files:

sha256sum <filename1> <filename2>

% Read a file of SHA256 sums and verify all files have matching checksums:

sha256sum -c <filename.sha256>
% sha384sum

% Calculate the SHA384 checksum for a file:

sha384sum <filename1>

% Calculate SHA384 checksums for multiple files:

sha384sum <filename1> <filename2>

% Read a file of SHA384 sums and verify all files have matching checksums:

sha384sum -c <filename.sha384>
% sha512sum

% Calculate the SHA512 checksum for a file:

sha512sum <filename1>

% Calculate SHA512 checksums for multiple files:

sha512sum <filename1> <filename2>

% Read a file of SHA512 sums and verify all files have matching checksums:

sha512sum -c <filename.sha512>
% shards

% Create a skeleton shard.yml file:

shards init

% Install dependencies from a shard.yml file:

shards install

% Update all dependencies:

shards update

% List all installed dependencies:

shards list

% List version of dependency:

shards version <path/to/dependency_directory>
% shc

% Compile a shell script:

shc -f <script>

% Compile a shell script and specify an output binary file:

shc -f <script> -o <binary>

% Compile a shell script and set an expiration date for the executable:

shc -f <script> -e <dd/mm/yyyy>

% Compile a shell script and set a message to display upon expiration:

shc -f <script> -e <dd/mm/yyyy> -m <"Please contact your provider">
% shellcheck

% Check a shell script:

shellcheck <file.sh>

% Override script's shebang:

shellcheck --shell <sh|bash|ksh> <file.sh>

% Ignore certain errors:

shellcheck --exclude <SC1009> <file.sh>

% Ignore multiple errors:

shellcheck --exclude <SC1009,SC1073> <file.sh>
% shiori

% Import bookmarks from HTML Netscape bookmark format file:

shiori import <path/to/bookmarks.html>

% Save the specified URL as bookmark:

shiori add <url>

% List the saved bookmarks:

shiori print

% Open the saved bookmark in a browser:

shiori open <bookmark_id>

% Start the web interface for managing bookmarks at port 8181:

shiori serve --port <8181>
% sh

% Start interactive shell:

sh

% Execute a command:

sh -c <command>

% Run commands from a file:

sh <file.sh>

% Run commands from `stdin`:

sh -s
% shopt

% List of all settable options and whether they are set:

shopt

% Set an option:

shopt -s <option_name>

% Unset an option:

shopt -u <option_name>

% Print a list of all options and their status formatted as runnable `shopt` commands:

shopt -p

% Show help for the command:

help shopt
% shred

% Overwrite a file:

shred <file>

% Overwrite a file, leaving zeroes instead of random data:

shred --zero <file>

% Overwrite a file 25 times:

shred -n25 <file>

% Overwrite a file and remove it:

shred --remove <file>
% shuf

% Randomize the order of lines in a file and output the result:

shuf <filename>

% Only output the first 5 entries of the result:

shuf -n <5> <filename>

% Write the output to another file:

shuf <filename> -o <output_filename>

% Generate random numbers in range:

shuf -i <1-10>
% singularity

% Download a remote image from Sylabs Cloud:

singularity pull --name <image.sif> <library://godlovedc/funny/lolcow:latest>

% Rebuild a remote image using latest Singularity image format:

singularity build <image.sif> <docker://godlovedc/lolcow>

% Start a container from an image and get a shell inside of it:

singularity shell <image.sif>

% Start a container from an image and run a command:

singularity exec <image.sif> <command>

% Start a container from an image and execute the internal runscript:

singularity run <image.sif>

% Build a singularity image from a recipe file:

sudo singularity build <image.sif> <recipe>
% skaffold

% Build the artifacts:

skaffold build -f <skaffold.yaml>

% Build and deploy your app every time your code changes:

skaffold dev -f <skaffold.yaml>

% Run a pipeline file:

skaffold run -f <skaffold.yaml>

% Run a diagnostic on Skaffold:

skaffold diagnose -f <skaffold.yaml>

% Deploy the artifacts:

skaffold deploy -f <skaffold.yaml>
% skicka

% Upload a file/folder to Google Drive:

skicka upload <path/to/local> <path/to/remote>

% Download a file/folder from Google Drive:

skicka download <path/to/remote> <path/to/local>

% List files:

skicka ls <path/to/folder>

% Show amount of space used by children folders:

skicka du <path/to/parent/folder>

% Create a folder:

skicka mkdir <path/to/folder>

% Delete a file:

skicka rm <path/to/file>
% slackcat

% Post a file to Slack:

slackcat --channel <channel_name> <path/to/file>

% Post a file to Slack with a custom filename:

slackcat --channel <channel_name> --filename=<filename> <path/to/file>

% Pipe command output to Slack as a text snippet:

<command> | slackcat --channel <channel_name> --filename=<snippet_name>

% Stream command output to Slack continuously:

<command> | slackcat --channel <channel_name> --stream
% sleep

% Delay in seconds:

sleep <seconds>

% Delay in minutes:

sleep <minutes>m

% Delay in hours:

sleep <hours>h
% slimrb

% Convert a Slim file to HTML:

slimrb <input.slim> <output.html>

% Convert a Slim file and output to prettified HTML:

slimrb --pretty <input.slim> <output.html>

% Convert a Slim file to ERB:

slimrb --erb <input.slim> <output.erb>
% sl

% Let a steam locomotive run through your terminal:

sl

% The train burns, people scream:

sl -a

% Let the train fly:

sl -F

% Make the train little:

sl -l

% Let the user exit (CTRL + C):

sl -e
% smartctl

% View SMART health summary:

sudo smartctl --health </dev/sda>

% View device information:

sudo smartctl --info </dev/sda>

% Begin a short self-test:

sudo smartctl --test short </dev/sda>

% View current/last self-test status and other SMART capabilities:

sudo smartctl --capabilities </dev/sda>

% View SMART self-test log (if supported):

sudo smartctl --log selftest </dev/sda>
% s

% Search for a query on Google(default provider):

s <query>

% List all providers:

s --list-providers

% Search for a query with a given provider:

s --provider <provider> <query>

% Use a specified binary to perform the search query:

s --binary "<binary> <arguments>" <query>
% sn

% Generate a new StrongNaming key:

sn -k <path/to/key.snk>

% Re-sign an assembly with the specified private key:

sn -R <path/to/assembly.dll> <path/to/keypair.snk>

% Show the public key of the private key that was used to sign an assembly:

sn -T <path/to/assembly.exe>

% Extract the public key to a file:

sn -e <path/to/assembly.dll> <path/to/output.pub>
% snyk

% Login to your Snyk account:

snyk auth

% Test your code for any known vulnerabilities:

snyk test

% Test a local Docker image for any known vulnerabilities:

snyk test --docker <docker_image>

% Record the state of dependencies and any vulnerabilities on snyk.io:

snyk monitor

% Auto patch and ignore vulnerabilities:

snyk wizard
% socat

% Listen to a port, wait for an incoming connection and transfer data to STDIO:

socat - TCP-LISTEN:8080,fork

% Create a connection to a host and port, transfer data in STDIO to connected host:

socat - TCP4:www.example.com:80

% Forward incoming data of a local port to another host and port:

socat TCP-LISTEN:80,fork TCP4:www.example.com:80
% solo

% List connected Solos:

solo ls

% Update the currently connected Solo's firmware to the latest version:

solo key update

% Blink the led of a specific Solo:

solo key wink --serial <serial_number>

% Generate random bytes using the currently connected Solo's secure random number generator:

solo key rng raw

% Monitor the serial output of a Solo:

solo monitor <path/to/serial_port>
% sops

% Encrypt a file:

sops -e <path/to/myfile.json> > <path/to/myfile.enc.json>

% Decrypt a file to the standard output:

sops -d <path/to/myfile.enc.json>

% Rotate data keys for a sops file:

sops -r <path/to/myfile.enc.yaml>

% Change the extension of the file once encrypted:

sops -d --input-type json <path/to/myfile.enc.json>

% Extract keys by naming them, and array elements by numbering them:

sops -d --extract '["an_array"][1]' <path/to/myfile.enc.json>

% Show the difference between two sops files:

diff <(sops -d <path/to/secret1.enc.yaml>) <(sops -d <path/to/secret2.enc.yaml>)
% sort

% Sort a file in ascending order:

sort <filename>

% Sort a file in descending order:

sort -r <filename>

% Sort a file in case-insensitive way:

sort --ignore-case <filename>

% Sort a file using numeric rather than alphabetic order:

sort -n <filename>

% Sort the passwd file by the 3rd field, numerically:

sort -t: -k 3n /etc/passwd

% Sort a file preserving only unique lines:

sort -u <filename>

% Sort human-readable numbers (in this case the 5th field of `ls -lh`):

ls -lh | sort -h -k 5
% source

% Evaluate contents of a given file:

source <path/to/file>
% sox

% Merge two audio files into one:

sox -m <input_audiofile1> <input_audiofile2> <output_audiofile>

% Trim an audio file to the specified times:

sox <input_audiofile> <output_audiofile> trim <start> <end>

% Normalize an audio file (adjust volume to the maximum peak level, without clipping):

sox --norm <input_audiofile> <output_audiofile>

% Reverse and save an audio file:

sox <input_audiofile> <output_audiofile> reverse

% Print statistical data of an audio file:

sox <input_audiofile> -n stat

% Increase the volume of an audio file by 2x:

sox -v 2.0 <input_audiofile> <output_audiofile>
% spark

% Register your API token:

spark register <token>

% Display the currently registered API token:

spark token

% Create a new Spark project:

spark new <project_name>

% Create a new Spark project with Braintree stubs:

spark new <project_name> --braintree

% Create a new Spark project with team based billing stubs:

spark new <project_name> --team-billing
% spatial

% Run this when you use a project for the first time:

spatial worker build

% Build workers for local deployment on Unity on macOS:

spatial worker build --target=development --target=Osx

% Build workers for local deployment on Unreal on Windows:

spatial worker build --target=local --target=Windows

% Deploy locally:

spatial local launch <launch_config> --snapshot=<snapshot_file>

% Launch a local worker to connect to your local deployment:

spatial local worker launch <worker_type> <launch_config>

% Upload an assembly to use for cloud deployments:

spatial cloud upload <assembly_name>

% Launch a cloud deployment:

spatial cloud launch <assembly_name> <launch_config> <deployment_name>

% Clean worker directories:

spatial worker clean
% speedtest-cli

% Run a speed test:

speedtest-cli

% Run a speed test and generate a shareable result picture:

speedtest-cli --share

% Print a list of all speedtest.net servers, sorted by distance, to file:

speedtest-cli --list > speedtest_servers.txt

% Run a speed test to the given speedtest.net server id:

speedtest-cli --server <server_id>
% sphinx-build

% Build documentation:

sphinx-build -b <html|epub|text|latex|man|...> <path/to/source_dir> <path/to/build_dir>

% Build documentations intended for readthedocs.io (requires the sphinx-rtd-theme pip package):

sphinx-build -b <html> <path/to/docs_dir> <path/to/build_dir>
% spike

% Create a new project using the default template:

spike new <project_name>

% Compile your project, watch for changes, and auto-reload the browser:

spike watch

% Compile your project once to the "public" directory:

spike compile

% Remove the output directory:

spike clean
% split

% Split a file, each split having 10 lines (except the last split):

split -l <10> <filename>

% Split a file into 5 files. File is split such that each split has same size (except the last split):

split -n <5> <filename>

% Split a file with 512 bytes in each split (except the last split; use 512k for kilobytes and 512m for megabytes):

split -b <512> <filename>

% Split a file with at most 512 bytes in each split without breaking lines:

split -C <512> <filename>
% sqlite3

% Start an interactive shell with a new database:

sqlite3

% Open an interactive shell against an existing database:

sqlite3 <path/to/database.sqlite3>

% Execute an SQL statement against a database and then exit:

sqlite3 <path/to/database.sqlite3> '<SELECT * FROM some_table;>'
% sqlmap

% Run sqlmap against a single target URL:

python sqlmap.py -u <"http://www.target.com/vuln.php?id=1">

% Send data in a POST request (`--data` implies POST request):

python sqlmap.py -u <"http://www.target.com/vuln.php"> --data=<"id=1">

% Change the parameter delimiter (& is the default):

python sqlmap.py -u <"http://www.target.com/vuln.php"> --data=<"query=foobar;id=1"> --param-del=<";">

% Select a random `User-Agent` from `./txt/user-agents.txt` and use it:

python sqlmap.py -u <"http://www.target.com/vuln.php"> --random-agent

% Provide user credentials for HTTP protocol authentication:

python sqlmap.py -u <"http://www.target.com/vuln.php"> --auth-type <Basic> --auth-cred <"testuser:testpass">
% sqsc

% List all queues:

sqsc lq <queue_prefix>

% List all messages in a queue:

sqsc ls <queue_name>

% Copy all messages from one queue to another:

sqsc cp <source_queue> <destination_queue>

% Move all messages from one queue to another:

sqsc mv <source_queue> <destination_queue>

% Describe a queue:

sqsc describe <queue_name>

% Query a queue with SQL syntax:

sqsc query "SELECT body FROM <queue_name> WHERE body LIKE '%user%'"

% Pull all messages from a queue into a local sqlite database in your present working directory:

sqsc pull <queue_name>
% srm

% Remove a file after a single-pass overwriting with random data:

srm -s </path/to/file>

% Remove a file after seven passes of overwriting with random data:

srm -m </path/to/file>

% Recursively remove a directory and its contents overwriting each file with a single-pass of random data:

srm -r -s </path/to/directory>

% Prompt before every removal:

srm -i <\*>
% ssh-copy-id

% Copy your keys to the remote machine:

ssh-copy-id <username@remote_host>

% Copy the given public key to the remote:

ssh-copy-id -i <path/to/certificate> <username>@<remote_host>

% Copy the given public key to the remote with specific port:

ssh-copy-id -i <path/to/certificate> -p <port> <username>@<remote_host>
% sshfs

% Mount remote directory:

sshfs <username>@<remote_host>:<remote_directory> <mountpoint>

% Unmount remote directory:

umount <mountpoint>

% Mount remote directory from server with specific port:

sshfs <username>@<remote_host>:<remote_directory> -p <2222>

% Use compression:

sshfs <username>@<remote_host>:<remote_directory> -C

% Follow symbolic links:

sshfs -o follow_symlinks <username>@<remote_host>:<remote_directory> <mountpoint>
% ssh-keygen

% Generate a key interactively:

ssh-keygen

% Specify file in which to save the key:

ssh-keygen -f ~/.ssh/<filename>

% Generate an ed25519 key with 100 key derivation function rounds:

ssh-keygen -t ed25519 -a 100

% Generate an RSA 4096 bit key with email as a comment:

ssh-keygen -t rsa -b 4096 -C "<email>"

% Retrieve the key fingerprint from a host (useful for confirming the authenticity of the host when first connecting to it via SSH):

ssh-keygen -l -F <remote_host>

% Remove the keys of a host from the known_hosts file (useful when a known host has a new key):

ssh-keygen -R <remote_host>

% Retrieve the fingerprint of a key in MD5 Hex:

ssh-keygen -l -E md5 -f ~/.ssh/<filename>

% Change the password of a key:

ssh-keygen -p -f ~/.ssh/<filename>
% ssh-keyscan

% Retrieve all public ssh keys of a remote host:

ssh-keyscan <host>

% Retrieve all public ssh keys of a remote host listening on a specific port:

ssh-keyscan -p <port> <host>

% Retrieve certain types of public ssh keys of a remote host:

ssh-keyscan -t <rsa,dsa,ecdsa,ed25519> <host>
% ssh

% Connect to a remote server:

ssh <username>@<remote_host>

% Connect to a remote server with a specific identity (private key):

ssh -i <path/to/key_file> <username>@<remote_host>

% Connect to a remote server using a specific port:

ssh <username>@<remote_host> -p <2222>

% Run a command on a remote server:

ssh <remote_host> <command -with -flags>

% SSH tunneling: Dynamic port forwarding (SOCKS proxy on localhost:9999):

ssh -D <9999> -C <username>@<remote_host>

% SSH tunneling: Forward a specific port (localhost:9999 to example.org:80) along with disabling pseudo-[t]ty allocation and executio[n] of remote commands:

ssh -L <9999>:<example.org>:<80> -N -T <username>@<remote_host>

% SSH jumping: Connect through a jumphost to a remote server (Multiple jump hops may be specified separated by comma characters):

ssh -J <username>@<jump_host> <username>@<remote_host>

% Agent forwarding: Forward the authentication information to the remote machine (see `man ssh_config` for available options):

ssh -A <username>@<remote_host>
% sshpass

% Connect to a remote server using a password supplied on a file descriptor (in this case, `stdin`):

sshpass -d <0> ssh <user>@<hostname>

% Connect to a remote server with the password supplied as an option, and automatically accept unknown ssh keys:

sshpass -p <password> ssh -o StrictHostKeyChecking=no <user>@<hostname>

% Connect to a remote server using the first line of a file as the password, automatically accept unknown ssh keys, and launch a command:

sshpass -f <file> ssh -o StrictHostKeyChecking=no <user>@<hostname> "<command>"
% stack

% Create a new package:

stack new <package_name> <template_name>

% Compile a package:

stack build

% Run tests inside a package:

stack test

% Compile a project and re-compile every time a file changes:

stack build --file-watch

% Compile a project and execute a command after compilation:

stack build --exec "<command>"

% Run a program and pass an argument to it:

stack exec <program_name> -- <argument>
% standard

% Lint all JavaScript source files in the current directory:

standard

% Lint specific JavaScript file(s):

standard <path/to/file(s)>

% Apply automatic fixes during linting:

standard --fix

% Declare any available global variables:

standard --global <variable>

% Use a custom ESLint plugin when linting:

standard --plugin <plugin>

% Use a custom JS parser when linting:

standard --parser <parser>

% Use a custom ESLint environment when linting:

standard --env <environment>
% stat

% Show file properties such as size, permissions, creation and access dates among others:

stat <file>

% Same as above but in a more concise way:

stat -t <file>

% Show filesystem information:

stat -f <file>

% Show only octal file permissions:

stat -c "%a %n" <file>

% Show owner and group of the file:

stat -c "%U %G" <file>

% Show the size of the file in bytes:

stat -c "%s %n" <file>
% stdbuf

% Change the standard input buffer size to 512 KiB:

stdbuf --input=<512K> <command>

% Change the standard output buffer to line-buffered:

stdbuf --output=<L> <command>

% Change the standard error buffer to unbuffered:

stdbuf --error=<0> <command>
% stern

% Tail all pods within a current namespace:

stern .

% Tail all pods with a specific status:

stern . --container-state <running|waiting|terminated>

% Tail all pods that matches a given regular expression:

stern <pod_query>

% Tail matched pods from all namespaces:

stern <pod_query> --all-namespaces

% Tail matched pods from 15 minutes ago:

stern <pod_query> --since <15m>

% Tail matched pods with a specific label:

stern <pod_query> --selector <release=canary>
% st-flash

% Read 4096 bytes from the device starting from 0x8000000:

st-flash read <firmware>.bin <0x8000000> <4096>

% Write firmware to device starting from 0x8000000:

st-flash write <firmware>.bin <0x8000000>

% Erase firmware from device:

st-flash erase
% st-info

% Display amount of program memory available:

st-info --flash

% Display amount of sram memory available:

st-info --sram

% Display summarized information of the device:

st-info --probe
% Stolon

% Get cluster status:

stolonctl --cluster-name <cluster_name> --store-backend <store_backend> --store-endpoints <store_endpoints> status

% Get cluster data:

stolonctl --cluster-name <cluster_name> --store-backend <store_backend> --store-endpoints <store_endpoints> clusterdata

% Get cluster specification:

stolonctl --cluster-name <cluster_name> --store-backend <store_backend> --store-endpoints <store_endpoints> spec

% Update cluster specification with a patch in json format:

stolonctl --cluster-name <cluster_name> --store-backend <store_backend> --store-endpoints <store_endpoints> update --patch '<cluster_spec>'
% stow

% Symlink all files recursively to a given directory:

stow --target=<path/to/target_directory> <file1 directory1 file2 directory2>

% Delete symlinks recursively from a given directory:

stow --delete --target=<path/to/target_directory> <file1 directory1 file2 directory2>

% Simulate to see what the result would be like:

stow --simulate --target=<path/to/target_directory> <file1 directory1 file2 directory2>

% Delete and resymlink:

stow --restow --target=<path/to/target_directory> <file1 directory1 file2 directory2>

% Exclude files matching a regular expression:

stow --ignore=<regex> --target=<path/to/target_directory> <file1 directory1 file2 directory2>
% strings

% Print all strings in a binary:

strings <file>

% Limit results to strings at least *length* characters long:

strings -n <length> <file>

% Prefix each result with its offset within the file:

strings -t d <file>

% Prefix each result with its offset within the file in hexadecimal:

strings -t x <file>
% stty

% Display all settings for the current terminal:

stty -a

% Set the number of rows:

stty rows <rows>

% Set the number of columns:

stty cols <cols>

% Get the actual transfer speed of a device:

stty -f <path/to/device_file> speed

% Reset all modes to reasonable values for the current terminal:

stty sane
% st-util

% Run GDB server on port 4500:

st-util -p <4500>

% Connect to GDB server:

(gdb) target extended-remote <localhost>:<4500>

% Write firmware to device:

(gdb) load <firmware.elf>
% subfinder

% Find subdomains for a specific domain:

subfinder -d <example.com>

% Show only the subdomains found:

subfinder --silent -d <example.com>

% Use bruteforcing to find subdomains:

subfinder -d <example.com> -b

% Remove wildcard subdomains:

subfinder -nW -d <example.com>

% Use a given comma-separated list of resolvers:

subfinder -r <8.8.8.8>,<1.1.1.1> -d <example.com>
% subliminal

% Download English subtitles for a video:

subliminal download -l <en> <video.ext>
% subl

% Open the current directory in Sublime Text:

subl <.>

% Open a file or directory in Sublime Text:

subl <path/to/file_or_directory>

% Open a file and jump to a specific line number:

subl <path/to/file>:<line_number>

% Open a file or directory in the currently open window:

subl -a <path/to/file>

% Open a file or directory in a new window:

subl -n <path/to/file>
% sudo

% Run a command as the superuser:

sudo <less /var/log/syslog>

% Edit a file as the superuser with your default editor:

sudo -e </etc/fstab>

% Run a command as another user and/or group:

sudo -u <user> -g <group> <id -a>

% Repeat the last command prefixed with "sudo" (only in bash, zsh, etc.):

sudo !!

% Launch the default shell with superuser privileges:

sudo -i
% su

% Switch to superuser (requires the root password):

su

% Switch to a given user (requires the user's password):

su <username>

% Switch to a given user and simulate a full login shell:

su - <username>

% Execute a command as another user:

su - <username> -c "<command>"
% sum

% Compute a checksum with BSD-compatible algorithm and 1024-byte blocks:

sum <file>

% Compute a checksum with System V-compatible algorithm and 512-byte blocks:

sum --sysv <file>
% supervisorctl

% Start/stop/restart a process:

supervisorctl <start|stop|restart> <process_name>

% Start/stop/restart all processes in a group:

supervisorctl <start|stop|restart> <group_name>:*

% Show last 100 **bytes** of process `stderr`:

supervisorctl tail -100 <process_name> stderr

% Keep displaying `stdout` of a process:

supervisorctl tail -f <process_name> stdout

% Reload process config file to add/remove processes as necessary:

supervisorctl update
% supervisord

% Start supervisord with specified configuration file:

supervisord -c <path/to/file>

% Run supervisord in the foreground:

supervisord -n
% surge

% Upload a new site to surge.sh:

surge <path/to/my_project>

% Deploy site to custom domain (note that the DNS records must point to the surge.sh subdomain):

surge <path/to/my_project> <my_custom_domain.com>

% List your surge projects:

surge list

% Remove a project:

surge teardown <my_custom_domain.com>
% svgcleaner

% Optimize an SVG image:

svgcleaner <input.svg> <output.svg>

% Optimize an SVG image multiple times:

svgcleaner --multipass <input.svg> <output.svg>
% svgo

% Optimize a file using the default plugins (overwrites the original file):

svgo <test.svg>

% Optimize a file and save the result to another file:

svgo <test.svg> <test.min.svg>

% Optimize all SVG files within a directory (overwrites the original files):

svgo -f <path/to/directory/with/svg/files>

% Optimize all SVG files within a directory and save the resulting files to another directory:

svgo -f <path/to/input/directory> -o <path/to/output/directory>

% Optimize SVG content passed from another command, and save the result to a file:

<cat test.svg> | svgo -i - -o <test.min.svg>

% Optimize a file and print out the result:

svgo <test.svg> -o -

% Optimize a file making sure a given plugin is enabled:

svgo --enable=<plugin_name>

% Show available plugins:

svgo --show-plugins
% svn

% Check out a working copy from a repository:

svn co <url/to/repository>

% Bring changes from the repository into the working copy:

svn up

% Put files and directories under version control, scheduling them for addition to repository. They will be added in next commit:

svn add <PATH>

% Send changes from your working copy to the repository:

svn ci -m <commit log message> [<PATH>]

% Display changes from the last 10 revisions, showing modified files for each revision:

svn log -vl <10>

% Show detailed help:

svn help
% swagger-codegen

% Generate documentation and code from an OpenAPI/swagger file:

swagger-codegen generate -i <swagger_file> -l <language>

% Generate java code using the library retrofit2 and the option useRxJava2:

swagger-codegen generate -i <http://petstore.swagger.io/v2/swagger.json> -l <java> --library <retrofit2> -D<useRxJava2>=<true>

% List available languages:

swagger-codegen langs

% Display help options for the generate command:

swagger-codegen help <generate>
% swift

% Invoke the interactive interpreter (REPL):

swift

% Execute a program:

swift <file.swift>

% Start a new project with the package manager:

swift package init

% Generate an Xcode project file:

swift package generate-xcodeproj

% Update dependencies:

swift package update

% Compile project for release:

swift build -c release
% symfony

% Create a new Symfony project:

symfony new <name>

% Run a local web server:

symfony serve

% Stop the local web server:

symfony server:stop

% Check for security issues in the project's dependencies:

symfony security:check
% sync

% Flush all pending write operations on all disks:

sync

% Flush all pending write operations on a single file to disk:

sync <path/to/file>
% tabula

% Extract all tables from a PDF to a CSV file:

tabula -o <file.csv> <file.pdf>

% Extract all tables from a PDF to a JSON file:

tabula --format JSON -o <file.json> <file.pdf>

% Extract tables from pages 1, 2, 3, and 6 of a PDF:

tabula --pages <1-3,6> <file.pdf>

% Extract tables from page 1 of a PDF, guessing which portion of the page to examine:

tabula --guess --pages <1> <file.pdf>

% Extract all tables from a PDF, using ruling lines to determine cell boundaries:

tabula --spreadsheet <file.pdf>

% Extract all tables from a PDF, using blank space to determine cell boundaries:

tabula --no-spreadsheet <file.pdf>
% tac

% Print the contents of *file1* reversed to the standard output:

tac <file1>

% Print the contents of the standard input reversed to the standard output:

<command> | tac

% Concatenate several files reversed into the target file:

tac <file1> <file2> > <target_file>
% tail

% Show last 'num' lines in file:

tail -n <num> <file>

% Show all file since line 'num':

tail -n +<num> <file>

% Show last 'num' bytes in file:

tail -c <num> <file>

% Keep reading file until `Ctrl + C`:

tail -f <file>

% Keep reading file until `Ctrl + C`, even if the file is rotated:

tail -F <file>
% tar

% Create an archive from files:

tar cf <target.tar> <file1> <file2> <file3>

% Create a gzipped archive:

tar czf <target.tar.gz> <file1> <file2> <file3>

% Create a gzipped archive from a directory using relative paths:

tar czf <target.tar.gz> -C <path/to/directory> .

% Extract a (compressed) archive into the current directory:

tar xf <source.tar[.gz|.bz2|.xz]>

% Extract an archive into a target directory:

tar xf <source.tar> -C <directory>

% Create a compressed archive, using archive suffix to determine the compression program:

tar caf <target.tar.xz> <file1> <file2> <file3>

% List the contents of a tar file:

tar tvf <source.tar>

% Extract files matching a pattern:

tar xf <source.tar> --wildcards <"*.html">
% task

% Add new task:

task add <thing_to_do>

% List tasks:

task list

% Mark task as completed:

task <task_id> done

% Modify task:

task <task_id> modify <new_thing_to_do>

% Delete task:

task <task_id> delete
% tb

% Add a new task to a board:

tb --task <task description> @<board_name>

% Add a new note to a board:

tb --note <note description> @<board_name>

% Edit item's priority:

tb --priority @<item_id> <priority>

% Check/uncheck item:

tb --check <item_id>

% Archive all checked items:

tb --clear

% Move item to a board:

tb --move @<item_id> <board_name>
% tcpdump

% List available network interfaces:

tcpdump -D

% Capture the traffic of a specific interface:

tcpdump -i <eth0>

% Capture all TCP traffic showing contents (ASCII) in console:

tcpdump -A tcp

% Capture the traffic from or to a host:

tcpdump host <www.example.com>

% Capture the traffic from a specific interface, source, destination and destination port:

tcpdump -i <eth0> src <192.168.1.1> and dst <192.168.1.2> and dst port <80>

% Capture the traffic of a network:

tcpdump net <192.168.1.0/24>

% Capture all traffic except traffic over port 22 and save to a dump file:

tcpdump -w <dumpfile.pcap> not port <22>

% Read from a given dump file:

tcpdump -r <dumpfile.pcap>
% tee

% Copy standard input to each FILE, and also to standard output:

echo "example" | tee <FILE>

% Append to the given FILEs, do not overwrite:

echo "example" | tee -a <FILE>

% Print standard input to the terminal, and also pipe it into another program for further processing:

echo "example" | tee </dev/tty> | <xargs printf "[%s]">

% Create a directory called "example", count the number of characters in "example" and write "example" to the terminal:

echo "example" | tee >(xargs mkdir) >(wc -c)
% telnet

% Telnet to the default port of a host:

telnet <host>

% Telnet to a specific port of a host:

telnet <ip_address> <port>

% Exit a telnet session:

quit

% Emit the default escape character combination for terminating the session:

Ctrl + ]

% Start telnet with "x" as the session termination character:

telnet -e <x> <ip_address> <port>
% terminalizer

% Create the global config directory:

terminalizer init

% Record the terminal and create a recording file:

terminalizer record <file_name>

% Play a recorded file on the terminal:

terminalizer play <file_name>

% Render a recording file as an animated gif image:

terminalizer render <file_name>

% Upload a video to terminalizer.com:

terminalizer share <file_name>
% terraform

% Initialize a new or existing Terraform configuration:

terraform init

% Generate and show an execution plan:

terraform plan

% Build or change infrastructure:

terraform apply

% Destroy Terraform-managed infrastructure:

terraform destroy
% tesseract

% Recognize text in an image and save it to `output.txt` (the '.txt' extension is added automatically):

tesseract <image.png> <output>

% Specify a custom language (default is English) with an ISO 639-2 code (e.g. deu = Deutsch = German):

tesseract -l deu <image.png> <output>

% List the ISO 639-2 codes of available languages:

tesseract --list-langs

% Specify a custom page segmentation mode (default is 3):

tesseract -psm <0_to_10> <image.png> <output>

% List page segmentation modes and their descriptions:

tesseract --help-psm
% test

% Test if given variable is equal to given string:

test $MY_VAR == '/bin/zsh'

% Test if given variable is empty:

test -z $GIT_BRANCH

% Test if file exists:

test -e <filename>

% Test if directory not exists:

test ! -d <path/to/directory>

% If-else statement:

test <condition> && echo "true" || echo "false"
% thundebird

% Open thunderbird:

thunderbird

% Use a specific user profile directory:

thunderbird -P <path/to/profile/directory>
% tig

% Show the sequence of commits starting from the current one in reverse chronological order:

tig

% Show the history of a specific branch:

tig <branch>

% Show the history of specific files or directories:

tig <path1 path2 …>

% Show the difference between two references (such as branches or tags):

tig <base_ref>..<compared_ref>

% Display commits from all branches and stashes:

tig --all

% Start in stash view, displaying all saved stashes:

tig stash
% time

% Time "ls":

time ls
% timeout

% Run `sleep 10` and terminate it, if it runs for more than 3 seconds:

timeout <3s> <sleep 10>

% Specify the signal to be sent to the command after the time limit expires. (By default, TERM is sent):

timeout --signal <INT> <5s> <sleep 10>
% timew

% Start a new stopwatch, giving a tag name to the activity being tracked:

timew start <activity_tag>

% View running stopwatches:

timew

% Stop the stopwatch with a given tag name:

timew stop <activity_tag>

% Stop all running stopwatches:

timew stop

% View tracked items:

timew summary
% tldrl

% Lint all pages:

tldrl <pages_directory>

% Format a specific page to `stdout`:

tldrl -f <page.md>

% Format all pages in place:

tldrl -fi <pages_directory>
% tldr

% Get typical usages of a command (hint: this is how you got here!):

tldr <command>

% Show the tar tldr page for Linux:

tldr -p <linux> <tar>

% Get help for a git subcommand:

tldr <git-checkout>
% tmux

% Start a new session:

tmux

% Start a new named session:

tmux new-session -s <name>

% List existing sessions:

tmux ls

% Attach to the most recently used session:

tmux attach-session

% Attach to a named session:

tmux attach-session -t <name>

% Detach from the current session (with prefix Ctrl-B):

Ctrl-B d

% Kill a session by name:

tmux kill-session -t <name>

% Kill the current session (with prefix Ctrl-B):

Ctrl-B :kill-session<Enter>
% tokei

% Get a report on the code in a directory and all subdirectories:

tokei <path/to/directory>

% Get a report for a directory excluding `.min.js` files:

tokei <path/to/directory> -e <*.min.js>

% Print out statistics for individual files in a directory:

tokei <path/to/directory> --files

% Get a report for all files of type Rust and Markdown:

tokei <path/to/directory> -t=<Rust>,<Markdown>
% touch

% Create a new empty file(s) or change the times for existing file(s) to current time:

touch <filename>

% Set the times on a file to a specific date and time:

touch -t <YYYYMMDDHHMM.SS> <filename>

% Use the times from a file to set the times on a second file:

touch -r <filename> <filename2>
% tox

% Run tests on all test environments:

tox

% Create a tox.ini configuration:

tox-quickstart

% List the available environments:

tox --listenvs-all

% Run tests on a specific environment (e.g. python 3.6):

tox -e <py36>

% Force the virtual environment to be recreated:

tox --recreate -e <py27>
% tpp

% View a presentation:

tpp <filename>

% Output a presentation:

tpp -t <type> -o <outputname> <filename>
% tput

% Move the cursor to a screen location:

tput cup <y_coordinate> <x_coordinate>

% Set foreground (af) or background (ab) color:

tput <setaf|setab> <ansi_color_code>

% Show number of columns, lines, or colors:

tput <cols|lines|colors>

% Ring the terminal bell:

tput bel

% Reset all terminal attributes:

tput sgr0

% Enable / Disable word wrap:

tput <smam|rmam>
% traceroute

% Traceroute to a host:

traceroute <host>

% Disable IP address and host name mapping:

traceroute -n <host>

% Specify wait time for response:

traceroute -w <0.5> <host>

% Specify number of queries per hop:

traceroute -q <5> <host>

% Specify size in bytes of probing packet:

traceroute <host> <42>
% traefik

% Start server with default config:

traefik

% Start server with a custom config file:

traefik --c <config_file>.toml

% Start server with cluster mode enabled:

traefik --cluster

% Start server with web UI enabled:

traefik --web
% transcode

% Create stabilisation file to be able to remove camera shakes:

transcode -J stabilize -i <input_file>

% Remove camera shakes after creating stabilisation file, transform video using xvid:

transcode -J transform -i <input_file> -y xvid -o <output_file>

% Resize the video to 640x480 pixels and convert to MPEG4 codec using xvid:

transcode -Z 640x480 -i <input_file> -y xvid -o <output_file>
% trans

% Translate a word (language is detected automatically):

trans "<word_or_sentence_to_translate>"

% Get a brief translation:

trans --brief "<word_or_sentence_to_translate>"

% Translate a word into french:

trans :<fr> <word>

% Translate a word from German to English:

trans <de>:<en> <Schmetterling>

% Behave like a dictionary to get the meaning of a word:

trans -d <word>
% transmission-cli

% Download a specific torrent:

transmission-cli <url|magnet|path/to/file>

% Download a torrent to a specific directory:

transmission-cli --download-dir <path/to/download_directory> <url|magnet|path/to/file>

% Create a torrent file from a specific file or directory:

transmission-cli --new <path/to/source_file_or_directory>

% Set the download speed limit to 50 KB/s:

transmission-cli --downlimit <50> <url|magnet|path/to/file>

% Set the upload speed limit to 50 KB/s:

transmission-cli --uplimit <50> <url|magnet|path/to/file>

% Use a specific port for connections:

transmission-cli --port <port_number> <url|magnet|path/to/file>

% Force encryption for peer connections:

transmission-cli --encryption-required <url|magnet|path/to/file>

% Use a Bluetack-formatted peer blocklist:

transmission-cli --blocklist <blocklist_url|path/to/blocklist> <url|magnet|path/to/file>
% transmission-remote

% Add a torrent file or magnet link to Transmission and download to a specified directory:

transmission-remote <hostname> -a <torrent|url> -w <path/to/download_directory>

% Change the default download directory:

transmission-remote <hostname> -w <path/to/download_directory>

% List all torrents:

transmission-remote <hostname> --list

% Start torrent 1 and 2, stop torrent 3:

transmission-remote <hostname> -t <"1,2"> --start -t <3> --stop

% Remove torrent 1 and 2, and also delete local data for torrent 2:

transmission-remote <hostname> -t <1> --remove -t <2> --remove-and-delete

% Stop all torrents:

transmission-remote <hostname> -t <all> --stop

% Move torrents 1-10 and 15-20 to a new folder (folder will be created if it does not exist):

transmission-remote <hostname> -t <"1-10,15-20"> --move <path/to/new_directory>
% trash-cli

% Trash files and directories:

trash-put <file_name>

% Empty the trashcan:

trash-empty

% List trashed files:

trash-list

% Restore a trashed file by choosing a number from the list that results from this command:

trash-restore

% Remove individual files from the trashcan:

trash-rm <file_name>
% trawl

% Show column names:

trawl -n

% Filter interface names using a case insensitive regular expression:

trawl -f wi

% Get a list of available interfaces:

trawl -i

% Include the loopback interface:

trawl -l
% tr

% Replace all occurrences of a character in a file, and print the result:

tr <find_character> <replace_character> < <filename>

% Replace all occurrences of a character from another command's output:

echo <text> | tr <find_character> <replace_character>

% Map each character of the first set to the corresponding character of the second set:

tr '<abcd>' '<jkmn>' < <filename>

% Delete all occurrences of the specified set of characters from the input:

tr -d '<input_characters>' < <filename>

% Compress a series of identical characters to a single character:

tr -s '<input_characters>' < <filename>

% Translate the contents of a file to upper-case:

tr "[:lower:]" "[:upper:]" < <filename>

% Strip out non-printable characters from a file:

tr -cd "[:print:]" < <filename>
% true

% Return a successful exit code:

true
% truncate

% Set a size of 10 GB to an exsting file, or create a new file with the specified size:

truncate -s <10G> <filename>

% Extend the file size by 50M, fill with holes (which reads as zero bytes):

truncate -s +<50M> <filename>

% Shrink the file by 2GiB, by removing data from the end of file:

truncate -s -<2G> <filename>

% Empty the file's content:

truncate -s 0 <filename>
% tsc

% Compile a TypeScript file `foobar.ts` into a JavaScript file `foobar.js`:

tsc <foobar.ts>

% Compile a TypeScript file into JavaScript using a specific target syntax (default is `ES3`):

tsc --target <ES5|ES2015|ES2016|ES2017|ES2018|ESNEXT> <foobar.ts>

% Compile a TypeScript file into a JavaScript file with a custom name:

tsc --outFile <output.js> <input.ts>

% Compile all `.ts` files of a TypeScript project defined in a `tsconfig.json` file:

tsc --build <tsconfig.json>

% Run the compiler using command line options and arguments fetched from a text file:

tsc @<args.txt>

% Type-check multiple JavaScript files, and output only the errors:

tsc --allowJs --checkJs --noEmit <src/**/*.js>
% tslint

% Create tslint config:

tslint --init

% Lint on a given set of files:

tslint <filename>.js <filename1>.js

% Fix lint issues:

tslint --fix

% Lint with the config file in the project root:

tslint --project <path/to/project_root>
% tsort

% Perform a topological sort consistent with a partial sort per line of input separated by blanks:

tsort <file>
% tty

% Print the file name of this terminal:

tty
% type

% Display the kind of a command:

type <command>

% Display all locations containing the specified executable:

type -a <command>

% Display the name of the disk file that would be executed:

type -p <command>
% ufraw-batch

% Simply convert RAW files to jpg:

ufraw-batch --out-type=jpg <input_file(s)>

% Simply convert RAW files to png:

ufraw-batch --out-type=png <input_file(s)>

% Extract the preview image from the raw file:

ufraw-batch --embedded-image <input_file(s)>

% Save the file with size up to the given maximums MAX1 and MAX2:

ufraw-batch --size=MAX1,MAX2 <input_file(s)>
% ulimit

% Get the properties of all the user limits:

ulimit -a

% Get hard limit for the number of simultaneously opened files:

ulimit -H -n

% Get soft limit for the number of simultaneously opened files:

ulimit -S -n

% Set max per-user process limit:

ulimit -u 30
% umask

% Display the current mask in octal notation:

umask

% Display the current mask in symbolic (human-readable) mode:

umask -S

% Change the mask symbolically to allow read permission for all users (the rest of the mask bits are unchanged):

umask <a+r>

% Set the mask (using octal) to restrict no permissions for the file's owner, and restrict all permissions for everyone else:

umask <077>
% umount

% Unmount a filesystem, by passing the path to the source it is mounted from:

umount <path/to/device_file>

% Unmount a filesystem, by passing the path to the target where it is mounted:

umount <path/to/mounted_directory>

% Unmount all mounted filesystems (except the `proc` filesystem):

umount -a
% unalias

% Remove an alias:

unalias <alias_name>

% Remove all aliases:

unalias -a
% uname

% Print hardware-related information: machine and processor:

uname -mp

% Print software-related information: operating system, release number, and version:

uname -srv

% Print the nodename (hostname) of the system:

uname -n

% Print all available system information (hardware, software, nodename):

uname -a
% unar

% Extract an archive to the current directory:

unar <archive>

% Extract an archive to the specified directory:

unar -o <path/to/directory> <archive>

% Force overwrite if files to be unpacked already exist:

unar -f <archive>

% Force rename if files to be unpacked already exist:

unar -r <archive>

% Force skip if files to be unpacked already exist:

unar -s <archive>
% uncrustify

% Format a single file:

uncrustify -f <path/to/file.cpp> -o <path/to/output.cpp>

% Read filenames from stdin, and take backups before writing output back to the original filepaths:

find . -name "*.cpp" | uncrustify -F - --replace

% Don't make backups (useful if files are under version control):

find . -name "*.cpp" | uncrustify -F - --no-backup

% Use a custom configuration file and write the result to stdout:

uncrustify -c <path/to/uncrustify.cfg> -f <path/to/file.cpp>

% Explicitly set a configuration variable's value:

uncrustify --set <option>=<value>

% Generate a new configuration file:

uncrustify --update-config -o <path/to/new.cfg>
% unexpand

% Convert blanks in each file to tabs, writing to standard output:

unexpand <file>

% Convert blanks to tabs, reading from standard output:

unexpand

% Convert all blanks, instead of just initial blanks:

unexpand -a <file>

% Convert only leading sequences of blanks (overrides -a):

unexpand --first-only <file>

% Have tabs a certain number of characters apart, not 8 (enables -a):

unexpand -t <number> <file>
% uniq

% Display each line once:

sort <file> | uniq

% Display only unique lines:

sort <file> | uniq -u

% Display only duplicate lines:

sort <file> | uniq -d

% Display number of occurrences of each line along with that line:

sort <file> | uniq -c

% Display number of occurrences of each line, sorted by the most frequent:

sort <file> | uniq -c | sort -nr
% unison

% Sync two directories (creates log first time these two directories are synchronised):

unison <path/to/directory_1> <path/to/directory_2>

% Automatically accept the (non-conflicting) defaults:

unison <path/to/directory_1> <path/to/directory_2> -auto

% Ignore some files using a pattern:

unison <path/to/directory_1> <path/to/directory_2> -ignore <pattern>

% Show documentation:

unison -doc <topics>
% unlink

% Remove the specified file if it is the last link:

unlink <path/to/file>
% unrar

% Extract files with original directory structure:

unrar x <compressed.rar>

% Extract files into current directory, losing directory structure in the archive:

unrar e <compressed.rar>

% Test integrity of each file inside the archive file:

unrar t <compressed.rar>

% List files inside the archive file without decompressing it:

unrar l <compressed.rar>
% unzip

% Extract zip file(s) (for multiple files, separate file paths by spaces):

unzip <file(s)>

% Extract zip files(s) to given path:

unzip <compressed_file(s)> -d </path/to/put/extracted_file(s)>

% List the contents of a zip file without extracting:

unzip -l <file.zip>

% Extract the contents of the file(s) to `stdout` alongside the extracted file names:

unzip -c <file.zip>

% Extract a zip file created in windows, containing files with non-ascii (chinese) filenames:

unzip -O <gbk> <file.zip>
% uptime

% Print current time, uptime, number of logged-in users and other information:

uptime

% Show only the amount of time the system has been booted for:

uptime --pretty

% Print the date and time the system booted up at:

uptime --since

% Show version information:

uptime --version
% upx

% Compress executable:

upx <file>

% Decompress executable:

upx -d <file>

% Detailed help:

upx --help
% users

% Display a list of logged in users:

users

% Display a list of logged in users according to a specific file:

users </var/log/wmtp>
% vagrant

% Create Vagrantfile in current directory with the base Vagrant box:

vagrant init

% Create Vagrantfile with the Ubuntu 14.04 (Trusty Tahr) box from HashiCorp Atlas:

vagrant init ubuntu/trusty32

% Start and provision the vagrant environment:

vagrant up

% Suspend the machine:

vagrant suspend

% Halt the machine:

vagrant halt

% Connect to machine via SSH:

vagrant ssh
% valgrind

% Use the (default) Memcheck tool to show a diagnostic of memory usage by `program`:

valgrind <program>

% Use Memcheck to report all possible memory leaks of `program` in full detail:

valgrind --leak-check=full --show-leak-kinds=all <program>

% Use the Cachegrind tool to profile and log CPU cache operations of `program`:

valgrind --tool=cachegrind <program>

% Use the Massif tool to profile and log heap memory and stack usage of `program`:

valgrind --tool=massif --stacks=yes <program>
% vault

% Connect to a Vault server and initialize a new encrypted data store:

vault init

% Unseal (unlock) the vault, by providing one of the key shares needed to access the encrypted data store:

vault unseal <key-share-x>

% Authenticate the CLI client against the Vault server, using an authentication token:

vault auth <authentication_token>

% Store a new secret in the vault, using the generic back-end called "secret":

vault write secret/<hello> value=<world>

% Read a value from the vault, using the generic back-end called "secret":

vault read secret/<hello>

% Read a specific field from the value:

vault read -field=<field_name> secret/<hello>

% Seal (lock) the Vault server, by removing the encryption key of the data store from memory:

vault seal
% vcsh

% Initialize an (empty) repository:

vcsh init <repository_name>

% Clone a repository into a custom directory name:

vcsh clone <git_url> <repository_name>

% List all managed repositories:

vcsh list

% Execute a git command on a managed repository:

vcsh <repository_name> <git_command>

% Push/pull all managed repositories to/from remotes:

vcsh <push|pull>

% Write a custom .gitignore file for a managed repository:

vcsh write-gitignore <repository_name>
% vdir

% List files and directories in the current directory, one per line, with details:

vdir

% List with sizes displayed in human readable units (KB, MB, GB):

vdir -h

% List including hidden files (starting with a dot):

vdir -a

% List files and directories sorting entries by size (largest first):

vdir -S

% List files and directories sorting entries by modification time (newest first):

vdir -t

% List grouping directories first:

vdir --group-directories-first

% Recursively list all files and directories in a specific directory:

vdir --recursive <path/to/directory>
% vegeta

% Launch an attack lasting 30 seconds:

echo "<GET https://example.com>" | vegeta attack -duration=<30s>

% Launch an attack on a server with a self-signed https certificate:

echo "<GET https://example.com>" | vegeta attack -insecure -duration=<30s>

% Launch an attack with a rate of 10 requests per second:

echo "<GET https://example.com>" | vegeta attack -duration=<30s> -rate=<10>

% Launch an attack and display a report:

echo "<GET https://example.com>" | vegeta attack -duration=<30s> | vegeta report

% Launch an attack and plot the results on a graph (latency over time):

echo "<GET https://example.com>" | vegeta attack -duration=<30s> | vegeta plot > <path/to/results.html>

% Launch an attack against multiple URLs from a file:

vegeta attack -duration=<30s> -targets=<requests.txt> | vegeta report
% velero

% Create a backup containing all resources:

velero backup create <backup_name>

% List all backups:

velero backup get

% Delete a backup:

velero backup delete <backup_name>

% Create a weekly backup, each living for 90 days (2160 hours):

velero schedule create <schedule_name> --schedules="<@every 7d>" --ttl <2160h0m0s>

% Create a restore from the latest successful backup triggered by specific schedule:

velero restore create --from-schedule <schedule_name>
% view

% Open a file:

view <file>
% vimdiff

% Open two files and show the differences (up to four files can be compared):

vimdiff <file1> <file2>

% Open two files using a horizontal window split instead of the default vertical split:

vimdiff -o <file1> <file2>

% Move the cursor to the window on the left|right|up|down:

Ctrl + w <h|l|k|j>
% vim

% Open a file:

vim <path/to/file>

% View Vim's help manual:

:help<Enter>

% Save a file:

:write<Enter>

% Quit without saving:

:quit!<Enter>

% Open a file at a specified line number:

vim +<line_number> <path/to/file>

% Undo the last operation:

u

% Search for a pattern in the file (press `n`/`N` to go to next/previous match):

/<search_pattern><Enter>

% Perform a regex substitution in the whole file:

:%s/<pattern>/<replacement>/g<Enter>
% vimtutor

% Launch the vim tutor using the given language (en, fr, de, ...):

vimtutor <language>

% Exit the tutor:

<Esc> :q <Enter>
% virsh

% Connect to a hypervisor session:

virsh connect <qemu://system>

% List all domains:

virsh list --all

% Dump guest configuration file:

virsh dumpxml <guest_id> > <path/to/guest.xml>

% Create a guest from a configuration file:

virsh create <path/to/config_file.xml>

% Edit a guest's configuration file (editor can be changed with $EDITOR):

virsh edit <guest_id>

% Start/reboot/shutdown/suspend/resume a guest:

virsh <command> <guest_id>

% Save the current state of a guest to a file:

virsh save <guest_id> <filename>

% Delete a running guest:

virsh destroy <guest_id> && virsh undefine <guest_id>
% virtualenv

% Create a new environment:

virtualenv <path/to/venv>

% Customize the prompt prefix:

virtualenv --prompt=<prompt_prefix> <path/to/venv>

% Use a different version of Python with virtualenv:

virtualenv --python=<path/to/pythonbin> <path/to/venv>

% Start (select) the environment:

source <path/to/venv>/bin/activate

% Stop the environment:

deactivate
% visudo

% Edit sudoers file:

sudo visudo

% Check sudoers file for errors:

sudo visudo -c
% vsce

% List all the extensions created by a publisher:

vsce list <publisher>

% Publish an extension as major, minor or patch version:

vsce publish <major|minor|patch>

% Unpublish an extension:

vsce unpublish <extension_id>

% Package the current working directory as .vsix file:

vsce package

% Show the metadata associated with an extension:

vsce show <extension_id>
% vue build

% Build a `.js` or `.vue` file in production mode with zero config:

vue build <filename>
% vue init

% Create a new project using one of the default templates:

vue init <webpack|webpack-simple|browserify|browserify-simple|simple> <project_name>

% Create a new project using a local template:

vue init <path/to/template_directory> <project_name>

% Create a new project using a template from GitHub:

vue init <username>/<repo> <project_name>
% vue

% Create a new vue project interactively:

vue create <project_name>

% Create a new project with web UI:

vue ui
% vue serve

% Serve a `.js` or `.vue` file in development mode with zero config:

vue serve <filename>
% w3m

% Open a URL:

w3m <http://example.com>

% Open a URL in monochrome mode:

w3m <http://example.com> -M

% Open a URL without mouse support:

w3m <http://example.com> --no-mouse

% Open a new browser tab:

Shift + T

% Display your browser history:

Ctrl + H

% Quit w3m:

'q' then 'y'
% wait

% Wait for a process to finish given its process ID (PID) and return its exit status:

wait <pid>

% Wait for all processes known to the invoking shell to finish:

wait
% waitress-serve

% Run a Python web app:

waitress-serve <import.path:wsgi_func>

% Listen on port 8080 on localhost:

waitress-serve --listen=<localhost>:<8080> <import.path:wsgi_func>

% Start waitress on a Unix socket:

waitress-serve --unix-socket=<path/to/socket> <import.path:wsgi_func>

% Use 4 threads to process requests:

waitress-serve --threads=<4> <import.path:wsgifunc>

% Call a factory method that returns a WSGI object:

waitress-serve --call <import.path.wsgi_factory>

% Set the URL scheme to https:

waitress-serve --url-scheme=<https> <import.path:wsgi_func>
% wal

% Preview color scheme:

wal --preview <image.png>

% Create color scheme:

wal -i <image.png>

% Create a light color scheme:

wal -il <image.png>

% Skip setting the desktop wallpaper:

wal -in <image.png>

% Skip setting the terminal colors:

wal -is <image.png>

% Restore the previously generated color scheme and wallpaper:

wal -R
% wapm

% Interactively create a new wapm.toml file:

wapm init

% Download all the packages listed as dependencies in wapm.toml:

wapm install

% Download a specific version of a package and add it to the list of dependencies in wapm.toml:

wapm install <package_name>@<version>

% Download a package and install it globally:

wapm install --global <package_name>

% Uninstall a package and remove it from the list of dependencies in wapm.toml:

wapm uninstall <package_name>

% Print a tree of locally-installed dependencies:

wapm list

% List top-level globally installed packages:

wapm list --global

% Execute a package command using the Wasmer runtime:

wapm run <command_name> <arguments>
% wasm2c

% Convert a file to a C source file and header and display it to the console:

wasm2c <file.wasm>

% Write the output to a given file (file.h gets additionally generated):

wasm2c <file.wasm> -o <file.c>
% wasm2wat

% Convert a file to the text format and display it to the console:

wasm2wat <file.wasm>

% Write the output to a given file:

wasm2wat <file.wasm> -o <file.wat>
% wasm-objdump

% Display the section headers of a given binary:

wasm-objdump -h <file.wasm>

% Display the entire disassembled output of a given binary:

wasm-objdump -d <file.wasm>

% Display the details of each section:

wasm-objdump --details <file.wasm>

% Display the details of a given section:

wasm-objdump --section '<import>' --details <file.wasm>
% wasm-opt

% Apply default optimizations and write to a given file:

wasm-opt -O <input.wasm> -o <output.wasm>

% Apply all optimizations and write to a given file (takes more time, but generates optimal code):

wasm-opt -O4 <input.wasm> -o <output.wasm>

% Optimize a file for size:

wasm-opt -Oz <input.wasm> -o <output.wasm>

% Print the textual representation of the binary to console:

wasm-opt <input.wasm> --print
% wat2wasm

% Parse and check a file for errors:

wat2wasm <file.wat>

% Write the output binary to a given file:

wat2wasm <file.wat> -o <file.wasm>

% Display simplified representation of every byte:

wat2wasm -v <file.wat>
% watch

% Repeatedly run a command and show the result:

watch <command>

% Re-run a command every 60 seconds:

watch -n <60> <command>

% Monitor the contents of a directory, highlighting differences as they appear:

watch -d <ls -l>
% wc

% Count lines in file:

wc -l <file>

% Count words in file:

wc -w <file>

% Count characters (bytes) in file:

wc -c <file>

% Count characters in file (taking multi-byte character sets into account):

wc -m <file>
% weasyprint

% Render a HTML file to PDF:

weasyprint <path/to/input.html> <path/to/output>.pdf

% Render a HTML file to PNG, including an additional user stylesheet:

weasyprint <path/to/input.html> <path/to/output>.png --stylesheet <path/to/stylesheet.css>

% Output additional debugging information when rendering:

weasyprint <path/to/input.html> <path/to/output>.pdf --verbose

% Specify a custom resolution when outputting to PNG:

weasyprint <path/to/input.html> <path/to/output>.png --resolution <300>

% Specify a base url for relative urls in the input HTML file:

weasyprint <path/to/input.html> <path/to/output>.png --base-url <url_or_filename>
% web-ext

% Run the web extension in the current directory in Firefox:

web-ext run

% Run a web extension from a specific directory in Firefox:

web-ext run --source-dir <path/to/directory>

% Display verbose execution output:

web-ext run --verbose

% Run a web extension in Firefox Android:

web-ext run --target firefox-android

% Lint the manifest and source files for errors:

web-ext lint

% Build and package the extension:

web-ext build

% Display verbose build output:

web-ext build --verbose

% Sign a package for self-hosting:

web-ext sign --api-key <api_key> --api-secret <api_secret>
% webpack

% Create a single output file from an entry point file:

webpack <app.js> <bundle.js>

% Load css files too from the js file (this uses the css loader for .css files):

webpack <app.js> <bundle.js> --module-bind 'css=css'

% Pass a config file (with eg. the entry script and the output filename) and show compilation progress:

webpack --config <webpack.config.js> --progress

% Automatically recompile on changes to project files:

webpack --watch <app.js> <bundle.js>
% webtorrent

% Download a torrent:

webtorrent download "<torrent_id>"

% Stream a torrent to VLC media player:

webtorrent download "<torrent_id>" --vlc

% Stream a torrent to a Digital Living Network Alliance (DLNA) device:

webtorrent download "<torrent_id>" --dlna

% Display a list of files for a specific torrent:

webtorrent download "<torrent_id>" --select

% Specify a file index from the torrent to download:

webtorrent download "<torrent_id>" --select <index>

% Seed a specific file or directory:

webtorrent seed <path/to/file_or_directory>

% Create a new torrent file for the specified file path:

webtorrent create <path/to/file>

% Display information for a magnet uri or .torrent file:

webtorrent info <path/to/file_or_magnet>
% wget

% Download the contents of an URL to a file (named "foo" in this case):

wget <https://example.com/foo>

% Download the contents of an URL to a file (named "bar" in this case):

wget -O <bar> <https://example.com/foo>

% Download a single web page and all its resources with 3-second intervals between requests (scripts, stylesheets, images, etc.):

wget --page-requisites --convert-links --wait=3 <https://example.com/somepage.html>

% Download all listed files within a directory and its sub-directories (does not download embedded page elements):

wget --mirror --no-parent <https://example.com/somepath/>

% Limit the download speed and the number of connection retries:

wget --limit-rate=<300k> --tries=<100> <https://example.com/somepath/>

% Download a file from an HTTP server using Basic Auth (also works for FTP):

wget --user=<username> --password=<password> <https://example.com>

% Continue an incomplete download:

wget -c <https://example.com>

% Download all URLs stored in a text file to a specific directory:

wget -P <path/to/directory> -i <URLs.txt>
% where

% Find all instances of a command:

where <command>
% which

% Search the PATH environment variable and display the location of any matching executables:

which <executable>

% If there are multiple executables which match, display all:

which -a <executable>
% while

% Read `stdin` and perform an action on every line:

while read line; do echo "$line"; done

% Execute a command forever once every second:

while :; do <command>; sleep 1; done
% whoami

% Display currently logged username:

whoami

% Display the username after a change in the user ID:

sudo whoami
% whois

% Get information about a domain name:

whois <example.com>

% Get information about an IP address:

whois <8.8.8.8>

% Get abuse contact for an IP address:

whois -b <8.8.8.8>
% who

% Display the username, line, and time of all currently logged-in sessions:

who

% Display information only for the current terminal session:

who am i

% Display all available information:

who -a

% Display all available information with table headers:

who -a -H
% w

% Show logged-in users info:

w

% Show logged-in users info without a header:

w -h
% wordgrinder

% Start wordgrinder (loads a blank document by default):

wordgrinder

% Open a given file:

wordgrinder <filename>

% Show the menu:

Alt + M
% wormhole

% Send a file:

wormhole send <path/to/file>

% Receive a file:

wormhole receive <wormhole_code>

% Send raw text:

wormhole send
% wpa_supplicant

% Join a protected wireless network:

wpa_supplicant -i <interface> -c <path/to/wpa_supplicant_conf.conf>

% Join a protected wireless network and run it in a daemon:

wpa_supplicant -B -i <interface> -c <path/to/wpa_supplicant_conf.conf>
% write

% Send a message to a given user on a given terminal id:

write <username> <terminal_id>

% Send message to "testuser" on terminal "/dev/tty/5":

write <testuser> <tty/5>

% Send message to "jhondoe" on pseudo terminal "/dev/pts/5":

write <jhondoe> <pts/5>
% wrk

% Run a benchmark for `30` seconds, using `12` threads, and keeping `400` HTTP connections open:

wrk -t<12> -c<400> -d<30s> "<http://127.0.0.1:8080/index.html>"

% Run a benchmark with a custom header:

wrk -t<2> -c<5> -d<5s> -H "<Host: example.com>" "<http://example.com/index.html>"

% Run a benchmark with a request timeout of `2` seconds:

wrk -t<2> -c<5> -d<5s> --timeout <2s> "<http://example.com/index.html>"
% wuzz

% Start wuzz:

wuzz

% Display help information:

F1

% Send an HTTP request:

Ctrl + R

% Switch to the next view:

Ctrl + J, Tab

% Switch to the previous view:

Ctrl + K, Shift + Tab
% xargs

% Run a command using the input data as arguments:

<arguments_source> | xargs <command>

% Run multiple chained commands on the input data:

<arguments_source> | xargs sh -c "<command1> && <command2> | <command3>"

% Delete all files with a `.backup` extension (`-print0` uses a null character to split file names, and `-0` uses it as delimiter):

find . -name <'*.backup'> -print0 | xargs -0 rm -v

% Execute the command once for each input line, replacing any occurrences of the placeholder (here marked as `_`) with the input line:

<arguments_source> | xargs -I _ <command> _ <optional_extra_arguments>

% Parallel runs of up to `max-procs` processes at a time; the default is 1. If `max-procs` is 0, xargs will run as many processes as possible at a time:

<arguments_source> | xargs -P <max-procs> <command>
% xcv

% Cut a file:

xcv x <input_file>

% Copy a file:

xcv c <input_file>

% Paste a file:

xcv v <output_file>

% List files available for pasting:

xcv l
% xdg-user-dirs-update

% Change XDG's DESKTOP directory to the specified directory (must be absolute):

xdg-user-dirs-update --set DESKTOP "<path/to/directory>"

% Write the result to the specified dry-run-file instead of the `user-dirs.dirs` file:

xdg-user-dirs-update --dummy-output "<path/to/dry_run_file>" --set <xdg_user_directory> "<path/to/directory>"
% xgettext

% Scan file and output strings to `messages.po`:

xgettext <path/to/input_file>

% Use a different output filename:

xgettext --output <path/to/output_file> <path/to/input_file>

% Append new strings to an existing file:

xgettext --join-existing --output <path/to/output_file> <path/to/input_file>

% Don't add a header containing metadata to the output file:

xgettext --omit-header <path/to/input_file>
% xkill

% Display a cursor to kill a window when pressing the left mouse button (press any other mouse button to cancel):

xkill
% xmllint

% Return all nodes (tags) named "foo":

xmllint --xpath "//<foo>" <source_file.xml>

% Return the contents of the first node named "foo" as a string:

xmllint --xpath "string(//<foo>)" <source_file.xml>

% Return the href attribute of the second anchor element in an html file:

xmllint --html --xpath "string(//a[2]/@href)" webpage.xhtml

% Return human-readable (indented) XML from file:

xmllint --format <source_file.xml>

% Check that a XML file meets the requirements of its DOCTYPE declaration:

xmllint --valid <source_file.xml>

% Validate XML against DTD schema hosted online:

xmllint --dtdvalid <URL> <source_file.xml>
% xo

% Lint files in the "src" directory:

xo

% Lint a given set of files:

xo <file1>.js <file2>.js

% Automatically fix any lint issues found:

xo --fix

% Lint using spaces as indentation instead of tabs:

xo --space

% Lint using the "prettier" code style:

xo --prettier
% xsv

% Inspect the headers of a file:

xsv headers <path/to/file.csv>

% Count the number of entries:

xsv count <path/to/file.csv>

% Get an overview of the shape of entries:

xsv stats <path/to/file.csv> | xsv table

% Select a few columns:

xsv select <column_a,column_b> <path/to/file.csv>

% Show 10 random entries:

xsv sample <10> <path/to/file.csv>

% Join a column from one file to another:

xsv join --no-case <column_a> <path/to/file/a.csv> <column_b> <path/to/file/b.csv> | xsv table
% xxd

% Generate a hexdump from a binary file and display the output:

xxd <input_file>

% Generate a hexdump from a binary file and save it as a text file:

xxd <input_file> <output_file>

% Display the output with 10 columns of one octet (byte) each:

xxd -c <10> <input_file>

% Display output only up to a length of 32 bytes:

xxd -l <32> <input_file>

% Display the output in plain mode, without any gaps between the columns:

xxd -p <input_file>

% Revert a plaintext hexdump back into binary, and save it as a binary file:

xxd -r -p <input_file> <output_file>
% x_x

% View an XLSX or CSV file:

x_x <file.xlsx|file.csv>

% View an XLSX or CSV file, using the first row as table headers:

x_x -h <0> <file.xlsx|file.csv>

% View a CSV file with unconventional delimiters:

x_x --delimiter=<';'> --quotechar=<'|'> <file.csv>
% xz

% Compress a file to the xz file format:

xz <file>

% Decompress a xz file:

xz -d <file.xz>

% Compress a file to the lzma file format:

xz --format=lzma <file>

% Decompress an lzma file:

xz -d --format=lzma <file.lzma>

% Decompress a file and write to `stdout`:

xz -dc <file.xz>

% Compress a file, but don't delete the original:

xz -k <file>

% Compress a file using the fastest compression:

xz -0 <file>

% Compress a file using the best compression:

xz -9 <file>
% yarn

% Install a module globally:

yarn global add <module_name>

% Install all dependencies referenced in the `package.json` file (the `install` is optional):

yarn install

% Install a module and save it as a dependency to the `package.json` file (add `--dev` to save as a dev dependency):

yarn add <module_name>@<version>

% Uninstall a module and remove it from the `package.json` file:

yarn remove <module_name>

% Interactively create a `package.json` file:

yarn init

% Identify whether a module is a dependency and list other modules that depend upon it:

yarn why <module_name>
% yarn-why

% Show why a Yarn package is installed:

yarn-why <package_name>
% yes

% Repeatedly output "message":

yes <message>

% Repeatedly output "y":

yes
% yesod

% Create a new scaffolded site, with sqlite as backend, in the "my-project" directory:

stack new <my-project> <yesod-sqlite>

% Install the Yesod CLI tool within a Yesod scaffolded site:

stack build yesod-bin cabal-install --install-ghc

% Start development server:

stack exec -- yesod devel

% Touch files with altered Template Haskell dependencies:

stack exec -- yesod touch

% Deploy application using Keter (Yesod's deployment manager):

stack exec -- yesod keter
% youtube-dl

% Download a video or playlist:

youtube-dl <https://www.youtube.com/watch?v=oHg5SJYRHA0>

% List all formats that a video or playlist is available in:

youtube-dl --list-formats <https://www.youtube.com/watch?v=Mwa0_nE9H7A>

% Download a video or playlist at a specific quality:

youtube-dl --format <"best[height<=480]"> <https://www.youtube.com/watch?v=oHg5SJYRHA0>

% Download the audio from a video and convert it to an MP3:

youtube-dl -x --audio-format <mp3> <url>

% Download the best quality audio and video and merge them:

youtube-dl -f bestvideo+bestaudio <url>

% Download video(s) as MP4 files with custom filenames:

youtube-dl --format <mp4> -o <"%(title)s by %(uploader)s on %(upload_date)s in %(playlist)s.%(ext)s"> <url>

% Download a video and save its description, metadata, annotations, subtitles, and thumbnail:

youtube-dl --write-description --write-info-json --write-annotations --write-sub --write-thumbnail <url>

% From a playlist, download all "Let's Play" videos that aren't marked "NSFW" or age-restricted for 7 year-olds:

youtube-dl --match-title <"let's play"> --age-limit <7> --reject-title <"nsfw"> <playlist_url>
% zbarimg

% Process an image file:

zbarimg <image_file>
% zcat

% Print the uncompressed contents of a gzipped file to the standard output:

zcat <file.txt.gz>

% Print compression details of a gzipped file to the standard output:

zcat -l <file.txt.gz>
% zdb

% Show detailed configuration of all mounted ZFS zpools:

zdb

% Show detailed configuration for a specific ZFS pool:

zdb -C <poolname>

% Show statistics about number, size and deduplication of blocks:

zdb -b <poolname>
% zfs

% List all available zfs filesystems:

zfs list

% Create a new ZFS filesystem:

zfs create <pool_name/filesystem_name>

% Delete a ZFS filesystem:

zfs destroy <pool_name/filesystem_name>

% Create a Snapshot of a ZFS filesystem:

zfs snapshot <pool_name/filesystem_name>@<snapshot_name>

% Enable compression on a filesystem:

zfs set compression=on <pool_name/filesystem_name>

% Change mountpoint for a filesystem:

zfs set mountpoint=</my/mount/path> <pool_name/filesystem_name>
% zipalign

% Align the data of a ZIP file on 4-byte boundaries:

zipalign <4> <path/to/input.zip> <path/to/output.zip>

% Check that a ZIP file is correctly aligned on 4-byte boundaries and display the results in a verbose manner:

zipalign -v -c <4> <path/to/input.zip>
% zip

% Package and compress a directory and its contents, [r]ecursively:

zip -r <compressed.zip> </path/to/dir>

% E[x]clude unwanted files from being added to the compressed archive:

zip -r <compressed.zip> <path/to/dir> -x <path/to/exclude>

% Archive a directory and its contents with the highest level [9] of compression:

zip -r -<9> <compressed.zip> </path/to/dir>

% Package and compress multiple directories and files:

zip -r <compressed.zip> </path/to/dir1 /path/to/dir2 /path/to/file>

% Create an encrypted archive (user will be prompted for a password):

zip -e -r <compressed.zip> <path/to/dir>

% Add files to an existing zip file:

zip <compressed.zip> <path/to/file>

% Delete files from an existing zip file:

zip -d <compressed.zip> "<foo/*.tmp>"

% Archive a directory and its contents to a multi-part [s]plit zip file (e.g. 3GB parts):

zip -r -s <3g> <compressed.zip> <path/to/dir>
% zless

% Page through a compressed archive with `less`:

zless <file.txt.gz>
% z

% Go to a directory that contains "foo" in the name:

z <foo>

% Go to a directory that contains "foo" and then "bar":

z <foo> <bar>

% Go to the highest-ranked directory matching "foo":

z -r <foo>

% Go to the most recently accessed directory matching "foo":

z -t <foo>

% List all directories in `z`'s database matching "foo":

z -l <foo>

% Remove the current directory from `z`'s database:

z -x .
% zola

% Create the directory structure used by Zola at the given directory:

zola init <my_site>

% Build the whole site in the `public` directory after deleting it:

zola build

% Build the whole site into a different directory:

zola build --output-dir <path/to/output_directory/>

% Build and serve the site using a local server (default is `127.0.0.1:1111`):

zola serve

% Build all pages just like the build command would, but without writing any of the results to disk:

zola check
% zopflipng

% Optimize a PNG image:

zopflipng <input.png> <output.png>

% Optimize several PNG images and save with given prefix:

zopflipng --prefix=<prefix> <image1.png> <image2.png> <image3.png>
% zpool

% Show the configuration and status of all ZFS zpools:

zpool status

% Check a ZFS pool for errors (verifies the checksum of EVERY block). Very CPU and disk intensive:

zpool scrub <pool_name>

% List zpools available for import:

zpool import

% Import a zpool:

zpool import <pool_name>

% Export a zpool (unmount all filesystems):

zpool export <pool_name>

% Show the history of all pool operations:

zpool history <pool_name>

% Create a mirrored pool:

zpool create <pool_name> mirror <disk1> <disk2> mirror <disk3> <disk4>

% Add a cache (L2ARC) device to a zpool:

zpool add <pool_name> cache <cache_disk>
% zsh

% Start interactive command line interpreter:

zsh

% Execute command passed as parameter:

zsh -c <command>

% Run commands from file (script):

zsh <file>

% Run commands from file and print them as they are executed:

zsh -x <file>
% zstd

% Compress a file into a new file with the .zst suffix:

zstd <file>

% Decompress a file:

zstd -d <file>.zst

% Decompress to `stdout`:

zstd -dc <file>.zst

% Compress a file, while specifing the compression level (0 being worst, 19 best, and 3 default):

zstd -<level> <file>

% Use more memory (both when compressing and decompressing) to achieve a higher compression ratio:

zstd --ultra -<level> <file>
